MODEL_PATH=./models/ggml-model-Q4_K_M.gguf
DB_DIR=./rag_system/db
LOG_DIR=./rag_system/logs
API_KEY=broadcast-tech-rag-2025
STREAMLIT_SERVER_PORT=8501

# ============================================================================
# Chat Format 설정
# ============================================================================
# auto: GGUF 메타데이터의 tokenizer.chat_template 자동 사용 (권장)
# 강제 지정: llama-2, chatml, qwen, zephyr 등
CHAT_FORMAT=auto

# ============================================================================
# API 공개 URL (선택적 - WSL/외부 접속 환경에서 설정)
# ============================================================================
# PUBLIC_API_BASE=http://192.168.0.10:7860
# 설정하지 않으면 FastAPI가 Request 헤더에서 자동 추출

# CPU 최적화 (Intel i7-14700K - 14코어/28스레드)
N_THREADS=20
PARALLEL_WORKERS=10

# GPU 최적화 (RTX 4060 8GB)
N_GPU_LAYERS=-1
MAIN_GPU=0
F16_KV=true
LOW_VRAM=false

# 컨텍스트 및 배치 크기 (GPU 모드 - 성능 최적화)
N_CTX=4096
N_BATCH=768
MAX_DOCUMENTS_TO_PROCESS=20
MAX_PAGES_PER_PDF=50
BATCH_SIZE=10

# 캐싱
CACHE_MAX_SIZE=1000
RESPONSE_CACHE_TTL=7200

# 성능 모드
ENVIRONMENT=production
DEBUG_MODE=false

# ============================================================================
# 검색 설정 (운영 최적화 값 - 2025-10-30 튜닝)
# ============================================================================
SEARCH_TOP_K=3             # 5 → 3 (오탐 감소)
# CRITICAL: BM25 위주 검색, Vector 가중치 상향 (균형)
SEARCH_VECTOR_WEIGHT=0.05  # 0.01 → 0.05 (의미 검색 강화)
SEARCH_BM25_WEIGHT=0.95    # 0.99 → 0.95 (균형 조정)
DEFAULT_THRESHOLD=0.20

# ============================================================================
# V2 Retriever Settings (신규 2-layer RAG 아키텍처) - FORCED
# ============================================================================
USE_V2_RETRIEVER=true  # true: v2 (HybridRetrieverV2), false: v1 (legacy)
INDEX_VERSION=v2       # 인덱스 버전 강제 (v1 fallback 방지)

# V2 Index Paths (하드코딩 방지, .env 값만 사용)
BM25_INDEX_PATH=./indexes_v2/bm25/bm25.pkl
VECTOR_INDEX_PATH=./indexes_v2/faiss/faiss.index
METADATA_DB_PATH=./metadata.db

# Search Parameters
SEARCH_BM25_TOP_K=20   # BM25 검색 개수 (RRF 융합 전)
SEARCH_VEC_TOP_K=20    # Vector 검색 개수 (RRF 융합 전)
SEARCH_RRF_K=60        # RRF constant (기본 60, 높을수록 precision 증가)

# Metadata Fusion (메타데이터 검색 병합)
ENABLE_METADATA_FUSION=true   # 메타데이터 검색 활성화
METADATA_FUSION_WEIGHT=0.6    # 메타데이터 검색 가중치
HYBRID_FUSION_WEIGHT=0.4      # 하이브리드 검색 가중치
FUSION_TOP_K=5                # 최종 융합 결과 개수

# ============================================================================
# 진단 모드 (Diagnostic Mode)
# ============================================================================
DIAG_RAG=true              # RAG 파이프라인 진단 활성화 (true/false)
DIAG_LOG_LEVEL=INFO        # 진단 로그 레벨 (DEBUG/INFO/WARNING)

# ============================================================================
# LLM 설정 (llama-cpp-python)
# ============================================================================
LLM_ENABLED=true  # LLM 활성화 (true=켜짐, false=꺼짐)
LLM_BACKEND=llama_cpp
LLM_MODEL_PATH=/home/wnstn4647/AI-CHAT/models/ggml-model-Q4_K_M.gguf
QWEN_MODEL_PATH=/home/wnstn4647/AI-CHAT/models/ggml-model-Q4_K_M.gguf
LLM_N_CTX=4096
LLM_N_THREADS=28
LLM_N_GPU_LAYERS=32  # GPU 레이어 수 (권장 20~40, -1=전체, 0=CPU only)
LLM_N_BATCH=512
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=512
MAX_LLM_RETRY=1  # LLM 생성 재시도 횟수 (운영: 1회)

# ============================================================================
# 운용 모드 설정 (2025-10-30) - 일반 대화 vs 문서근거 자동 전환
# ============================================================================
MODE=AUTO  # AUTO: 점수 기반 자동 전환 | SUMMARIZE: 문서 요약 전용 | CHAT: 일반 대화 전용
RAG_MIN_SCORE=0.35  # 문서근거 모드 최소 점수 (0.0~1.0, 이하면 일반 대화 모드)
DOC_TOPK=1  # 문서근거 모드에서 사용할 상위 문서 개수 (2→1, 지연 축소)
REQUIRE_CITATIONS=true  # 출처 인용 필수 (true일 때 출처 누락 시 재시도)
ALLOW_UNGROUNDED_CHAT=true  # 일반 대화 허용 (false면 항상 문서근거만)

# 라우팅 정책 (2025-10-30 절대값 기반 게이팅 + Coverage Gate)
RAG_MIN_SCORE_POLICY=absolute  # absolute: 절대값 임계값 | normalized: 정규화 점수
BM25_MIN_ABS=5.0               # BM25 절대값 최소 임계값
VEC_MIN_ABS=0.25               # Vector 코사인 절대값 최소 임계값
MIN_KEYWORD_COVERAGE=1         # 최소 키워드 커버리지 (검색 결과에서 발견된 키워드 개수)

# === 모드별 토큰 예산 (2025-10-30 지연 최적화) ===
CHAT_MAX_TOKENS=64             # 스몰토크/일반 질의 (예상: ~2.5-3.5s)
RAG_MAX_TOKENS=160             # 근거 인용형 답변 (예상: ~4.5-6.5s)
SUMMARIZE_MAX_TOKENS=320       # 요약 모드 (JSON 스키마 + 상세 요약, 예상: ~5-7s)
SUMMARIZE_PROMPT_BUDGET=900    # 요약 프롬프트 컨텍스트 예산 (토큰)
# LLM_MAX_TOKENS=512는 상한으로 유지 (개별 모드 값이 우선)

# 답변 스타일 최소화
RAG_STYLE_COMPACT=true         # 불릿 3~5개 + 짧은 결론
RESPONSE_SENTENCE_CAP=6        # 문장 수 상한

# 컨텍스트 최적화 (입력측 토큰 절감)
CONTEXT_MAX_TOKENS=1200        # 프롬프트 컨텍스트 상한
CHUNK_MERGE_MIN_TOKENS=200     # 과분절 합치기

# 품질 가드
ENABLE_SCORE_GATING=true  # 점수 게이팅 (모든 문서 점수 미달 시 문서근거 차단)
ENABLE_HALLUCINATION_CHECK=true  # 환각 감지 (출처 없는 사실 주장 탐지)
LOG_QUERY_ANALYTICS=true  # 질의 분석 로깅 (mode/score/latency)

# ============================================================================
# 보안 설정 (프로덕션 필수) - 2025-10-30
# ============================================================================
# API 인증 (32자 이상 강력한 키 사용, Git 커밋 금지!)
# API_KEY=CHANGE-ME-TO-STRONG-SECRET-KEY-32CHARS-MINIMUM

# CORS 허용 도메인 (쉼표 구분, 화이트리스트)
ALLOWED_ORIGINS=http://localhost:8501,http://127.0.0.1:8501

# 레이트 리미트
RATE_LIMIT_PER_MINUTE=10
RATE_LIMIT_PER_HOUR=100
MAX_CONCURRENT_REQUESTS=4

# 네트워크 바인딩 (보안: 내부만 허용, Nginx 프록시 사용)
FASTAPI_HOST=127.0.0.1
FASTAPI_PORT=7860
STREAMLIT_HOST=127.0.0.1
# STREAMLIT_PORT는 상단에 이미 정의됨

# ========================================
# RAG 시스템 안전 모드 설정 (2025-10-25)
# ========================================
USE_MULTILEVEL_FILTER=0
USE_RERANKER=0
USE_QUERY_EXPANSION=0
USE_DOCUMENT_COMPRESSION=0
MIN_TOP_K=3
DIAG_RAG=1

# ========================================
# 체감 품질 향상 파라미터 (2025-10-25 후속 조치)
# ========================================
DEFAULT_TOP_K=10            # 기본 검색 결과 개수
SNIPPET_MINLEN=200          # snippet 최소 길이 (200자)
SEARCH_BM25_WEIGHT=0.85     # BM25 가중치 (한글 키워드 중심)
SEARCH_VECTOR_WEIGHT=0.15   # Vector 가중치 (의미 보완)

# ============================================================================
# LIST 모드 표시 제한 (2025-10-31)
# ============================================================================
LIST_DEFAULT_LIMIT=20          # 기본 목록 표시 개수
LIST_MAX_LIMIT=200             # 최대 목록 표시 개수 ("전부" 키워드 시)
SOURCES_MAX_DISPLAY=20         # 출처 문서 최대 표시 개수

# ============================================================================
# 검색/카운트 소스 단일화 (2025-10-31 핫픽스: 0건 표시 버그 해결)
# ============================================================================
INDEX_SOURCE=metadata          # bm25, metadata 중 metadata 강제 (UI 카운트용)
UI_USE_BM25=false              # UI가 bm25_index.pkl 로드 금지

# Alerts Configuration (Index Hygiene Monitoring)
ALERTS_DRY_RUN=true
SLACK_WEBHOOK_URL=
LOW_CONF_DELTA=0.05          # Score delta threshold (초기: 0.05, 모니터링 후 0.07까지 상향 검토)
LOW_CONF_MIN_HITS=1           # Minimum hits required for confidence check
LOW_CONF_LIST_SIZE=20         # LIST_FIRST 모드에서 표시할 문서 개수
FINANCE_TOLERANCE_PCT=0.05    # ±5% 허용 오차 (unit_price×qty vs amount 등)
OCR_MIN_AVG_CHARS_PER_PAGE=300  # 페이지당 평균 글자수 임계값 (이미 ingest_from_docs.py에 반영됨)
