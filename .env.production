# AI-CHAT Production Environment Variables
# ==========================================

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_RELOAD=false

# Web Interface Configuration
WEB_HOST=0.0.0.0
WEB_PORT=8501
WEB_MAX_UPLOAD_SIZE=200

# Monitor Configuration
MONITOR_HOST=0.0.0.0
MONITOR_PORT=8502
MONITOR_REFRESH_INTERVAL=5

# Model Configuration
MODEL_PATH=/app/models
MODEL_NAME=qwen2.5-7b-instruct-q4_k_m.gguf
MODEL_TEMPERATURE=0.3
MODEL_MAX_TOKENS=512
MODEL_N_CTX=8192
MODEL_N_BATCH=256
LOW_VRAM=true

# Performance Settings
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000
LAZY_LOADING=true
PARALLEL_WORKERS=4

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=/app/logs/app.log
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30

# Security Settings (Replace with actual values)
JWT_SECRET=${JWT_SECRET}
API_KEY=${API_KEY}
ALLOWED_ORIGINS=http://localhost:8501,http://localhost:8000
CORS_ENABLED=true

# Database Configuration
DATABASE_URL=${DATABASE_URL}
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# Redis Cache (Optional)
REDIS_HOST=${REDIS_HOST}
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=${REDIS_PASSWORD}

# Monitoring & Alerting
SENTRY_DSN=${SENTRY_DSN}
PROMETHEUS_ENABLED=true
METRICS_PORT=9090

# Resource Limits
MAX_MEMORY_GB=16
MAX_CPU_PERCENT=80
MAX_CONCURRENT_REQUESTS=100

# Feature Flags
ENABLE_OCR=true
ENABLE_STREAMING=true
ENABLE_WEBSOCKET=true
ENABLE_CACHE=true
ENABLE_METRICS=true

# Deployment
ENVIRONMENT=production
DEBUG=false
VERSION=2.0.0