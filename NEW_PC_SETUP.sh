#!/bin/bash
# ================================================
# AI-CHAT ìƒˆ PC WSL í™˜ê²½ ì™„ì „ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
# ================================================

echo "ðŸš€ AI-CHAT ìƒˆ PC ì„¤ì • ì‹œìž‘..."
echo "================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
echo -e "${YELLOW}[1/8] ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸...${NC}"
sudo apt-get update

# 2. Python 3.10 ì„¤ì¹˜ (WSL ê¸°ë³¸ì€ ë³´í†µ 3.8)
echo -e "${YELLOW}[2/8] Python 3.10 ì„¤ì¹˜...${NC}"
sudo apt-get install -y python3.10 python3.10-venv python3-pip

# 3. í•„ìˆ˜ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo -e "${YELLOW}[3/8] í•„ìˆ˜ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜...${NC}"
sudo apt-get install -y \
    build-essential \
    gcc \
    g++ \
    cmake \
    git \
    curl \
    wget \
    tesseract-ocr \
    tesseract-ocr-kor \
    poppler-utils \
    libgomp1 \
    libpoppler-cpp-dev

# 4. CUDA ì„¤ì¹˜ (ì„ íƒì‚¬í•­ - GPU ìžˆëŠ” ê²½ìš°ë§Œ)
echo -e "${YELLOW}[4/8] GPU í™•ì¸...${NC}"
if nvidia-smi &>/dev/null; then
    echo -e "${GREEN}âœ“ GPU ê°ì§€ë¨. CUDA ì´ë¯¸ ì„¤ì¹˜ë¨.${NC}"
else
    echo -e "${YELLOW}GPUê°€ ì—†ê±°ë‚˜ ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.${NC}"
    echo "GPU ì‚¬ìš©í•˜ë ¤ë©´ ë‚˜ì¤‘ì— ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:"
    echo "  1. Windowsì—ì„œ NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜"
    echo "  2. WSLì—ì„œ CUDA Toolkit ì„¤ì¹˜"
fi

# 5. í”„ë¡œì íŠ¸ ì••ì¶• í•´ì œ
echo -e "${YELLOW}[5/8] í”„ë¡œì íŠ¸ ì••ì¶• í•´ì œ...${NC}"
if [ -f "ai-chat-complete.tar.gz" ]; then
    tar -xzf ai-chat-complete.tar.gz
    echo -e "${GREEN}âœ“ ì••ì¶• í•´ì œ ì™„ë£Œ${NC}"
else
    echo -e "${RED}âš  ai-chat-complete.tar.gz íŒŒì¼ì„ ë¨¼ì € ë³µì‚¬í•˜ì„¸ìš”!${NC}"
    exit 1
fi

# 6. Python ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
echo -e "${YELLOW}[6/8] Python ê°€ìƒí™˜ê²½ ì„¤ì •...${NC}"
cd AI-CHAT || exit
python3.10 -m venv venv
source venv/bin/activate

# 7. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo -e "${YELLOW}[7/8] Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ (5-10ë¶„ ì†Œìš”)...${NC}"
pip install --upgrade pip
pip install -r requirements_updated.txt

# GPU ìžˆìœ¼ë©´ CUDA ë²„ì „ llama-cpp ìž¬ì„¤ì¹˜
if nvidia-smi &>/dev/null; then
    echo -e "${YELLOW}GPUìš© llama-cpp-python ìž¬ì„¤ì¹˜...${NC}"
    pip uninstall -y llama-cpp-python
    CMAKE_ARGS="-DLLAMA_CUDA=on" pip install llama-cpp-python==0.2.28
fi

# 8. ë””ë ‰í† ë¦¬ ê¶Œí•œ ì„¤ì •
echo -e "${YELLOW}[8/8] ë””ë ‰í† ë¦¬ ìƒì„± ë° ê¶Œí•œ ì„¤ì •...${NC}"
mkdir -p cache indexes logs rag_system/db
chmod -R 755 .

# ì™„ë£Œ!
echo ""
echo -e "${GREEN}================================================${NC}"
echo -e "${GREEN}âœ… ì„¤ì • ì™„ë£Œ!${NC}"
echo -e "${GREEN}================================================${NC}"
echo ""
echo "ì‹¤í–‰ ë°©ë²•:"
echo "  cd AI-CHAT"
echo "  source venv/bin/activate"
echo "  streamlit run web_interface.py"
echo ""
echo "ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì ‘ì†"
echo ""

# íŒŒì¼ ì²´í¬
echo "íŒŒì¼ í™•ì¸:"
echo "  ëª¨ë¸: $(du -sh models/ 2>/dev/null || echo 'âŒ models í´ë” ì—†ìŒ')"
echo "  ë¬¸ì„œ: $(find docs -name '*.pdf' 2>/dev/null | wc -l)ê°œ PDF"
echo ""