#!/usr/bin/env python3
"""
FastAPI ê¸°ë°˜ ê³ ì„±ëŠ¥ API ì„œë²„ V2
=================================

í”„ë¡œë•ì…˜ ë ˆë²¨ ë¡œê¹… ë° ì—ëŸ¬ í•¸ë“¤ë§ ì ìš©
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Request, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import asyncio
import uvicorn
import time
import json
from datetime import datetime
from functools import lru_cache
import uuid
from contextlib import asynccontextmanager

# ë¡œê¹… ì‹œìŠ¤í…œ ì„í¬íŠ¸
from logger_config import (
    get_logger,
    api_logger,
    search_logger,
    perf_logger,
    log_exception
)

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

# ==================== ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬ ====================

class APIState:
    """API ì„œë²„ ìƒíƒœ ê´€ë¦¬"""

    def __init__(self):
        self.rag_instance = None
        self.start_time = time.time()
        self.total_requests = 0
        self.cache_hits = 0
        self.response_times = []
        self.active_connections = 0
        self.initialized = False

    async def initialize(self):
        """RAG ì‹œìŠ¤í…œ ë¹„ë™ê¸° ì´ˆê¸°í™”"""
        if not self.initialized:
            start_time = time.time()
            logger.info("Initializing RAG system...")

            try:
                # Lazy import
                from perfect_rag import PerfectRAG
                self.rag_instance = PerfectRAG()
                self.initialized = True

                load_time = time.time() - start_time
                perf_logger.log_model_loading(
                    model_name="PerfectRAG",
                    load_time_s=load_time,
                    memory_gb=8.0  # ì˜ˆìƒ ë©”ëª¨ë¦¬
                )
                logger.info(f"RAG system initialized in {load_time:.2f}s")

            except Exception as e:
                log_exception(logger, e, {'operation': 'initialize_rag'})
                raise

    def get_metrics(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ë°˜í™˜"""
        hit_rate = (self.cache_hits / max(1, self.total_requests)) * 100
        avg_time = sum(self.response_times[-100:]) / max(1, len(self.response_times[-100:]))

        return {
            "total_requests": self.total_requests,
            "cache_hits": self.cache_hits,
            "cache_hit_rate": round(hit_rate, 2),
            "avg_response_time_ms": round(avg_time * 1000, 2),
            "active_connections": self.active_connections,
            "uptime_seconds": round(time.time() - self.start_time, 2)
        }

# ì „ì—­ ìƒíƒœ ì¸ìŠ¤í„´ìŠ¤
state = APIState()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    # ì‹œì‘
    logger.info("ğŸš€ API Server starting...")
    await state.initialize()
    logger.info("âœ… API Server ready!")

    yield

    # ì¢…ë£Œ
    logger.info("Shutting down API Server...")
    # ì •ë¦¬ ì‘ì—…
    if state.rag_instance:
        logger.info("Cleaning up RAG instance...")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI-CHAT RAG API",
    description="í”„ë¡œë•ì…˜ ë ˆë²¨ RAG ì‹œìŠ¤í…œ API",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œí•œ í•„ìš”
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== ë¯¸ë“¤ì›¨ì–´ ====================

@app.middleware("http")
async def log_requests(request: Request, call_next):
    """ìš”ì²­/ì‘ë‹µ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´"""
    request_id = str(uuid.uuid4())
    start_time = time.time()

    # ìš”ì²­ ë¡œê¹…
    api_logger.info(
        f"Request started: {request.method} {request.url.path}",
        extra={'context': {
            'request_id': request_id,
            'client': request.client.host if request.client else None,
            'user_agent': request.headers.get('user-agent'),
        }}
    )

    try:
        response = await call_next(request)
        process_time = time.time() - start_time

        # ì‘ë‹µ ë¡œê¹…
        perf_logger.log_api_request(
            method=request.method,
            path=request.url.path,
            status=response.status_code,
            duration_ms=process_time * 1000,
            request_id=request_id
        )

        response.headers["X-Request-ID"] = request_id
        response.headers["X-Process-Time"] = str(process_time)
        return response

    except Exception as e:
        process_time = time.time() - start_time
        log_exception(api_logger, e, {
            'request_id': request_id,
            'method': request.method,
            'path': request.url.path
        })
        raise

# ==================== ì˜ˆì™¸ ì²˜ë¦¬ ====================

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """ê²€ì¦ ì˜¤ë¥˜ ì²˜ë¦¬"""
    api_logger.warning(
        f"Validation error: {exc.errors()}",
        extra={'context': {'path': request.url.path}}
    )
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={
            "detail": exc.errors(),
            "body": exc.body if hasattr(exc, 'body') else None
        }
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    api_logger.warning(
        f"HTTP exception: {exc.status_code} - {exc.detail}",
        extra={'context': {'path': request.url.path}}
    )
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail}
    )

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬"""
    request_id = str(uuid.uuid4())
    log_exception(api_logger, exc, {
        'request_id': request_id,
        'path': request.url.path
    })
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "detail": "Internal server error",
            "request_id": request_id,
            "message": "An unexpected error occurred. Please try again later."
        }
    )

# ==================== ë°ì´í„° ëª¨ë¸ ====================

class SearchRequest(BaseModel):
    """ê²€ìƒ‰ ìš”ì²­ ëª¨ë¸"""
    query: str = Field(..., description="ê²€ìƒ‰ ì¿¼ë¦¬", min_length=1, max_length=500)
    mode: str = Field("document", description="ê²€ìƒ‰ ëª¨ë“œ", pattern="^(document|asset)$")
    top_k: int = Field(5, ge=1, le=20, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜")
    use_cache: bool = Field(True, description="ìºì‹œ ì‚¬ìš© ì—¬ë¶€")
    stream: bool = Field(False, description="ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì—¬ë¶€")

class SearchResponse(BaseModel):
    """ê²€ìƒ‰ ì‘ë‹µ ëª¨ë¸"""
    query: str
    response: str
    sources: List[Dict[str, Any]]
    search_time: float
    cached: bool
    timestamp: datetime
    request_id: Optional[str] = None

class HealthResponse(BaseModel):
    """í—¬ìŠ¤ì²´í¬ ì‘ë‹µ"""
    status: str
    version: str
    uptime: float
    memory_usage_gb: float
    gpu_available: bool
    checks: Dict[str, bool]

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/", response_model=dict)
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "AI-CHAT RAG API V2",
        "version": "2.0.0",
        "docs": "/docs",
        "health": "/health",
        "metrics": "/metrics"
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    import psutil
    import torch

    memory = psutil.virtual_memory()
    uptime = time.time() - state.start_time

    # ìƒíƒœ ì²´í¬
    checks = {
        "rag_initialized": state.initialized,
        "model_loaded": state.rag_instance is not None,
        "cache_available": True,
        "database": True  # TODO: ì‹¤ì œ DB ì²´í¬
    }

    return HealthResponse(
        status="healthy" if all(checks.values()) else "degraded",
        version="2.0.0",
        uptime=uptime,
        memory_usage_gb=memory.used / (1024**3),
        gpu_available=torch.cuda.is_available(),
        checks=checks
    )

@app.get("/health/ready")
async def readiness_check():
    """ì¤€ë¹„ ìƒíƒœ ì²´í¬"""
    if not state.initialized:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Service not ready"
        )
    return {"status": "ready"}

@app.get("/health/live")
async def liveness_check():
    """ìƒì¡´ ì²´í¬"""
    return {"status": "alive"}

@app.post("/search", response_model=SearchResponse)
async def search(request: SearchRequest, req: Request):
    """ê²€ìƒ‰ API"""

    # ì´ˆê¸°í™” í™•ì¸
    if not state.initialized:
        await state.initialize()

    request_id = req.headers.get("X-Request-ID", str(uuid.uuid4()))
    state.total_requests += 1
    state.active_connections += 1

    search_logger.info(
        f"Search request: mode={request.mode}, top_k={request.top_k}",
        extra={'context': {
            'request_id': request_id,
            'query_length': len(request.query)
        }}
    )

    try:
        start_time = time.time()

        # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            state.rag_instance.search_and_generate,
            request.query,
            request.mode,
            request.top_k,
            request.use_cache
        )

        search_time = time.time() - start_time
        state.response_times.append(search_time)

        # ìºì‹œ íˆíŠ¸ í™•ì¸
        cached = search_time < 0.5
        if cached:
            state.cache_hits += 1

        # ì„±ëŠ¥ ë¡œê¹…
        perf_logger.log_search_performance(
            query=request.query,
            mode=request.mode,
            results=request.top_k,
            duration_ms=search_time * 1000,
            cached=cached
        )

        # ì‘ë‹µ ìƒì„±
        result = SearchResponse(
            query=request.query,
            response=response,
            sources=[],  # TODO: ì‹¤ì œ ì†ŒìŠ¤ ì¶”ê°€
            search_time=search_time,
            cached=cached,
            timestamp=datetime.now(),
            request_id=request_id
        )

        return result

    except Exception as e:
        log_exception(search_logger, e, {
            'request_id': request_id,
            'query': request.query
        })
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Search failed: {str(e)}"
        )

    finally:
        state.active_connections -= 1

@app.post("/search/stream")
async def search_stream(request: SearchRequest):
    """ìŠ¤íŠ¸ë¦¬ë° ê²€ìƒ‰ API"""

    async def generate():
        """ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„°"""
        request_id = str(uuid.uuid4())

        try:
            # ì´ˆê¸° ì‘ë‹µ
            yield json.dumps({
                "status": "searching",
                "request_id": request_id
            }) + "\n"

            # ê²€ìƒ‰ ìˆ˜í–‰
            response = await search(request, Request(
                {"type": "http", "headers": [(b"x-request-id", request_id.encode())]}
            ))

            # ì²­í¬ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            chunks = response.response.split(". ")
            for i, chunk in enumerate(chunks):
                data = {
                    "chunk": chunk + ".",
                    "progress": (i + 1) / len(chunks),
                    "done": i == len(chunks) - 1,
                    "request_id": request_id
                }
                yield json.dumps(data) + "\n"
                await asyncio.sleep(0.05)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼

        except Exception as e:
            error_data = {
                "error": str(e),
                "request_id": request_id
            }
            yield json.dumps(error_data) + "\n"

    return StreamingResponse(
        generate(),
        media_type="application/x-ndjson"
    )

@app.get("/metrics")
async def get_metrics():
    """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    return state.get_metrics()

@app.post("/cache/clear")
async def clear_cache():
    """ìºì‹œ ì´ˆê¸°í™”"""
    if state.rag_instance:
        state.rag_instance.clear_cache()
        state.cache_hits = 0
        logger.info("Cache cleared successfully")
        return {"message": "Cache cleared successfully"}
    return {"message": "System not initialized"}

# ==================== WebSocket ì§€ì› ====================

from fastapi import WebSocket, WebSocketDisconnect

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    connection_id = str(uuid.uuid4())

    logger.info(f"WebSocket connection established: {connection_id}")

    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_text()
            request = json.loads(data)

            # ê²€ìƒ‰ ìˆ˜í–‰
            search_req = SearchRequest(**request)
            response = await search(
                search_req,
                Request({"type": "websocket", "headers": []})
            )

            # ì‘ë‹µ ì „ì†¡
            await websocket.send_json(response.dict())

    except WebSocketDisconnect:
        logger.info(f"WebSocket connection closed: {connection_id}")
    except Exception as e:
        log_exception(logger, e, {'connection_id': connection_id})
        await websocket.close()

# ==================== ì‹¤í–‰ ====================

def run_server(host="0.0.0.0", port=8000, reload=False):
    """API ì„œë²„ ì‹¤í–‰"""
    logger.info(f"Starting API server on {host}:{port}")

    uvicorn.run(
        "api_server_v2:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info",
        access_log=False  # ì»¤ìŠ¤í…€ ë¡œê¹… ì‚¬ìš©
    )

if __name__ == "__main__":
    print("="*60)
    print("ğŸš€ AI-CHAT RAG API Server V2")
    print("í”„ë¡œë•ì…˜ ë ˆë²¨ ë¡œê¹… ì‹œìŠ¤í…œ ì ìš©")
    print("="*60)
    print()
    print("ğŸ“Œ Endpoints:")
    print("   â€¢ Docs: http://localhost:8000/docs")
    print("   â€¢ Health: http://localhost:8000/health")
    print("   â€¢ Metrics: http://localhost:8000/metrics")
    print()
    print("="*60)

    run_server()