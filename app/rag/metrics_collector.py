"""RAG ì½”ë“œ ê²€ìƒ‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° v2.0 (Thread-safe + High precision)

ì „ì—­ ì‹±ê¸€í„´ìœ¼ë¡œ ë™ì‘í•˜ë©°, HybridRetriever/ExactMatchRetrieverì—ì„œ í˜¸ì¶œ

2025-11-11 v2.0 ê°œì„ ì‚¬í•­:
- Nearest-rank ë°±ë¶„ìœ„ ê³„ì‚° (ì •í™•ë„ í–¥ìƒ)
- ë½ í™€ë“œ ìµœì†Œí™” (ìŠ¤ëƒ…ìƒ· í›„ ê³„ì‚°)
- ë‹¨ì¡° ì‹œê³„ ì‚¬ìš© (ì‹œê³„ ë³€ê²½ ì°¨ë‹¨)
- ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € API (ì¸¡ì • ì½”ë“œ í‘œì¤€í™”)
- EWMA ì§€í‘œ (ì²˜ë¦¬ìœ¨/íˆíŠ¸ìœ¨ ì¶”ì„¸)
- í”„ë¡œë©”í…Œìš°ìŠ¤ í…ìŠ¤íŠ¸ í¬ë§· ë‚´ë³´ë‚´ê¸°
"""

import math
import threading
import time
from collections import deque
from contextlib import contextmanager
from typing import Iterator

from app.core.logging import get_logger

logger = get_logger(__name__)


def _percentile(sorted_vals: list[float], p: float) -> float:
    """ìµœê·¼ì ‘ ìˆœìœ„(nearest-rank) ë°±ë¶„ìœ„ ê³„ì‚°

    Args:
        sorted_vals: ì •ë ¬ëœ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
        p: ë°±ë¶„ìœ„ (0.0 < p <= 1.0)

    Returns:
        pë²ˆì§¸ ë°±ë¶„ìœ„ ê°’
    """
    n = len(sorted_vals)
    if n == 0:
        return 0.0
    # ìµœê·¼ì ‘ ìˆœìœ„: ceil(p * n), ë²”ìœ„ [1, n]
    rank = max(1, min(n, math.ceil(p * n)))
    return float(sorted_vals[rank - 1])


class CodeSearchMetrics:
    """ì½”ë“œ ê²€ìƒ‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° v2.0 (Thread-safe + High precision)"""

    def __init__(self, latency_window_size: int = 2000):
        """Initialize metrics collector

        Args:
            latency_window_size: ì§€ì—°ì‹œê°„ ìƒ˜í”Œ ìœˆë„ í¬ê¸° (ê¸°ë³¸ 2000)
        """
        self._lock = threading.Lock()

        # ì¹´ìš´í„°
        self.code_queries_total = 0
        self.exact_match_hits_total = 0
        self.rrf_fusion_used_total = 0
        self.citation_forced_total = 0

        # ë§ˆì§€ë§‰ ê²€ìƒ‰ ìƒíƒœ
        self.stage0_candidates_last = 0
        self.stage1_candidates_last = 0

        # ì§€ì—°ì‹œê°„ íˆìŠ¤í† ê·¸ë¨ (ìµœê·¼ Nê°œ, ì •í™•í•œ ë°±ë¶„ìœ„ ê³„ì‚°ìš©)
        self.latency_samples = deque(maxlen=latency_window_size)

        # EWMA ì§€í‘œ (1ë¶„ ë°˜ê°ê¸°)
        self._last_tick = time.perf_counter()
        self._qps_ewma_1m = 0.0  # ì´ˆë‹¹ ì¿¼ë¦¬ ìˆ˜
        self._hit_rate_ewma_1m = 0.0  # íˆíŠ¸ìœ¨ ì¶”ì„¸

    def _tick_rate(self, hit_increment: int) -> None:
        """ì²˜ë¦¬ìœ¨ ë° íˆíŠ¸ìœ¨ EWMA ê°±ì‹  (ë‚´ë¶€ìš©, ë½ ë‚´ë¶€ì—ì„œ í˜¸ì¶œ)

        Args:
            hit_increment: íˆíŠ¸ ì¦ë¶„ (0 ë˜ëŠ” 1)
        """
        now = time.perf_counter()
        dt = max(1e-6, now - self._last_tick)

        # ìˆœê°„ ì²˜ë¦¬ìœ¨ (í˜¸ì¶œë‹¹)
        inst_qps = 1.0 / dt

        # 1ë¶„ EWMA (ë°˜ê°ê¸° 60ì´ˆ)
        alpha = 1 - math.exp(-dt / 60.0)
        self._qps_ewma_1m = (1 - alpha) * self._qps_ewma_1m + alpha * inst_qps
        self._hit_rate_ewma_1m = (
            (1 - alpha) * self._hit_rate_ewma_1m + alpha * hit_increment
        )

        self._last_tick = now

    def record_code_query(
        self, has_exact_match: bool, stage0_count: int, stage1_count: int
    ) -> None:
        """ì½”ë“œ ì¿¼ë¦¬ ê¸°ë¡

        Args:
            has_exact_match: ExactMatch íˆíŠ¸ ì—¬ë¶€
            stage0_count: Stage 0 í›„ë³´ ìˆ˜
            stage1_count: Stage 1 í›„ë³´ ìˆ˜
        """
        with self._lock:
            self.code_queries_total += 1
            hit_inc = 1 if has_exact_match else 0
            if has_exact_match:
                self.exact_match_hits_total += 1
            self.stage0_candidates_last = stage0_count
            self.stage1_candidates_last = stage1_count
            self._tick_rate(hit_inc)

    def record_rrf_fusion(self) -> None:
        """RRF ìœµí•© ì‚¬ìš© ê¸°ë¡"""
        with self._lock:
            self.rrf_fusion_used_total += 1

    def record_citation_forced(self) -> None:
        """Citation ê°•ì œ ê¸°ë¡"""
        with self._lock:
            self.citation_forced_total += 1

    def record_latency(self, latency_ms: float) -> None:
        """ê²€ìƒ‰ ì§€ì—°ì‹œê°„ ê¸°ë¡

        Args:
            latency_ms: ì§€ì—°ì‹œê°„ (ë°€ë¦¬ì´ˆ)
        """
        with self._lock:
            self.latency_samples.append(latency_ms)

    @contextmanager
    def measure_retrieval_latency(self) -> Iterator[None]:
        """ê²€ìƒ‰ ì§€ì—°ì‹œê°„ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €

        Example:
            with metrics.measure_retrieval_latency():
                results = retriever.search(query, top_k=10)
        """
        t0 = time.perf_counter_ns()
        try:
            yield
        finally:
            dt_ms = (time.perf_counter_ns() - t0) / 1_000_000
            self.record_latency(dt_ms)

    def get_metrics(self) -> dict:
        """ë©”íŠ¸ë¦­ ìŠ¤ëƒ…ìƒ· ë°˜í™˜ (ë½ í™€ë“œ ìµœì†Œí™”)

        Returns:
            dict: {
                code_queries_total, exact_match_hits_total, exact_match_hit_rate,
                stage0_candidates_last, stage1_candidates_last,
                rrf_fusion_used_total, citation_forced_total,
                retrieval_latency_ms_p50, retrieval_latency_ms_p95,
                qps_ewma_1m, hit_rate_ewma_1m
            }
        """
        # ë½ ë‚´ë¶€: ìŠ¤ëƒ…ìƒ·ë§Œ í™•ë³´í•˜ê³  ì¦‰ì‹œ í•´ì œ
        with self._lock:
            total = self.code_queries_total
            hits = self.exact_match_hits_total
            stage0 = self.stage0_candidates_last
            stage1 = self.stage1_candidates_last
            rrf = self.rrf_fusion_used_total
            cit = self.citation_forced_total
            samples = list(self.latency_samples)
            qps_ewma = self._qps_ewma_1m
            hit_ewma = self._hit_rate_ewma_1m

        # ë½ ë°–: ê³„ì‚° (ì •ë ¬/ë°±ë¶„ìœ„)
        hit_rate = (hits / total) if total > 0 else 0.0

        if samples:
            samples.sort()
            p50 = int(_percentile(samples, 0.50))
            p95 = int(_percentile(samples, 0.95))
        else:
            p50 = p95 = 0

        return {
            "code_queries_total": total,
            "exact_match_hits_total": hits,
            "exact_match_hit_rate": round(hit_rate, 3),
            "stage0_candidates_last": stage0,
            "stage1_candidates_last": stage1,
            "rrf_fusion_used_total": rrf,
            "citation_forced_total": cit,
            "retrieval_latency_ms_p50": p50,
            "retrieval_latency_ms_p95": p95,
            "qps_ewma_1m": round(qps_ewma, 2),
            "hit_rate_ewma_1m": round(hit_ewma, 3),
        }

    def to_prometheus_text(self) -> str:
        """í”„ë¡œë©”í…Œìš°ìŠ¤ í…ìŠ¤íŠ¸ í¬ë§·ìœ¼ë¡œ ë©”íŠ¸ë¦­ ë‚´ë³´ë‚´ê¸°

        Returns:
            str: í”„ë¡œë©”í…Œìš°ìŠ¤ ë©”íŠ¸ë¦­ í…ìŠ¤íŠ¸
        """
        m = self.get_metrics()
        lines = [
            "# HELP code_queries_total Total number of code queries",
            "# TYPE code_queries_total counter",
            f'code_queries_total {m["code_queries_total"]}',
            "",
            "# HELP exact_match_hits_total Total number of exact match hits",
            "# TYPE exact_match_hits_total counter",
            f'exact_match_hits_total {m["exact_match_hits_total"]}',
            "",
            "# HELP exact_match_hit_rate Exact match hit rate",
            "# TYPE exact_match_hit_rate gauge",
            f'exact_match_hit_rate {m["exact_match_hit_rate"]}',
            "",
            "# HELP stage0_candidates_last Last stage 0 candidates count",
            "# TYPE stage0_candidates_last gauge",
            f'stage0_candidates_last {m["stage0_candidates_last"]}',
            "",
            "# HELP stage1_candidates_last Last stage 1 candidates count",
            "# TYPE stage1_candidates_last gauge",
            f'stage1_candidates_last {m["stage1_candidates_last"]}',
            "",
            "# HELP rrf_fusion_used_total Total RRF fusion uses",
            "# TYPE rrf_fusion_used_total counter",
            f'rrf_fusion_used_total {m["rrf_fusion_used_total"]}',
            "",
            "# HELP citation_forced_total Total citation forced count",
            "# TYPE citation_forced_total counter",
            f'citation_forced_total {m["citation_forced_total"]}',
            "",
            "# HELP retrieval_latency_ms_p50 Retrieval latency p50 (ms)",
            "# TYPE retrieval_latency_ms_p50 gauge",
            f'retrieval_latency_ms_p50 {m["retrieval_latency_ms_p50"]}',
            "",
            "# HELP retrieval_latency_ms_p95 Retrieval latency p95 (ms)",
            "# TYPE retrieval_latency_ms_p95 gauge",
            f'retrieval_latency_ms_p95 {m["retrieval_latency_ms_p95"]}',
            "",
            "# HELP qps_ewma_1m Queries per second (1m EWMA)",
            "# TYPE qps_ewma_1m gauge",
            f'qps_ewma_1m {m["qps_ewma_1m"]}',
            "",
            "# HELP hit_rate_ewma_1m Hit rate (1m EWMA)",
            "# TYPE hit_rate_ewma_1m gauge",
            f'hit_rate_ewma_1m {m["hit_rate_ewma_1m"]}',
        ]
        return "\n".join(lines) + "\n"

    def reset(self) -> None:
        """ë©”íŠ¸ë¦­ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)"""
        with self._lock:
            self.code_queries_total = 0
            self.exact_match_hits_total = 0
            self.rrf_fusion_used_total = 0
            self.citation_forced_total = 0
            self.stage0_candidates_last = 0
            self.stage1_candidates_last = 0
            self.latency_samples.clear()
            self._last_tick = time.perf_counter()
            self._qps_ewma_1m = 0.0
            self._hit_rate_ewma_1m = 0.0
            logger.info("ğŸ“Š ë©”íŠ¸ë¦­ ì´ˆê¸°í™”ë¨")


# ì „ì—­ ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤
_metrics_instance = None
_metrics_lock = threading.Lock()


def get_metrics_collector() -> CodeSearchMetrics:
    """ì „ì—­ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í„´)

    Returns:
        CodeSearchMetrics: ì „ì—­ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
    """
    global _metrics_instance
    if _metrics_instance is None:
        with _metrics_lock:
            if _metrics_instance is None:
                _metrics_instance = CodeSearchMetrics(latency_window_size=2000)
                logger.info("ğŸ“Š CodeSearchMetrics v2.0 ì´ˆê¸°í™”ë¨ (ì‹±ê¸€í„´)")
    return _metrics_instance
