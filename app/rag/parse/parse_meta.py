"""
ë©”íƒ€ë°ì´í„° íŒŒì‹± ëª¨ë“ˆ
2025-10-26

ë¬¸ì„œ ë‚ ì§œì™€ ì¹´í…Œê³ ë¦¬ë¥¼ í‘œì¤€í™”í•©ë‹ˆë‹¤.

ê·œì¹™:
- ë‚ ì§œ: ê¸°ì•ˆì¼ì ìš°ì„ , ì‹œí–‰ì¼ì í´ë°±, ë‘˜ ë‹¤ í‘œì‹œ
- ì¹´í…Œê³ ë¦¬: ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜, "ì •ë³´ ì—†ìŒ" ëŒ€ì‹  "ë¯¸ë¶„ë¥˜" ì‚¬ìš©
"""

from pathlib import Path
from typing import Dict, Any, Tuple
import yaml

from app.core.logging import get_logger

logger = get_logger(__name__)


class MetaParser:
    """ë©”íƒ€ë°ì´í„° íŒŒì„œ"""

    def __init__(self, config_path: str = "config/document_processing.yaml"):
        """ì´ˆê¸°í™”

        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = self._load_config(config_path)

        # metadata ì„¹ì…˜ì—ì„œ ì„¤ì • ë¡œë“œ
        metadata_config = self.config.get("metadata", {})

        # ë‚ ì§œ ìš°ì„ ìˆœìœ„ (configì—ì„œ ë¡œë“œ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        self.date_priority = metadata_config.get(
            "date_priority",
            ["ì‹œí–‰ì¼ì", "ê¸°ì•ˆì¼ì", "ì‘ì„±ì¼ì", "ë³´ê³ ì¼ì", "íšŒì˜ì¼ì"],
        )

        # ì‘ì„±ì í•„ë“œ ìš°ì„ ìˆœìœ„
        self.author_fields = metadata_config.get(
            "author_fields", ["ê¸°ì•ˆì", "ì‘ì„±ì", "ë³´ê³ ì", "ê²€í† ì"]
        )

        # ë¶€ì„œ í•„ë“œ ìš°ì„ ìˆœìœ„
        self.department_fields = metadata_config.get(
            "department_fields", ["ê¸°ì•ˆë¶€ì„œ", "ì†Œì†", "ë¶€ì„œ"]
        )

        # ì‘ì„±ì Stoplist (ê¸°ì•ˆì ì˜¤ê²€ì¶œ ë°©ì§€)
        self.author_stoplist = metadata_config.get("author_stoplist", [])

        # ì¹´í…Œê³ ë¦¬ ê·œì¹™ (ì´ì „ í˜¸í™˜ì„± ìœ ì§€)
        self.category_rules = self.config.get("meta_parsing", {}).get(
            "category_rules", {}
        )
        self.default_category = self.config.get("meta_parsing", {}).get(
            "default_category", "ë¯¸ë¶„ë¥˜"
        )

        logger.info(
            f"ğŸ“‹ ë©”íƒ€ íŒŒì„œ ì´ˆê¸°í™”: ë‚ ì§œ ìš°ì„ ìˆœìœ„ {len(self.date_priority)}ê°œ, ì‘ì„±ì í•„ë“œ {len(self.author_fields)}ê°œ, Stoplist {len(self.author_stoplist)}ê°œ, ì¹´í…Œê³ ë¦¬ ê·œì¹™ {len(self.category_rules)}ê°œ"
        )

    def _validate_author(self, author: str) -> bool:
        """ì‘ì„±ì ì´ë¦„ ê²€ì¦ (í•œê¸€ 2~4ìŒì ˆ + Stoplist)

        Args:
            author: ì‘ì„±ì í›„ë³´ ë¬¸ìì—´

        Returns:
            ê²€ì¦ í†µê³¼ ì—¬ë¶€
        """
        if not author or not author.strip():
            return False

        author = author.strip()

        # Stoplist ì²´í¬
        if author in self.author_stoplist:
            logger.debug(f"ì‘ì„±ì Stoplist ì œì™¸: {author}")
            return False

        # í•œê¸€ 2~4ìŒì ˆë§Œ í—ˆìš© (ê³µë°± ì—†ì´)
        import re

        pattern = r"^[ê°€-í£]{2,4}$"
        if not re.match(pattern, author):
            logger.debug(f"ì‘ì„±ì íŒ¨í„´ ë¶ˆì¼ì¹˜ (í•œê¸€ 2~4ìŒì ˆ ì•„ë‹˜): {author}")
            return False

        return True

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ

        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ

        Returns:
            ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        try:
            config_file = Path(config_path)
            if not config_file.exists():
                logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                return {}

            with open(config_file, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
                logger.info(f"âœ“ ì„¤ì • ë¡œë“œ: {config_path}")
                return config

        except Exception as e:
            logger.error(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def parse_dates(self, metadata: Dict[str, Any]) -> Tuple[str, str]:
        """ë‚ ì§œ íŒŒì‹± ë° í‘œì¤€í™”

        Args:
            metadata: ë¬¸ì„œ ë©”íƒ€ë°ì´í„° (ê¸°ì•ˆì¼ì, ì‹œí–‰ì¼ì, ì‘ì„±ì¼ì ë“± í¬í•¨)

        Returns:
            (display_date, date_detail)
            - display_date: ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ëŒ€í‘œ ë‚ ì§œ (YYYY-MM-DD)
            - date_detail: "ê¸°ì•ˆì¼ì / ì‹œí–‰ì¼ì" í˜•ì‹
        """
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ëŒ€í‘œ ë‚ ì§œ ì„ íƒ
        display_date = None
        for date_key in self.date_priority:
            if date_key in metadata and metadata[date_key]:
                raw_date = metadata[date_key]
                # ë‚ ì§œ ì •ê·œí™” (ë²”ìœ„, ì‹œê°„ ì œê±°, í˜•ì‹ í‘œì¤€í™”)
                display_date = self._normalize_date(raw_date)
                break

        # ê¸°ì•ˆì¼ìì™€ ì‹œí–‰ì¼ìë¥¼ ëª¨ë‘ í‘œì‹œ
        draft_date = metadata.get("ê¸°ì•ˆì¼ì") or metadata.get("date")
        action_date = metadata.get("ì‹œí–‰ì¼ì")

        # ê° ë‚ ì§œë„ ì •ê·œí™”
        if draft_date:
            draft_date = self._normalize_date(draft_date)
        if action_date:
            action_date = self._normalize_date(action_date)

        if draft_date and action_date:
            date_detail = f"{draft_date} / {action_date}"
        elif draft_date:
            date_detail = draft_date
        elif action_date:
            date_detail = action_date
        else:
            date_detail = display_date or "ì •ë³´ ì—†ìŒ"

        display_date = display_date or "ì •ë³´ ì—†ìŒ"

        return display_date, date_detail

    def _normalize_date(self, date_str: str) -> str:
        """ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™” (YYYY-MM-DD í˜•ì‹)

        Args:
            date_str: ì›ë³¸ ë‚ ì§œ ë¬¸ìì—´

        Returns:
            ì •ê·œí™”ëœ ë‚ ì§œ (YYYY-MM-DD) ë˜ëŠ” ì›ë³¸
        """
        if not date_str or not isinstance(date_str, str):
            return date_str

        import re
        from datetime import datetime

        date_str = date_str.strip()

        # 1. ë²”ìœ„ í˜•ì‹ ì²˜ë¦¬ (YYYY-MM-DD ~ YYYY-MM-DD â†’ ì• ë‚ ì§œ ì±„íƒ)
        range_pattern = r"(\d{4}-\d{1,2}-\d{1,2})\s*~\s*\d{4}-\d{1,2}-\d{1,2}"
        range_match = re.search(range_pattern, date_str)
        if range_match:
            date_str = range_match.group(1)

        # 2. ì‹œê°„ ì œê±° (YYYY-MM-DD HH:MM:SS â†’ YYYY-MM-DD)
        date_str = re.sub(r"\s+\d{1,2}:\d{2}(:\d{2})?", "", date_str)

        # 3. YY. M. D. í˜•ì‹ â†’ YYYY-MM-DD
        # ì˜ˆ: "24. 10. 24" â†’ "2024-10-24"
        yy_pattern = r"(\d{2})\.\s*(\d{1,2})\.\s*(\d{1,2})"
        yy_match = re.search(yy_pattern, date_str)
        if yy_match:
            yy, mm, dd = yy_match.groups()
            # 2ìë¦¬ ì—°ë„ë¥¼ 4ìë¦¬ë¡œ ë³€í™˜ (20YYë¡œ ê°€ì •)
            yyyy = f"20{yy}"
            return f"{yyyy}-{mm.zfill(2)}-{dd.zfill(2)}"

        # 4. YYYY-M-D ë˜ëŠ” YYYY.M.D â†’ YYYY-MM-DD
        date_str = re.sub(r"(\d{4})[./](\d{1,2})[./](\d{1,2})", r"\1-\2-\3", date_str)

        # 5. íŒ¨ë”© (YYYY-M-D â†’ YYYY-MM-DD)
        padding_pattern = r"(\d{4})-(\d{1,2})-(\d{1,2})"
        padding_match = re.search(padding_pattern, date_str)
        if padding_match:
            yyyy, mm, dd = padding_match.groups()
            return f"{yyyy}-{mm.zfill(2)}-{dd.zfill(2)}"

        # 6. ê²€ì¦ ë° ë°˜í™˜
        try:
            # YYYY-MM-DD í˜•ì‹ ê²€ì¦
            datetime.strptime(date_str, "%Y-%m-%d")
            return date_str
        except ValueError:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            logger.debug(f"ë‚ ì§œ ì •ê·œí™” ì‹¤íŒ¨ (ì›ë³¸ ë°˜í™˜): {date_str}")
            return date_str

    def classify_category(
        self, title: str = "", content: str = "", filename: str = ""
    ) -> Tuple[str, str]:
        """ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜

        Args:
            title: ë¬¸ì„œ ì œëª©
            content: ë¬¸ì„œ ë‚´ìš©
            filename: íŒŒì¼ëª…

        Returns:
            (category, source)
            - category: ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬
            - source: ë¶„ë¥˜ ë°©ë²• ("rule", "ml", "default")
        """
        # ë¶„ë¥˜ ëŒ€ìƒ í…ìŠ¤íŠ¸ (ì œëª© > íŒŒì¼ëª… > ë‚´ìš©)
        search_text = f"{title} {filename} {content[:500]}"
        search_text = search_text.lower()

        matched_categories = []

        # 1. ë¬¸ì„œ ìœ í˜• ê·œì¹™ ì ìš© (ìš°ì„ ìˆœìœ„ 1)
        doc_type_rules = self.category_rules.get("document_type", [])
        for rule in doc_type_rules:
            keywords = rule.get("keywords", [])
            category = rule.get("category", "")

            if any(kw in search_text for kw in keywords):
                matched_categories.append(category)
                logger.debug(f"âœ“ ë¬¸ì„œ ìœ í˜• ë§¤ì¹­: {category} (í‚¤ì›Œë“œ: {keywords})")

        # 2. ì¥ë¹„ ë¶„ë¥˜ ê·œì¹™ ì ìš© (ìš°ì„ ìˆœìœ„ 2)
        equipment_rules = self.category_rules.get("equipment_type", [])
        for rule in equipment_rules:
            keywords = rule.get("keywords", [])
            category = rule.get("category", "")

            if any(kw in search_text for kw in keywords):
                matched_categories.append(category)
                logger.debug(f"âœ“ ì¥ë¹„ ë¶„ë¥˜ ë§¤ì¹­: {category} (í‚¤ì›Œë“œ: {keywords})")

        # 3. ì¹´í…Œê³ ë¦¬ ì¡°í•©
        if matched_categories:
            # ì¤‘ë³µ ì œê±°í•˜ê³  ìˆœì„œ ìœ ì§€
            unique_categories = list(dict.fromkeys(matched_categories))
            combined_category = " / ".join(unique_categories)
            return combined_category, "rule"

        # 4. ML ë¶„ë¥˜ (í–¥í›„ êµ¬í˜„)
        # TODO: ML ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¶”ê°€

        # 5. ê¸°ë³¸ ì¹´í…Œê³ ë¦¬
        return self.default_category, "default"

    def parse(
        self, metadata: Dict[str, Any], title: str = "", content: str = ""
    ) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° íŒŒì‹± ë° í‘œì¤€í™”

        Args:
            metadata: ì›ë³¸ ë©”íƒ€ë°ì´í„°
            title: ë¬¸ì„œ ì œëª©
            content: ë¬¸ì„œ ë‚´ìš©

        Returns:
            í‘œì¤€í™”ëœ ë©”íƒ€ë°ì´í„°
        """
        # ë‚ ì§œ íŒŒì‹±
        display_date, date_detail = self.parse_dates(metadata)

        # ì‘ì„±ì ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
        author = None
        for field in self.author_fields:
            if field in metadata and metadata[field]:
                candidate = metadata[field]
                # ì‘ì„±ì ê²€ì¦ (í•œê¸€ 2~4ìŒì ˆ + Stoplist)
                if self._validate_author(candidate):
                    author = candidate
                    break
        author = author or metadata.get("drafter") or "ì •ë³´ ì—†ìŒ"

        # ë¶€ì„œ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
        department = None
        for field in self.department_fields:
            if field in metadata and metadata[field]:
                department = metadata[field]
                break
        department = department or metadata.get("department") or "ì •ë³´ ì—†ìŒ"

        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        filename = metadata.get("filename", "")
        category, category_source = self.classify_category(title, content, filename)

        # í‘œì¤€í™”ëœ ë©”íƒ€ë°ì´í„° êµ¬ì„±
        standardized = {
            "drafter": author,
            "department": department,
            "doc_number": metadata.get("doc_number")
            or metadata.get("ë¬¸ì„œë²ˆí˜¸")
            or "ì •ë³´ ì—†ìŒ",
            "retention": metadata.get("retention")
            or metadata.get("ë³´ì¡´ê¸°ê°„")
            or "ì •ë³´ ì—†ìŒ",
            "display_date": display_date,
            "date_detail": date_detail,
            "category": category,
            "category_source": category_source,
            "filename": filename,
        }

        # "ì •ë³´ ì—†ìŒ"ì„ ë¯¸ë¶„ë¥˜ë¡œ ë³€ê²½ (ì¹´í…Œê³ ë¦¬ë§Œ)
        if standardized["category"] == "ì •ë³´ ì—†ìŒ":
            standardized["category"] = self.default_category

        logger.debug(
            f"ğŸ“‹ ë©”íƒ€ íŒŒì‹± ì™„ë£Œ: author={author}, category={category} (source={category_source}), date={date_detail}"
        )

        return standardized

    def format_meta_display(self, parsed_meta: Dict[str, Any]) -> str:
        """ë©”íƒ€ë°ì´í„° í‘œì‹œ í˜•ì‹ ìƒì„±

        Args:
            parsed_meta: íŒŒì‹±ëœ ë©”íƒ€ë°ì´í„°

        Returns:
            Markdown í˜•ì‹ì˜ ë©”íƒ€ë°ì´í„° ë¬¸ìì—´
        """
        lines = []
        lines.append(
            f"**ê¸°ì•ˆì/ë¶€ì„œ:** {parsed_meta['drafter']} / {parsed_meta['department']}"
        )
        lines.append(f"**ê¸°ì•ˆì¼ì / ì‹œí–‰ì¼ì:** {parsed_meta['date_detail']}")
        lines.append(f"**ìœ í˜•/ì¹´í…Œê³ ë¦¬:** {parsed_meta['category']}")

        # ì„ íƒì  í•„ë“œ
        if parsed_meta.get("doc_number") and parsed_meta["doc_number"] != "ì •ë³´ ì—†ìŒ":
            lines.append(f"**ë¬¸ì„œë²ˆí˜¸:** {parsed_meta['doc_number']}")

        if parsed_meta.get("retention") and parsed_meta["retention"] != "ì •ë³´ ì—†ìŒ":
            lines.append(f"**ë³´ì¡´ê¸°ê°„:** {parsed_meta['retention']}")

        return "\n".join(lines)
