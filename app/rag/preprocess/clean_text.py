"""
í…ìŠ¤íŠ¸ ë…¸ì´ì¦ˆ ì œê±° ëª¨ë“ˆ
2025-10-26

ë¬¸ì„œì—ì„œ í”„ë¦°íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„, URL, ë°˜ë³µ í—¤ë”/í‘¸í„° ë“±ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.
"""

import re
from collections import Counter
from pathlib import Path
from typing import List, Dict, Any, Tuple
import yaml

from app.core.logging import get_logger

logger = get_logger(__name__)


class TextCleaner:
    """í…ìŠ¤íŠ¸ ë…¸ì´ì¦ˆ ì œê±° í´ë˜ìŠ¤"""

    def __init__(self, config_path: str = "config/document_processing.yaml"):
        """ì´ˆê¸°í™”

        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = self._load_config(config_path)
        self.noise_patterns = self._compile_patterns()
        self.deduplicate_lines = self.config.get("text_cleaning", {}).get(
            "deduplicate_lines", True
        )
        self.max_duplicate_threshold = self.config.get("text_cleaning", {}).get(
            "max_duplicate_threshold", 2
        )
        self.min_repeat_for_noise = self.config.get("text_cleaning", {}).get(
            "min_repeat_for_noise", 3
        )

        logger.info(
            f"ğŸ§¹ í…ìŠ¤íŠ¸ í´ë¦¬ë„ˆ ì´ˆê¸°í™”: {len(self.noise_patterns)}ê°œ ë…¸ì´ì¦ˆ íŒ¨í„´ ë¡œë“œ"
        )

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ

        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ

        Returns:
            ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        try:
            config_file = Path(config_path)
            if not config_file.exists():
                logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                return {}

            with open(config_file, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
                logger.info(f"âœ“ ì„¤ì • ë¡œë“œ: {config_path}")
                return config

        except Exception as e:
            logger.error(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def _compile_patterns(self) -> List[Tuple[re.Pattern, str]]:
        """ë…¸ì´ì¦ˆ íŒ¨í„´ ì»´íŒŒì¼

        Returns:
            (ì»´íŒŒì¼ëœ íŒ¨í„´, ì„¤ëª…) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        patterns = []
        noise_config = self.config.get("text_cleaning", {}).get("noise_patterns", [])

        for pattern_config in noise_config:
            pattern_str = pattern_config.get("pattern")
            description = pattern_config.get("description", "unknown")

            try:
                compiled = re.compile(pattern_str)
                patterns.append((compiled, description))
                logger.debug(f"âœ“ íŒ¨í„´ ì»´íŒŒì¼: {description} - {pattern_str}")
            except re.error as e:
                logger.error(f"âŒ íŒ¨í„´ ì»´íŒŒì¼ ì‹¤íŒ¨: {pattern_str} - {e}")

        return patterns

    def clean(self, text: str) -> Tuple[str, Dict[str, int]]:
        """í…ìŠ¤íŠ¸ ë…¸ì´ì¦ˆ ì œê±°

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸

        Returns:
            (ì •ë¦¬ëœ í…ìŠ¤íŠ¸, ë…¸ì´ì¦ˆ ì¹´ìš´íŠ¸ ë”•ì…”ë„ˆë¦¬)
        """
        if not text:
            return "", {}

        lines = text.split("\n")
        noise_counts = {}

        # 1. íŒ¨í„´ ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°
        lines, pattern_counts = self._remove_pattern_noise(lines)
        noise_counts.update(pattern_counts)

        # 2. ë¹ˆë„ ê¸°ë°˜ ë°˜ë³µ í—¤ë”/í‘¸í„° ì œê±°
        lines, repeat_count = self._remove_repeated_lines(lines)
        noise_counts["repeated_headers_footers"] = repeat_count

        # 3. ì¤‘ë³µ ë¼ì¸ ì œê±° (ì„ íƒì )
        if self.deduplicate_lines:
            lines, dedup_count = self._deduplicate_consecutive_lines(lines)
            noise_counts["deduplicated_lines"] = dedup_count

        # 4. ë¹ˆ ë¼ì¸ ì •ë¦¬ (ì—°ì†ëœ ë¹ˆ ë¼ì¸ì„ í•˜ë‚˜ë¡œ)
        lines = self._normalize_blank_lines(lines)

        cleaned_text = "\n".join(lines)

        logger.debug(f"ğŸ§¹ ì •ë¦¬ ì™„ë£Œ: {sum(noise_counts.values())}ê°œ ë…¸ì´ì¦ˆ ì œê±°")

        return cleaned_text, noise_counts

    def _remove_pattern_noise(
        self, lines: List[str]
    ) -> Tuple[List[str], Dict[str, int]]:
        """íŒ¨í„´ ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°

        Args:
            lines: ì›ë³¸ ë¼ì¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ì •ë¦¬ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸, íŒ¨í„´ë³„ ì¹´ìš´íŠ¸)
        """
        counts = {desc: 0 for _, desc in self.noise_patterns}
        cleaned_lines = []

        for line in lines:
            is_noise = False

            for pattern, description in self.noise_patterns:
                if pattern.search(line):
                    counts[description] += 1
                    is_noise = True
                    break

            if not is_noise:
                cleaned_lines.append(line)

        return cleaned_lines, counts

    def _remove_repeated_lines(self, lines: List[str]) -> Tuple[List[str], int]:
        """ë¹ˆë„ ê¸°ë°˜ ë°˜ë³µ í—¤ë”/í‘¸í„° ì œê±°

        3íšŒ ì´ìƒ ë°˜ë³µë˜ëŠ” ë¼ì¸ì€ ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ê³  ì œê±°

        Args:
            lines: ì›ë³¸ ë¼ì¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ì •ë¦¬ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸, ì œê±°ëœ ë¼ì¸ ìˆ˜)
        """
        # ë¹ˆ ë¼ì¸ê³¼ ë„ˆë¬´ ì§§ì€ ë¼ì¸ì€ ì œì™¸
        non_empty_lines = [line.strip() for line in lines if len(line.strip()) > 5]

        # ë¹ˆë„ ê³„ì‚°
        line_counts = Counter(non_empty_lines)

        # ë°˜ë³µ ë¼ì¸ ì‹ë³„ (min_repeat_for_noiseíšŒ ì´ìƒ)
        repeated_lines = {
            line
            for line, count in line_counts.items()
            if count >= self.min_repeat_for_noise
        }

        if not repeated_lines:
            return lines, 0

        logger.debug(
            f"ğŸ” ë°˜ë³µ ë¼ì¸ {len(repeated_lines)}ê°œ ë°œê²¬: {list(repeated_lines)[:3]}..."
        )

        # ë°˜ë³µ ë¼ì¸ ì œê±°
        cleaned_lines = []
        removed_count = 0

        for line in lines:
            stripped = line.strip()
            if stripped in repeated_lines:
                removed_count += 1
            else:
                cleaned_lines.append(line)

        return cleaned_lines, removed_count

    def _deduplicate_consecutive_lines(self, lines: List[str]) -> Tuple[List[str], int]:
        """ì—°ì†ëœ ì¤‘ë³µ ë¼ì¸ ì œê±°

        ë™ì¼í•œ ë¼ì¸ì´ ì—°ì†í•´ì„œ ë‚˜íƒ€ë‚˜ë©´ max_duplicate_thresholdê°œê¹Œì§€ë§Œ ìœ ì§€

        Args:
            lines: ì›ë³¸ ë¼ì¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ì •ë¦¬ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸, ì œê±°ëœ ë¼ì¸ ìˆ˜)
        """
        if not lines:
            return lines, 0

        cleaned_lines = []
        removed_count = 0
        current_line = None
        consecutive_count = 0

        for line in lines:
            if line == current_line:
                consecutive_count += 1
                if consecutive_count <= self.max_duplicate_threshold:
                    cleaned_lines.append(line)
                else:
                    removed_count += 1
            else:
                current_line = line
                consecutive_count = 1
                cleaned_lines.append(line)

        return cleaned_lines, removed_count

    def _normalize_blank_lines(self, lines: List[str]) -> List[str]:
        """ì—°ì†ëœ ë¹ˆ ë¼ì¸ì„ í•˜ë‚˜ë¡œ ì •ë¦¬

        Args:
            lines: ì›ë³¸ ë¼ì¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì •ë¦¬ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        """
        cleaned_lines = []
        prev_blank = False

        for line in lines:
            is_blank = not line.strip()

            if is_blank:
                if not prev_blank:
                    cleaned_lines.append("")
                prev_blank = True
            else:
                cleaned_lines.append(line)
                prev_blank = False

        # ì•ë’¤ ë¹ˆ ë¼ì¸ ì œê±°
        while cleaned_lines and not cleaned_lines[0].strip():
            cleaned_lines.pop(0)
        while cleaned_lines and not cleaned_lines[-1].strip():
            cleaned_lines.pop()

        return cleaned_lines

    def get_stats(self, noise_counts: Dict[str, int]) -> str:
        """ë…¸ì´ì¦ˆ ì œê±° í†µê³„ ë¬¸ìì—´ ìƒì„±

        Args:
            noise_counts: ë…¸ì´ì¦ˆ ì¹´ìš´íŠ¸ ë”•ì…”ë„ˆë¦¬

        Returns:
            í†µê³„ ë¬¸ìì—´
        """
        total = sum(noise_counts.values())
        if total == 0:
            return "ë…¸ì´ì¦ˆ ì—†ìŒ"

        stats = f"ì´ {total}ê°œ ë…¸ì´ì¦ˆ ì œê±°: "
        parts = [f"{desc}={count}" for desc, count in noise_counts.items() if count > 0]
        stats += ", ".join(parts)

        return stats
