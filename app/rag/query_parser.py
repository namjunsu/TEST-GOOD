"""
ì¿¼ë¦¬ íŒŒì‹± ëª¨ë“ˆ - Closed-World Validation
ê¸°ì•ˆì/ì—°ë„ ì¶”ì¶œì„ ë©”íƒ€ë°ì´í„° DB ê¸°ë°˜ìœ¼ë¡œ ê²€ì¦
"""

import re
import yaml
from pathlib import Path
from typing import Optional, Dict, Set
from difflib import SequenceMatcher
import logging

logger = logging.getLogger(__name__)

# ì„¤ì • ë¡œë“œ
CONFIG_PATH = Path(__file__).parent.parent.parent / "config" / "filters.yaml"


class QueryParser:
    """ì¿¼ë¦¬ íŒŒì„œ - Closed-World Validation ì ìš©"""

    def __init__(self, known_drafters: Set[str]):
        """
        Args:
            known_drafters: DBì—ì„œ ë¡œë“œí•œ ê³ ìœ  ê¸°ì•ˆì ì§‘í•©
        """
        self.known_drafters = known_drafters
        self.stopwords = self._load_stopwords()
        self.token_patterns = self._load_token_patterns()

        logger.info(f"âœ… QueryParser ì´ˆê¸°í™”: {len(known_drafters)}ëª… ê¸°ì•ˆì, {len(self.stopwords)}ê°œ ë¶ˆìš©ì–´")

    def _load_stopwords(self) -> Set[str]:
        """ë¶ˆìš©ì–´ ë¡œë“œ"""
        try:
            with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return set(config.get('drafter_stopwords', []))
        except Exception as e:
            logger.warning(f"ë¶ˆìš©ì–´ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            return {'ë¬¸ì„œ', 'ìë£Œ', 'íŒŒì¼', 'ë³´ê³ ì„œ', 'ì „ì²´', 'ëª¨ë“ '}

    def _load_token_patterns(self) -> Dict[str, str]:
        """í† í° íŒ¨í„´ ë¡œë“œ"""
        try:
            with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config.get('query_tokens', {})
        except Exception as e:
            logger.warning(f"í† í° íŒ¨í„´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def parse_filters(self, query: str) -> Dict[str, Optional[str]]:
        """ì¿¼ë¦¬ì—ì„œ í•„í„° ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: í† í° > Closed-World > íŒ¨í„´)

        Args:
            query: ì‚¬ìš©ì ì§ˆì˜

        Returns:
            dict: {"year": str, "drafter": str, "source": str}
        """
        result = {
            "year": None,
            "drafter": None,
            "source": None
        }

        # 1ë‹¨ê³„: í† í° íŒ¨í„´ ìš°ì„  ì¶”ì¶œ
        token_result = self._extract_from_tokens(query)
        if token_result['year'] or token_result['drafter']:
            result.update(token_result)
            result['source'] = 'token'
            logger.info(f"ğŸ¯ í† í° íŒŒì‹±: year={result['year']}, drafter={result['drafter']}")
            return result

        # 2ë‹¨ê³„: ì—°ë„ ì¶”ì¶œ
        result['year'] = self._extract_year(query)

        # 3ë‹¨ê³„: ê¸°ì•ˆì ì¶”ì¶œ (Closed-World Validation)
        drafter, source = self._extract_drafter_closed_world(query)
        result['drafter'] = drafter
        result['source'] = source

        logger.info(f"ğŸ“‹ íŒŒì‹± ê²°ê³¼: year={result['year']}, drafter={result['drafter']}, source={result['source']}")
        return result

    def _extract_from_tokens(self, query: str) -> Dict[str, Optional[str]]:
        """í† í° ë¬¸ë²• ì¶”ì¶œ (year:2024, drafter:ìµœìƒˆë¦„)"""
        result = {"year": None, "drafter": None}

        # year: í† í°
        if 'year' in self.token_patterns:
            match = re.search(self.token_patterns['year'], query, re.IGNORECASE)
            if match:
                result['year'] = match.group(1)

        # drafter: í† í°
        if 'drafter' in self.token_patterns:
            match = re.search(self.token_patterns['drafter'], query, re.IGNORECASE)
            if match:
                drafter_raw = match.group(1).strip()
                # ê³µë°± ì •ê·œí™”
                drafter_normalized = self._normalize_name(drafter_raw)
                if drafter_normalized in self.known_drafters:
                    result['drafter'] = drafter_normalized

        return result

    def _extract_year(self, query: str) -> Optional[str]:
        """ì—°ë„ ì¶”ì¶œ"""
        match = re.search(r'(\d{4})ë…„?', query)
        return match.group(1) if match else None

    def _extract_drafter_closed_world(self, query: str) -> tuple[Optional[str], str]:
        """ê¸°ì•ˆì ì¶”ì¶œ - Closed-World Validation

        Returns:
            (drafter, source): (ê¸°ì•ˆìëª…, ì¶œì²˜: 'closed_world'|'fuzzy'|None)
        """
        # 1. í•œê¸€ 2-4ì í† í° í›„ë³´ ì¶”ì¶œ
        candidates = re.findall(r'[ê°€-í£]{2,4}', query)

        # 2. ë¶ˆìš©ì–´ ì œê±°
        candidates = [c for c in candidates if c not in self.stopwords]

        if not candidates:
            return None, None

        # 3. Exact Match (ë‹«íŒ ì§‘í•© ê²€ì¦)
        for candidate in candidates:
            if candidate in self.known_drafters:
                logger.info(f"âœ… ê¸°ì•ˆì ì •í™• ë§¤ì¹­: {candidate}")
                return candidate, 'closed_world'

        # 4. Fuzzy Match (í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜, ê³µë°± ì •ê·œí™”)
        for candidate in candidates:
            normalized = self._normalize_name(candidate)
            if normalized in self.known_drafters:
                logger.info(f"âœ… ê¸°ì•ˆì ì •ê·œí™” ë§¤ì¹­: {candidate} â†’ {normalized}")
                return normalized, 'closed_world'

            # ìœ ì‚¬ë„ ë§¤ì¹­ (threshold = 0.85)
            match = self._fuzzy_match(normalized, self.known_drafters, threshold=0.85)
            if match:
                logger.info(f"âœ… ê¸°ì•ˆì ìœ ì‚¬ë„ ë§¤ì¹­: {candidate} â†’ {match}")
                return match, 'fuzzy'

        # 5. ë§¤ì¹­ ì‹¤íŒ¨
        logger.info(f"âš ï¸ ê¸°ì•ˆì í›„ë³´ '{candidates}'ëŠ” KNOWN_DRAFTERSì— ì—†ìŒ â†’ None")
        return None, None

    def _normalize_name(self, name: str) -> str:
        """ì´ë¦„ ì •ê·œí™” (ê³µë°± ì œê±°, ì˜ë¬¸ ì†Œë¬¸ìí™”)"""
        # ê³µë°± ì œê±°
        name = name.replace(' ', '')
        # ì˜ë¬¸ ì†Œë¬¸ìí™”
        return name.lower()

    def _fuzzy_match(self, query: str, candidates: Set[str], threshold: float = 0.85) -> Optional[str]:
        """ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­

        Args:
            query: ê²€ìƒ‰ ë¬¸ìì—´
            candidates: í›„ë³´ ì§‘í•©
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0-1.0)

        Returns:
            ê°€ì¥ ìœ ì‚¬í•œ í›„ë³´ ë˜ëŠ” None
        """
        best_match = None
        best_score = 0.0

        query_normalized = self._normalize_name(query)

        for candidate in candidates:
            candidate_normalized = self._normalize_name(candidate)
            score = SequenceMatcher(None, query_normalized, candidate_normalized).ratio()

            if score > best_score and score >= threshold:
                best_score = score
                best_match = candidate

        return best_match


def parse_filters_simple(query: str, known_drafters: Set[str]) -> Dict[str, Optional[str]]:
    """ê°„ë‹¨í•œ íŒŒì‹± í•¨ìˆ˜ (í•¨ìˆ˜í˜• API)

    Args:
        query: ì‚¬ìš©ì ì§ˆì˜
        known_drafters: ê³ ìœ  ê¸°ì•ˆì ì§‘í•©

    Returns:
        {"year": str, "drafter": str, "source": str}
    """
    parser = QueryParser(known_drafters)
    return parser.parse_filters(query)