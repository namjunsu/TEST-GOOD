"""ì •í™•ì¼ì¹˜ ê²€ìƒ‰ê¸° (Stage 0 - ëª¨ë¸/ë¶€í’ˆ ì½”ë“œ ì „ìš©)

model_codes í…Œì´ë¸”ì„ í™œìš©í•œ ì •í™•ì¼ì¹˜ ê²€ìƒ‰
- ì½”ë“œ ë³€í˜•(hyphen/space/no-space) ìë™ í™•ì¥
- íŒŒì¼ëª… ì •í™•/ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
- ê°€ì¤‘ì¹˜: exact_code=+3.0, filename_hit=+1.0
"""

from typing import List, Dict, Any, Tuple, Set
from app.core.logging import get_logger
from modules.metadata_db import MetadataDB

logger = get_logger(__name__)

# normalizer ì„í¬íŠ¸ (fallback ì²˜ë¦¬)
try:
    from app.textproc.normalizer import extract_codes, normalize_code, generate_variants
    NORMALIZER_AVAILABLE = True
except ImportError:
    logger.warning("âš ï¸ normalizer ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ExactMatchRetriever ë¹„í™œì„±í™”)")
    NORMALIZER_AVAILABLE = False

    def extract_codes(text: str, normalize_result: bool = True) -> List[str]:
        return []

    def normalize_code(code: str, uppercase: bool = True) -> str:
        return code.upper()

    def generate_variants(code: str) -> List[str]:
        return [code]


class ExactMatchRetriever:
    """ì •í™•ì¼ì¹˜ ê²€ìƒ‰ê¸° (Stage 0)

    ëª¨ë¸/ë¶€í’ˆ ì½”ë“œ ê²€ìƒ‰ì„ ìœ„í•œ ì •í™•ì¼ì¹˜ ë ˆì´ì–´
    - model_codes í…Œì´ë¸”ì—ì„œ norm_code ê¸°ë°˜ ê²€ìƒ‰
    - íŒŒì¼ëª… ì •í™•/ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
    - ìŠ¤ì½”ì–´ ë¶€ìŠ¤íŒ…ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì¡°ì •
    """

    # ìŠ¤ì½”ì–´ ê°€ì¤‘ì¹˜
    EXACT_CODE_WEIGHT = 3.0      # model_codes í…Œì´ë¸”ì—ì„œ ì •í™•ì¼ì¹˜
    FILENAME_HIT_WEIGHT = 1.0    # íŒŒì¼ëª…ì— ì½”ë“œ í¬í•¨

    def __init__(self, db: MetadataDB = None):
        """ì´ˆê¸°í™”

        Args:
            db: MetadataDB ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
        """
        self.db = db or MetadataDB()
        self.enabled = NORMALIZER_AVAILABLE

        if not self.enabled:
            logger.warning("âš ï¸ ExactMatchRetriever ë¹„í™œì„±í™” (normalizer ì—†ìŒ)")
        else:
            logger.info("âœ… ExactMatchRetriever ì´ˆê¸°í™” ì™„ë£Œ")

    def search_codes(self, query: str) -> List[Tuple[int, float, str]]:
        """ì½”ë“œ ê¸°ë°˜ ì •í™•ì¼ì¹˜ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜ (ì˜ˆ: "XRN-1620B2 ë§¤ë‰´ì–¼")

        Returns:
            List of (doc_id, score, match_type):
            - doc_id: documents.id
            - score: ê°€ì¤‘ì¹˜ ì ìˆ˜
            - match_type: 'exact_code' | 'filename'
        """
        if not self.enabled:
            return []

        # 1. ì¿¼ë¦¬ì—ì„œ ì½”ë“œ ì¶”ì¶œ
        codes = extract_codes(query, normalize_result=True)

        if not codes:
            logger.debug("ì½”ë“œ íŒ¨í„´ ì—†ìŒ - ExactMatch ê±´ë„ˆë›°ê¸°")
            return []

        logger.info(f"ğŸ¯ ExactMatch: ì½”ë“œ ì¶”ì¶œ = {codes}")

        # 2. ì½”ë“œ ë³€í˜• ìƒì„± (hyphen/space/no-space)
        all_variants = set()
        for code in codes:
            variants = generate_variants(code)
            all_variants.update(variants)

        logger.debug(f"ì½”ë“œ ë³€í˜• ìƒì„±: {all_variants}")

        # 3. model_codes í…Œì´ë¸”ì—ì„œ ì •í™•ì¼ì¹˜ ê²€ìƒ‰
        exact_matches = self._query_model_codes(all_variants)

        # 4. íŒŒì¼ëª… ì¼ì¹˜ ê²€ìƒ‰ (model_codesì— ì—†ëŠ” ê²½ìš° ë³´ì™„)
        filename_matches = self._query_filename_matches(all_variants)

        # 5. ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
        results = self._merge_results(exact_matches, filename_matches)

        logger.info(f"ğŸ“Š ExactMatch: {len(results)}ê±´ (exact={len(exact_matches)}, filename={len(filename_matches)})")

        return results

    def _query_model_codes(self, variants: Set[str]) -> List[Tuple[int, float, str]]:
        """model_codes í…Œì´ë¸”ì—ì„œ ì •í™•ì¼ì¹˜ ê²€ìƒ‰ (Patch B: LIKE í™•ì¥ ì¶”ê°€)

        Args:
            variants: ì •ê·œí™”ëœ ì½”ë“œ ë³€í˜• ì§‘í•©

        Returns:
            List of (doc_id, score, 'exact_code')
        """
        if not variants:
            return []

        try:
            conn = self.db._get_conn()
            doc_ids_found = set()

            # 1. ì •í™•ì¼ì¹˜ (IN ì¿¼ë¦¬)
            placeholders = ','.join(['?'] * len(variants))
            query_exact = f"""
                SELECT DISTINCT doc_id
                FROM model_codes
                WHERE norm_code IN ({placeholders})
            """
            cursor = conn.execute(query_exact, list(variants))
            rows = cursor.fetchall()

            for row in rows:
                doc_ids_found.add(row[0])

            # 2. LIKE í™•ì¥ (Patch B: ë¶€ë¶„ ì¼ì¹˜ë¡œ ì¬í˜„ìœ¨ ì¦ëŒ€)
            for variant in variants:
                query_like = """
                    SELECT DISTINCT doc_id
                    FROM model_codes
                    WHERE norm_code LIKE ?
                """
                cursor = conn.execute(query_like, (f'%{variant}%',))
                rows = cursor.fetchall()

                for row in rows:
                    doc_ids_found.add(row[0])

            # (doc_id, score, match_type)
            results = [(doc_id, self.EXACT_CODE_WEIGHT, 'exact_code') for doc_id in doc_ids_found]

            logger.debug(f"model_codes ì¼ì¹˜: {len(results)}ê±´ (exact + LIKE í™•ì¥)")
            return results

        except Exception as e:
            logger.error(f"model_codes ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _query_filename_matches(self, variants: Set[str]) -> List[Tuple[int, float, str]]:
        """íŒŒì¼ëª…ì—ì„œ ì½”ë“œ ì¼ì¹˜ ê²€ìƒ‰

        Args:
            variants: ì •ê·œí™”ëœ ì½”ë“œ ë³€í˜• ì§‘í•©

        Returns:
            List of (doc_id, score, 'filename')
        """
        if not variants:
            return []

        try:
            conn = self.db._get_conn()
            results = []

            # ê° ë³€í˜•ì— ëŒ€í•´ LIKE ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            for variant in variants:
                query = """
                    SELECT DISTINCT id
                    FROM documents
                    WHERE UPPER(filename) LIKE ?
                """

                # ë³€í˜•ì˜ ëŒ€ì†Œë¬¸ì ë²„ì „ë“¤ ëª¨ë‘ ì‹œë„
                patterns = [
                    f"%{variant}%",
                    f"%{variant.lower()}%",
                    f"%{variant.upper()}%"
                ]

                for pattern in patterns:
                    cursor = conn.execute(query, (pattern,))
                    rows = cursor.fetchall()

                    for row in rows:
                        results.append((row[0], self.FILENAME_HIT_WEIGHT, 'filename'))

            logger.debug(f"filename ì¼ì¹˜: {len(results)}ê±´")
            return results

        except Exception as e:
            logger.error(f"filename ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _merge_results(
        self,
        exact_matches: List[Tuple[int, float, str]],
        filename_matches: List[Tuple[int, float, str]]
    ) -> List[Tuple[int, float, str]]:
        """ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°

        - exact_codeê°€ ìš°ì„ ìˆœìœ„ (filenameê³¼ ì¤‘ë³µë˜ë©´ exact_code ì±„íƒ)
        - doc_idë³„ë¡œ ìµœê³  ì ìˆ˜ ìœ ì§€

        Args:
            exact_matches: model_codes ì¼ì¹˜
            filename_matches: filename ì¼ì¹˜

        Returns:
            List of (doc_id, score, match_type) - doc_id ê¸°ì¤€ ì •ë ¬
        """
        # doc_id -> (score, match_type)
        doc_scores: Dict[int, Tuple[float, str]] = {}

        # exact_code ë¨¼ì € ì¶”ê°€ (ìµœìš°ì„ )
        for doc_id, score, match_type in exact_matches:
            if doc_id not in doc_scores:
                doc_scores[doc_id] = (score, match_type)
            else:
                # ë” ë†’ì€ ì ìˆ˜ë¡œ ê°±ì‹  (ë™ì¼ ì†ŒìŠ¤ ì¤‘ë³µì‹œ)
                if score > doc_scores[doc_id][0]:
                    doc_scores[doc_id] = (score, match_type)

        # filename ì¶”ê°€ (exact_codeê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
        for doc_id, score, match_type in filename_matches:
            if doc_id not in doc_scores:
                doc_scores[doc_id] = (score, match_type)

        # (doc_id, score, match_type) íŠœí”Œë¡œ ë³€í™˜ ë° ì •ë ¬
        results = [(doc_id, score, match_type) for doc_id, (score, match_type) in doc_scores.items()]
        results.sort(key=lambda x: (-x[1], x[0]))  # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ, doc_id ì˜¤ë¦„ì°¨ìˆœ

        return results

    def get_documents_by_ids(self, doc_ids: List[int]) -> List[Dict[str, Any]]:
        """doc_id ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ

        Args:
            doc_ids: documents.id ë¦¬ìŠ¤íŠ¸

        Returns:
            ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if not doc_ids:
            return []

        try:
            conn = self.db._get_conn()

            placeholders = ','.join(['?'] * len(doc_ids))
            query = f"""
                SELECT id, path, filename, title, date, year, drafter,
                       category, text_preview, page_count
                FROM documents
                WHERE id IN ({placeholders})
            """

            cursor = conn.execute(query, doc_ids)
            rows = cursor.fetchall()

            # Row -> dict ë³€í™˜
            results = []
            for row in rows:
                results.append({
                    'id': row[0],
                    'path': row[1],
                    'filename': row[2],
                    'title': row[3],
                    'date': row[4],
                    'year': row[5],
                    'drafter': row[6],
                    'category': row[7],
                    'text_preview': row[8],
                    'page_count': row[9]
                })

            return results

        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """ì „ì²´ ê²€ìƒ‰ ìˆ˜í–‰ (HybridRetriever ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ìƒìœ„ Kê°œ ê²°ê³¼

        Returns:
            ì •ê·œí™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸:
            [
                {
                    "doc_id": str,
                    "page": int,
                    "score": float,
                    "snippet": str,
                    "meta": dict,
                    "match_type": str  # 'exact_code' | 'filename'
                }, ...
            ]
        """
        if not self.enabled:
            return []

        # 1. ì½”ë“œ ê¸°ë°˜ ê²€ìƒ‰
        matches = self.search_codes(query)

        if not matches:
            return []

        # 2. top_k ì œí•œ
        matches = matches[:top_k]

        # 3. ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        doc_ids = [doc_id for doc_id, _, _ in matches]
        documents = self.get_documents_by_ids(doc_ids)

        # doc_id -> doc ë§µí•‘
        doc_map = {doc['id']: doc for doc in documents}

        # 4. ê²°ê³¼ ì •ê·œí™”
        results = []
        for doc_id, score, match_type in matches:
            doc = doc_map.get(doc_id)
            if not doc:
                continue

            snippet = (doc.get('text_preview') or "")[:800]
            if not snippet:
                snippet = f"[{doc.get('filename', 'unknown')}]"

            results.append({
                "doc_id": doc.get("filename", "unknown"),
                "page": 1,
                "score": score,
                "snippet": snippet,
                "match_type": match_type,  # ì¶”ê°€ í•„ë“œ
                "meta": {
                    "filename": doc.get("filename", ""),
                    "drafter": doc.get("drafter", ""),
                    "date": doc.get("date", ""),
                    "category": doc.get("category", "pdf"),
                    "doc_id": doc.get("filename", "unknown"),
                    "match_type": match_type  # ë©”íƒ€ì—ë„ í¬í•¨
                }
            })

        logger.info(f"ğŸ¯ ExactMatch: {len(results)}ê±´ ë°˜í™˜")
        return results
