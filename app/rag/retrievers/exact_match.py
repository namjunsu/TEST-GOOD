"""ì •í™•ì¼ì¹˜ ê²€ìƒ‰ê¸° v2.0 (Stage 0 - ëª¨ë¸/ë¶€í’ˆ ì½”ë“œ ì „ìš©)

2025-11-11 v2.0 ê°œì„ ì‚¬í•­:
- SQLite ì¸ë±ìŠ¤ ì¹œí™”ì  ì„¤ê³„ (COLLATE NOCASE, ë°°ì¹˜ ì¿¼ë¦¬)
- LIKE ê²½ê³„ ì œì•½ (padded_norm ê¸°ë°˜ ì˜¤ê²€ì¶œ ë°©ì§€)
- íŠ¹ìˆ˜ë¬¸ìž ì´ìŠ¤ì¼€ì´í”„ (ì™€ì¼ë“œì¹´ë“œ ì œì–´)
- ìŠ¤ì½”ì–´ë§ ê°œì„  (íŒŒì¼ëª… ì •í™•ì¼ì¹˜, ìµœì‹ ì„± ê°€ì¤‘)
- ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (hit_rate, query_time)

model_codes í…Œì´ë¸”ì„ í™œìš©í•œ ì •í™•ì¼ì¹˜ ê²€ìƒ‰
- ì½”ë“œ ë³€í˜•(hyphen/space/no-space) ìžë™ í™•ìž¥
- íŒŒì¼ëª… ì •í™•/ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
- ê°€ì¤‘ì¹˜: exact_code=+3.0, filename_exact=+1.5, filename_partial=+1.0
"""

import time
from typing import Any, Dict, List, Set, Tuple

from app.core.logging import get_logger
from modules.metadata_db import MetadataDB

logger = get_logger(__name__)

# normalizer ìž„í¬íŠ¸ (fallback ì²˜ë¦¬)
try:
    from app.textproc.normalizer import extract_codes, generate_variants, normalize_code
    NORMALIZER_AVAILABLE = True
except ImportError:
    logger.warning("âš ï¸ normalizer ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ExactMatchRetriever ë¹„í™œì„±í™”)")
    NORMALIZER_AVAILABLE = False

    def extract_codes(text: str, normalize_result: bool = True) -> List[str]:
        return []

    def normalize_code(code: str, uppercase: bool = True) -> str:
        return code.upper()

    def generate_variants(code: str) -> List[str]:
        return [code]


class ExactMatchRetriever:
    """ì •í™•ì¼ì¹˜ ê²€ìƒ‰ê¸° v2.0 (Stage 0)

    ëª¨ë¸/ë¶€í’ˆ ì½”ë“œ ê²€ìƒ‰ì„ ìœ„í•œ ì •í™•ì¼ì¹˜ ë ˆì´ì–´
    - model_codes í…Œì´ë¸”ì—ì„œ norm_code ê¸°ë°˜ ê²€ìƒ‰
    - íŒŒì¼ëª… ì •í™•/ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
    - ìŠ¤ì½”ì–´ ë¶€ìŠ¤íŒ…ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì¡°ì •
    """

    # ìŠ¤ì½”ì–´ ê°€ì¤‘ì¹˜ (v2.0 ì—…ë°ì´íŠ¸)
    EXACT_CODE_WEIGHT = 3.0          # model_codes í…Œì´ë¸”ì—ì„œ ì •í™•ì¼ì¹˜
    FILENAME_EXACT_WEIGHT = 1.5      # íŒŒì¼ëª… ì •í™•ì¼ì¹˜ (í† í° ì „ì²´)
    FILENAME_PARTIAL_WEIGHT = 1.0    # íŒŒì¼ëª… ë¶€ë¶„ì¼ì¹˜
    RECENCY_WEIGHT = 0.1             # ìµœì‹ ì„± ê°€ì¤‘ (ì—°ë„ë‹¹)

    def __init__(self, db: MetadataDB = None):
        """ì´ˆê¸°í™”

        Args:
            db: MetadataDB ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
        """
        self.db = db or MetadataDB()
        self.enabled = NORMALIZER_AVAILABLE

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        self.metrics = {
            "total_queries": 0,
            "exact_hits": 0,
            "filename_hits": 0,
            "total_query_time_ms": 0.0
        }

        if not self.enabled:
            logger.warning("âš ï¸ ExactMatchRetriever ë¹„í™œì„±í™” (normalizer ì—†ìŒ)")
        else:
            logger.info("âœ… ExactMatchRetriever v2.0 ì´ˆê¸°í™” ì™„ë£Œ")

    @staticmethod
    def _escape_like(s: str) -> str:
        """LIKE íŒ¨í„´ìš© íŠ¹ìˆ˜ë¬¸ìž ì´ìŠ¤ì¼€ì´í”„

        Args:
            s: ì›ë³¸ ë¬¸ìžì—´

        Returns:
            ì´ìŠ¤ì¼€ì´í”„ëœ ë¬¸ìžì—´
        """
        return s.replace("\\", "\\\\").replace("%", "\\%").replace("_", "\\_")

    def _has_column(self, table: str, column: str) -> bool:
        """í…Œì´ë¸”ì— ì»¬ëŸ¼ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸

        Args:
            table: í…Œì´ë¸”ëª…
            column: ì»¬ëŸ¼ëª…

        Returns:
            ì¡´ìž¬ ì—¬ë¶€
        """
        try:
            conn = self.db._get_conn()
            cursor = conn.execute(f"PRAGMA table_info({table})")
            columns = [row[1].lower() for row in cursor.fetchall()]
            return column.lower() in columns
        except Exception as e:
            logger.debug(f"ì»¬ëŸ¼ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def search_codes(self, query: str) -> List[Tuple[int, float, str]]:
        """ì½”ë“œ ê¸°ë°˜ ì •í™•ì¼ì¹˜ ê²€ìƒ‰ v2.0

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜ (ì˜ˆ: "XRN-1620B2 ë§¤ë‰´ì–¼")

        Returns:
            List of (doc_id, score, match_type):
            - doc_id: documents.id
            - score: ê°€ì¤‘ì¹˜ ì ìˆ˜
            - match_type: 'exact_code' | 'filename_exact' | 'filename_partial'
        """
        if not self.enabled:
            return []

        start_time = time.time()
        self.metrics["total_queries"] += 1

        # 1. ì¿¼ë¦¬ì—ì„œ ì½”ë“œ ì¶”ì¶œ
        codes = extract_codes(query, normalize_result=True)

        if not codes:
            logger.debug("ì½”ë“œ íŒ¨í„´ ì—†ìŒ - ExactMatch ê±´ë„ˆë›°ê¸°")
            return []

        logger.info(f"ðŸŽ¯ ExactMatch v2.0: ì½”ë“œ ì¶”ì¶œ = {codes}")

        # 2. ì½”ë“œ ë³€í˜• ìƒì„± (hyphen/space/no-space)
        all_variants = set()
        for code in codes:
            variants = generate_variants(code)
            all_variants.update(variants)

        logger.debug(f"ì½”ë“œ ë³€í˜• ìƒì„±: {len(all_variants)}ê°œ - {list(all_variants)[:5]}...")

        # 3. model_codes í…Œì´ë¸”ì—ì„œ ì •í™•ì¼ì¹˜ ê²€ìƒ‰
        exact_matches = self._query_model_codes(all_variants)

        # 4. íŒŒì¼ëª… ì¼ì¹˜ ê²€ìƒ‰ (model_codesì— ì—†ëŠ” ê²½ìš° ë³´ì™„)
        filename_matches = self._query_filename_matches(all_variants, codes)

        # 5. ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
        results = self._merge_results(exact_matches, filename_matches)

        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        if exact_matches:
            self.metrics["exact_hits"] += 1
        if filename_matches:
            self.metrics["filename_hits"] += 1

        elapsed_ms = (time.time() - start_time) * 1000
        self.metrics["total_query_time_ms"] += elapsed_ms

        logger.info(
            f"ðŸ“Š ExactMatch v2.0: {len(results)}ê±´ ë°˜í™˜ "
            f"(exact={len(exact_matches)}, filename={len(filename_matches)}, {elapsed_ms:.1f}ms)"
        )

        return results

    def _query_model_codes(self, variants: Set[str]) -> List[Tuple[int, float, str]]:
        """model_codes í…Œì´ë¸”ì—ì„œ ì •í™•ì¼ì¹˜ ê²€ìƒ‰ v2.0

        ë°°ì¹˜ ì¿¼ë¦¬ + ê²½ê³„ ì œì•½ìœ¼ë¡œ ë¼ìš´ë“œíŠ¸ë¦½ ìµœì†Œí™” ë° ì˜¤ê²€ì¶œ ë°©ì§€

        Args:
            variants: ì •ê·œí™”ëœ ì½”ë“œ ë³€í˜• ì§‘í•©

        Returns:
            List of (doc_id, score, 'exact_code')
        """
        if not variants:
            return []

        try:
            conn = self.db._get_conn()
            doc_ids_found = set()

            # 1. ì •í™•ì¼ì¹˜ (IN ì¿¼ë¦¬ - 1íšŒ ë¼ìš´ë“œíŠ¸ë¦½)
            placeholders = ",".join(["?"] * len(variants))
            query_exact = f"""
                SELECT DISTINCT doc_id
                FROM model_codes
                WHERE norm_code IN ({placeholders})
            """
            cursor = conn.execute(query_exact, list(variants))
            exact_count = 0
            for row in cursor.fetchall():
                doc_ids_found.add(row[0])
                exact_count += 1

            # 2. ê²½ê³„ ì œì•½ LIKE (padded_norm ì»¬ëŸ¼ ì¡´ìž¬ ì‹œë§Œ ìˆ˜í–‰)
            # ì˜¤ê²€ì¶œ ë°©ì§€: ' XRN1620 ' í˜•íƒœë¡œ ê³µë°± ê²½ê³„ ê°•ì œ
            boundary_count = 0
            if self._has_column("model_codes", "padded_norm"):
                # UNION ALLë¡œ ë°°ì¹˜ (1íšŒ ë¼ìš´ë“œíŠ¸ë¦½)
                patterns = [f"% {v} %" for v in variants]
                union_clauses = " UNION ALL ".join(
                    ["SELECT DISTINCT doc_id FROM model_codes WHERE padded_norm LIKE ?"]
                    * len(patterns)
                )
                query_boundary = f"SELECT DISTINCT doc_id FROM ({union_clauses})"

                cursor = conn.execute(query_boundary, patterns)
                for row in cursor.fetchall():
                    if row[0] not in doc_ids_found:
                        doc_ids_found.add(row[0])
                        boundary_count += 1

            # (doc_id, score, match_type)
            results = [(doc_id, self.EXACT_CODE_WEIGHT, "exact_code") for doc_id in doc_ids_found]

            logger.debug(
                f"model_codes ì¼ì¹˜: {len(results)}ê±´ (ì •í™•={exact_count}, ê²½ê³„={boundary_count})"
            )
            return results

        except Exception as e:
            logger.error(f"model_codes ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            return []

    def _query_filename_matches(
        self, variants: Set[str], original_codes: List[str]
    ) -> List[Tuple[int, float, str]]:
        """íŒŒì¼ëª…ì—ì„œ ì½”ë“œ ì¼ì¹˜ ê²€ìƒ‰ v2.0

        COLLATE NOCASE + UNION ALL ë°°ì¹˜ ì¿¼ë¦¬ë¡œ ì¸ë±ìŠ¤ í™œìš© ë° ë¼ìš´ë“œíŠ¸ë¦½ ì ˆê°

        Args:
            variants: ì •ê·œí™”ëœ ì½”ë“œ ë³€í˜• ì§‘í•©
            original_codes: ì¶”ì¶œëœ ì›ë³¸ ì½”ë“œ (ì •í™•ì¼ì¹˜ íŒì •ìš©)

        Returns:
            List of (doc_id, score, match_type):
            - match_type: 'filename_exact' | 'filename_partial'
        """
        if not variants:
            return []

        try:
            conn = self.db._get_conn()
            results_map: Dict[int, Tuple[float, str]] = {}

            # ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ëœ íŒ¨í„´ ìƒì„±
            escaped_variants = [self._escape_like(v) for v in variants]
            patterns = [f"%{v}%" for v in escaped_variants]

            # UNION ALLë¡œ ë°°ì¹˜ (1íšŒ ë¼ìš´ë“œíŠ¸ë¦½, COLLATE NOCASEë¡œ ì¸ë±ìŠ¤ í™œìš©)
            union_clauses = " UNION ALL ".join(
                ["SELECT DISTINCT id, filename FROM documents WHERE filename COLLATE NOCASE LIKE ? ESCAPE '\\'"]
                * len(patterns)
            )
            query = f"SELECT DISTINCT id, filename FROM ({union_clauses})"

            cursor = conn.execute(query, patterns)
            rows = cursor.fetchall()

            # ì •í™•ì¼ì¹˜ vs ë¶€ë¶„ì¼ì¹˜ êµ¬ë¶„
            for doc_id, filename in rows:
                # íŒŒì¼ëª…ì—ì„œ ì •í™•ì¼ì¹˜ ì—¬ë¶€ í™•ì¸ (í† í° ì „ì²´ ë§¤ì¹˜)
                filename_upper = filename.upper()
                is_exact = False

                for code in original_codes:
                    # íŒŒì¼ëª… í† í°í™” (í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´, ê³µë°± ê¸°ì¤€)
                    import re
                    tokens = re.split(r"[-_\s.]+", filename_upper)
                    if code.upper() in tokens:
                        is_exact = True
                        break

                if is_exact:
                    match_type = "filename_exact"
                    score = self.FILENAME_EXACT_WEIGHT
                else:
                    match_type = "filename_partial"
                    score = self.FILENAME_PARTIAL_WEIGHT

                # ë” ë†’ì€ ì ìˆ˜ë¡œ ê°±ì‹ 
                if doc_id not in results_map or score > results_map[doc_id][0]:
                    results_map[doc_id] = (score, match_type)

            results = [(doc_id, score, match_type) for doc_id, (score, match_type) in results_map.items()]

            exact_count = sum(1 for _, _, mt in results if mt == "filename_exact")
            partial_count = len(results) - exact_count

            logger.debug(
                f"filename ì¼ì¹˜: {len(results)}ê±´ (ì •í™•={exact_count}, ë¶€ë¶„={partial_count})"
            )
            return results

        except Exception as e:
            logger.error(f"filename ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            return []

    def _merge_results(
        self,
        exact_matches: List[Tuple[int, float, str]],
        filename_matches: List[Tuple[int, float, str]]
    ) -> List[Tuple[int, float, str]]:
        """ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°

        - exact_codeê°€ ìš°ì„ ìˆœìœ„ (filenameê³¼ ì¤‘ë³µë˜ë©´ exact_code ì±„íƒ)
        - doc_idë³„ë¡œ ìµœê³  ì ìˆ˜ ìœ ì§€

        Args:
            exact_matches: model_codes ì¼ì¹˜
            filename_matches: filename ì¼ì¹˜

        Returns:
            List of (doc_id, score, match_type) - doc_id ê¸°ì¤€ ì •ë ¬
        """
        # doc_id -> (score, match_type)
        doc_scores: Dict[int, Tuple[float, str]] = {}

        # exact_code ë¨¼ì € ì¶”ê°€ (ìµœìš°ì„ )
        for doc_id, score, match_type in exact_matches:
            if doc_id not in doc_scores:
                doc_scores[doc_id] = (score, match_type)
            else:
                # ë” ë†’ì€ ì ìˆ˜ë¡œ ê°±ì‹  (ë™ì¼ ì†ŒìŠ¤ ì¤‘ë³µì‹œ)
                if score > doc_scores[doc_id][0]:
                    doc_scores[doc_id] = (score, match_type)

        # filename ì¶”ê°€ (exact_codeê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
        for doc_id, score, match_type in filename_matches:
            if doc_id not in doc_scores:
                doc_scores[doc_id] = (score, match_type)

        # (doc_id, score, match_type) íŠœí”Œë¡œ ë³€í™˜ ë° ì •ë ¬
        results = [(doc_id, score, match_type) for doc_id, (score, match_type) in doc_scores.items()]
        results.sort(key=lambda x: (-x[1], x[0]))  # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ, doc_id ì˜¤ë¦„ì°¨ìˆœ

        return results

    def get_documents_by_ids(self, doc_ids: List[int]) -> List[Dict[str, Any]]:
        """doc_id ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ

        Args:
            doc_ids: documents.id ë¦¬ìŠ¤íŠ¸

        Returns:
            ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if not doc_ids:
            return []

        try:
            conn = self.db._get_conn()

            placeholders = ",".join(["?"] * len(doc_ids))
            query = f"""
                SELECT id, path, filename, title, date, year, drafter,
                       category, text_preview, page_count
                FROM documents
                WHERE id IN ({placeholders})
            """

            cursor = conn.execute(query, doc_ids)
            rows = cursor.fetchall()

            # Row -> dict ë³€í™˜
            results = []
            for row in rows:
                results.append({
                    "id": row[0],
                    "path": row[1],
                    "filename": row[2],
                    "title": row[3],
                    "date": row[4],
                    "year": row[5],
                    "drafter": row[6],
                    "category": row[7],
                    "text_preview": row[8],
                    "page_count": row[9]
                })

            return results

        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """ì „ì²´ ê²€ìƒ‰ ìˆ˜í–‰ (HybridRetriever ì¸í„°íŽ˜ì´ìŠ¤ í˜¸í™˜)

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ìƒìœ„ Kê°œ ê²°ê³¼

        Returns:
            ì •ê·œí™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸:
            [
                {
                    "doc_id": str,
                    "page": int,
                    "score": float,
                    "snippet": str,
                    "meta": dict,
                    "match_type": str  # 'exact_code' | 'filename'
                }, ...
            ]
        """
        if not self.enabled:
            return []

        # 1. ì½”ë“œ ê¸°ë°˜ ê²€ìƒ‰
        matches = self.search_codes(query)

        if not matches:
            return []

        # 2. top_k ì œí•œ
        matches = matches[:top_k]

        # 3. ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        doc_ids = [doc_id for doc_id, _, _ in matches]
        documents = self.get_documents_by_ids(doc_ids)

        # doc_id -> doc ë§µí•‘
        doc_map = {doc["id"]: doc for doc in documents}

        # 4. ê²°ê³¼ ì •ê·œí™”
        results = []
        for doc_id, score, match_type in matches:
            doc = doc_map.get(doc_id)
            if not doc:
                continue

            snippet = (doc.get("text_preview") or "")[:800]
            if not snippet:
                snippet = f"[{doc.get('filename', 'unknown')}]"

            # ìŠ¤ì½”ì–´ ì •ê·œí™” (0-10 ë²”ìœ„ í´ë¦¬í•‘)
            normalized_score = max(0.0, min(10.0, score))

            results.append({
                "doc_id": doc.get("filename", "unknown"),
                "page": 1,
                "score": normalized_score,
                "snippet": snippet,
                "match_type": match_type,  # ì¶”ê°€ í•„ë“œ
                "meta": {
                    "filename": doc.get("filename", ""),
                    "drafter": doc.get("drafter", ""),
                    "date": doc.get("date", ""),
                    "category": doc.get("category", "pdf"),
                    "doc_id": doc.get("filename", "unknown"),
                    "match_type": match_type  # ë©”íƒ€ì—ë„ í¬í•¨
                }
            })

        logger.info(f"ðŸŽ¯ ExactMatch v2.0: {len(results)}ê±´ ë°˜í™˜ (score range: 0-10)")
        return results

    def get_metrics(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ

        Returns:
            ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬:
            - total_queries: ì „ì²´ ì§ˆì˜ ìˆ˜
            - exact_hits: model_codes ížˆíŠ¸ ìˆ˜
            - filename_hits: filename ížˆíŠ¸ ìˆ˜
            - exact_match_hit_rate: ì •í™•ì¼ì¹˜ ížˆíŠ¸ìœ¨
            - avg_query_time_ms: í‰ê·  ì§ˆì˜ ì‹œê°„(ms)
        """
        metrics = self.metrics.copy()

        if metrics["total_queries"] > 0:
            metrics["exact_match_hit_rate"] = metrics["exact_hits"] / metrics["total_queries"]
            metrics["avg_query_time_ms"] = metrics["total_query_time_ms"] / metrics["total_queries"]
        else:
            metrics["exact_match_hit_rate"] = 0.0
            metrics["avg_query_time_ms"] = 0.0

        return metrics
