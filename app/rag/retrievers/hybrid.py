"""í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (MetadataDB ê¸°ë°˜ ì„ì‹œ êµ¬í˜„)

QuickFixRAGê°€ ì œê±°ë˜ì–´ MetadataDBë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
"""

import os
import re
from typing import List, Dict, Any
from app.core.logging import get_logger
from modules.metadata_db import MetadataDB
from app.rag.query_parser import QueryParser

logger = get_logger(__name__)


class HybridRetriever:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (MetadataDB ê¸°ë°˜)

    RAGPipelineì˜ Retriever í”„ë¡œí† ì½œì„ êµ¬í˜„í•˜ë©°,
    ë‚´ë¶€ì ìœ¼ë¡œ MetadataDBë¥¼ ì‚¬ìš©í•´ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """ì´ˆê¸°í™” - MetadataDB ë¡œë“œ"""
        try:
            # MetadataDB ì´ˆê¸°í™”
            self.metadata_db = MetadataDB()
            self.known_drafters = self.metadata_db.list_unique_drafters()
            self.parser = QueryParser(self.known_drafters)
            logger.info("âœ… HybridRetriever ì´ˆê¸°í™” ì™„ë£Œ (MetadataDB ê¸°ë°˜)")
        except Exception as e:
            logger.error(f"âŒ HybridRetriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _calculate_relevance_score(self, query: str, doc: Dict[str, Any]) -> float:
        """ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ relevance ìŠ¤ì½”ì–´ ê³„ì‚° (BM25 ìœ ì‚¬)

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            doc: ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬ (filename, text_preview í¬í•¨)

        Returns:
            0.0~1.0 ë²”ìœ„ì˜ relevance ìŠ¤ì½”ì–´
        """
        # ì¿¼ë¦¬ í† í°í™” (ê³µë°± + íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        query_tokens = set(re.findall(r'\w+', query.lower()))
        if not query_tokens:
            return 0.5  # í† í° ì—†ìœ¼ë©´ ì¤‘ë¦½ ìŠ¤ì½”ì–´

        # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¤€ë¹„ (filename + text_preview)
        doc_text = (
            (doc.get('filename') or '') + ' ' +
            (doc.get('text_preview') or '') + ' ' +
            (doc.get('drafter') or '')
        ).lower()

        # ë§¤ì¹­ëœ í† í° ìˆ˜ ê³„ì‚°
        matched_tokens = sum(1 for token in query_tokens if token in doc_text)

        # ê¸°ë³¸ ìŠ¤ì½”ì–´: ë§¤ì¹­ë¥ 
        match_ratio = matched_tokens / len(query_tokens)

        # ë³´ë„ˆìŠ¤: ì™„ì „ ì¼ì¹˜í•˜ëŠ” êµ¬ë¬¸ì´ ìˆìœ¼ë©´ ê°€ì‚°ì 
        if query.lower() in doc_text:
            match_ratio = min(1.0, match_ratio + 0.3)

        # í˜ë„í‹°: ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê°ì  (ì‹ ë¢°ë„ ì €í•˜)
        text_len = len(doc.get('text_preview') or '')
        if text_len < 100:
            match_ratio *= 0.7

        return max(0.0, min(1.0, match_ratio))

    def search(self, query: str, top_k: int) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ìˆ˜í–‰

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ìƒìœ„ Kê°œ ê²°ê³¼

        Returns:
            ì •ê·œí™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (score_stats ì†ì„± í¬í•¨):
            [
                {
                    "doc_id": str,
                    "page": int,
                    "score": float,
                    "snippet": str,
                    "meta": dict
                }, ...
            ]
        """
        try:
            # ì¿¼ë¦¬ íŒŒì‹±
            filters = self.parser.parse_filters(query)
            year = filters.get('year')
            drafter = filters.get('drafter')

            # MetadataDBì—ì„œ ê²€ìƒ‰ (top_k * 3ë°° ê°€ì ¸ì™€ì„œ relevance ì¬ì •ë ¬)
            results = self.metadata_db.search_documents(
                year=year,
                drafter=drafter,
                limit=top_k * 3  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ relevanceë¡œ ì¬ì •ë ¬
            )

            # ê²°ê³¼ ì •ê·œí™” + relevance ìŠ¤ì½”ì–´ ê³„ì‚°
            normalized = []
            for doc in results:
                snippet = (doc.get('text_preview') or doc.get('content') or "")[:800]
                if not snippet:
                    snippet = f"[{doc.get('filename', 'unknown')}]"

                # Relevance ìŠ¤ì½”ì–´ ê³„ì‚° (íŒ¨ì¹˜ AC1-S1)
                relevance_score = self._calculate_relevance_score(query, doc)

                normalized.append({
                    "doc_id": doc.get("filename", "unknown"),
                    "page": 1,
                    "score": relevance_score,  # ì‹¤ìˆ˜ relevance ìŠ¤ì½”ì–´
                    "snippet": snippet,
                    "meta": {
                        "filename": doc.get("filename", ""),
                        "drafter": doc.get("drafter", ""),
                        "date": doc.get("date", ""),
                        "category": doc.get("category", "pdf"),
                        "doc_id": doc.get("filename", "unknown"),
                    }
                })

            # Relevance ìŠ¤ì½”ì–´ ê¸°ì¤€ ì •ë ¬ í›„ top_kê°œë§Œ ì„ íƒ
            normalized.sort(key=lambda x: x['score'], reverse=True)
            normalized = normalized[:top_k]

            # ìŠ¤ì½”ì–´ ë¶„í¬ í†µê³„ ê³„ì‚° (low-confidence ê°€ë“œë ˆì¼ìš©)
            scores = [r["score"] for r in normalized]
            top1 = scores[0] if len(scores) > 0 else 0.0
            top2 = scores[1] if len(scores) > 1 else 0.0
            top3 = scores[2] if len(scores) > 2 else 0.0

            score_stats = {
                "hits": len(normalized),
                "top1": top1,
                "top2": top2,
                "top3": top3,
                "delta12": max(0.0, top1 - top2),
                "delta13": max(0.0, top1 - top3)
            }

            # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— score_stats ì†ì„± ì¶”ê°€ (duck typing)
            # QueryRouterê°€ getattr(results, "score_stats", {})ë¡œ ì ‘ê·¼ ê°€ëŠ¥
            class ResultsWithStats(list):
                def __init__(self, items, stats):
                    super().__init__(items)
                    self.score_stats = stats

            results_with_stats = ResultsWithStats(normalized, score_stats)

            logger.info(
                f"ğŸ” HybridRetriever: {len(normalized)}ê±´ ê²€ìƒ‰ ì™„ë£Œ "
                f"(top1={top1:.2f}, delta12={score_stats['delta12']:.2f})"
            )
            return results_with_stats

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
