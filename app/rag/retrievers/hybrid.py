"""í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (BM25 ì¸ë±ìŠ¤ ê¸°ë°˜)

BM25Storeë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰
"""

import os
import re
import yaml
from pathlib import Path
from typing import List, Dict, Any
from app.core.logging import get_logger
from modules.metadata_db import MetadataDB
from app.rag.query_parser import QueryParser
from rag_system.bm25_store import BM25Store  # ì¸ë±ì„œì™€ ë™ì¼ ëª¨ë“ˆ ì‚¬ìš©

logger = get_logger(__name__)


class HybridRetriever:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (BM25 ì¸ë±ìŠ¤ ê¸°ë°˜)

    RAGPipelineì˜ Retriever í”„ë¡œí† ì½œì„ êµ¬í˜„í•˜ë©°,
    ë‚´ë¶€ì ìœ¼ë¡œ BM25Storeë¥¼ ì‚¬ìš©í•´ ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """ì´ˆê¸°í™” - BM25Store ë° MetadataDB ë¡œë“œ"""
        try:
            # ê²€ìƒ‰ ë°±ì—”ë“œ ì„¤ì •
            self.use_bm25 = os.getenv("RETRIEVER_BACKEND", "bm25").lower() == "bm25"

            # MetadataDB ì´ˆê¸°í™” (í•„í„°ë§ìš©)
            self.metadata_db = MetadataDB()
            self.known_drafters = self.metadata_db.list_unique_drafters()
            self.parser = QueryParser(self.known_drafters)

            # BM25Store ì´ˆê¸°í™”
            self.bm25 = None
            if self.use_bm25:
                index_path = os.getenv("BM25_INDEX_PATH", "var/index/bm25_index.pkl")
                logger.info(f"ğŸ” DEBUG: BM25_INDEX_PATH={index_path} (exists={os.path.exists(index_path)})")
                self.bm25 = BM25Store(index_path=index_path)
                logger.info(f"âœ… HybridRetriever ì´ˆê¸°í™” ì™„ë£Œ (BM25 ë°±ì—”ë“œ, {len(self.bm25.documents)}ê°œ ë¬¸ì„œ, path={self.bm25.index_path})")
            else:
                logger.info("âœ… HybridRetriever ì´ˆê¸°í™” ì™„ë£Œ (MetadataDB í´ë°± ëª¨ë“œ)")

            # ì¸ë±ìŠ¤ íŒŒì¼ mtime ì¶”ì  (ìë™ ì¬ë¡œë“œìš©)
            self._last_index_mtime = self._get_index_mtime()

            # DOC_ANCHORED í‚¤ì›Œë“œ ë¡œë“œ (YAML ì™¸ë¶€í™”)
            self._load_router_keywords()

        except Exception as e:
            logger.error(f"âŒ HybridRetriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _load_router_keywords(self):
        """ë¼ìš°í„° í‚¤ì›Œë“œ YAML ë¡œë“œ (ìš´ì˜ ì¤‘ ìˆ˜ì • ê°€ëŠ¥)"""
        try:
            config_path = Path("config/router_keywords.yaml")
            if config_path.exists():
                config = yaml.safe_load(config_path.read_text())
                allow_patterns = config["doc_anchored"]["allow"]
                self.device_pattern = "|".join(allow_patterns)
                logger.info(f"âœ… DOC_ANCHORED í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ ({len(allow_patterns)}ê°œ íŒ¨í„´)")
            else:
                # í´ë°±: í•˜ë“œì½”ë”© íŒ¨í„´ ì‚¬ìš©
                self.device_pattern = (
                    r"\bHRD[-\s]?\d{3,4}\b|DVR|NVR|"
                    r"Hanwha(?:\s+(?:Techwin|Vision))?|"
                    r"ë³´ì¡´ìš©|ë…¹í™”ìš©|êµì²´|ë…¸í›„|ì¥ë¹„|ì¹´ë©”ë¼|ëª¨ë‹ˆí„°"
                )
                logger.warning("âš ï¸ router_keywords.yaml ì—†ìŒ, í´ë°± íŒ¨í„´ ì‚¬ìš©")
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}, í´ë°± íŒ¨í„´ ì‚¬ìš©")
            self.device_pattern = (
                r"\bHRD[-\s]?\d{3,4}\b|DVR|NVR|"
                r"Hanwha(?:\s+(?:Techwin|Vision))?|"
                r"ë³´ì¡´ìš©|ë…¹í™”ìš©|êµì²´|ë…¸í›„|ì¥ë¹„|ì¹´ë©”ë¼|ëª¨ë‹ˆí„°"
            )

    def _get_index_mtime(self) -> float:
        """ì¸ë±ìŠ¤ íŒŒì¼ì˜ ìˆ˜ì • ì‹œê°„ ë°˜í™˜"""
        if not self.use_bm25:
            return 0.0
        index_path = os.getenv("BM25_INDEX_PATH", "var/index/bm25_index.pkl")
        return os.path.getmtime(index_path) if os.path.exists(index_path) else 0.0

    def _reload_if_index_rotated(self):
        """ì¸ë±ìŠ¤ íŒŒì¼ì´ ê°±ì‹ ë˜ë©´ ìë™ ë¦¬ë¡œë“œ"""
        if not self.use_bm25:
            return

        current_mtime = self._get_index_mtime()
        if current_mtime > self._last_index_mtime:
            logger.info("ğŸ”„ ì¸ë±ìŠ¤ íŒŒì¼ ê°±ì‹  ê°ì§€, ì¬ë¡œë“œ ì¤‘...")
            index_path = os.getenv("BM25_INDEX_PATH", "var/index/bm25_index.pkl")
            self.bm25 = BM25Store(index_path=index_path)
            self._last_index_mtime = current_mtime
            logger.info(f"âœ… ì¸ë±ìŠ¤ ì¬ë¡œë“œ ì™„ë£Œ ({len(self.bm25.documents)}ê°œ ë¬¸ì„œ)")

    def _calculate_relevance_score(self, query: str, doc: Dict[str, Any]) -> float:
        """ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ relevance ìŠ¤ì½”ì–´ ê³„ì‚° (BM25 ìœ ì‚¬)

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            doc: ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬ (filename, text_preview í¬í•¨)

        Returns:
            0.0~1.0 ë²”ìœ„ì˜ relevance ìŠ¤ì½”ì–´
        """
        # ì¿¼ë¦¬ í† í°í™” (ê³µë°± + íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        query_tokens = set(re.findall(r'\w+', query.lower()))
        if not query_tokens:
            return 0.5  # í† í° ì—†ìœ¼ë©´ ì¤‘ë¦½ ìŠ¤ì½”ì–´

        # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¤€ë¹„ (filename + text_preview)
        doc_text = (
            (doc.get('filename') or '') + ' ' +
            (doc.get('text_preview') or '') + ' ' +
            (doc.get('drafter') or '')
        ).lower()

        # ë§¤ì¹­ëœ í† í° ìˆ˜ ê³„ì‚°
        matched_tokens = sum(1 for token in query_tokens if token in doc_text)

        # ê¸°ë³¸ ìŠ¤ì½”ì–´: ë§¤ì¹­ë¥ 
        match_ratio = matched_tokens / len(query_tokens)

        # ë³´ë„ˆìŠ¤: ì™„ì „ ì¼ì¹˜í•˜ëŠ” êµ¬ë¬¸ì´ ìˆìœ¼ë©´ ê°€ì‚°ì 
        if query.lower() in doc_text:
            match_ratio = min(1.0, match_ratio + 0.3)

        # í˜ë„í‹°: ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê°ì  (ì‹ ë¢°ë„ ì €í•˜)
        text_len = len(doc.get('text_preview') or '')
        if text_len < 100:
            match_ratio *= 0.7

        return max(0.0, min(1.0, match_ratio))

    def search(self, query: str, top_k: int, mode: str = "chat", selected_filename: Optional[str] = None) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ìˆ˜í–‰

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            top_k: ìƒìœ„ Kê°œ ê²°ê³¼
            mode: ê²€ìƒ‰ ëª¨ë“œ ("chat", "doc_anchored" ë“±)
            selected_filename: ì„ íƒëœ ë¬¸ì„œ íŒŒì¼ëª… (ìš°ì„  ê²€ìƒ‰ìš©, ì„ íƒì‚¬í•­)

        Returns:
            ì •ê·œí™”ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (score_stats ì†ì„± í¬í•¨):
            [
                {
                    "doc_id": str,
                    "page": int,
                    "score": float,
                    "snippet": str,
                    "meta": dict
                }, ...
            ]
        """
        try:
            # ì¸ë±ìŠ¤ ê°±ì‹  ì²´í¬
            self._reload_if_index_rotated()

            # BM25 ë°±ì—”ë“œ ì‚¬ìš©
            if self.use_bm25 and self.bm25:
                # DOC_ANCHORED ëª¨ë“œ: ë„‰ë„‰í•˜ê²Œ ê²€ìƒ‰ í›„ í•„í„°ë§
                search_k = 50 if mode.lower() == "doc_anchored" else top_k

                # BM25Storeì—ì„œ ì§ì ‘ ê²€ìƒ‰
                bm25_results = self.bm25.search(query, top_k=search_k)

                # BM25 ê²°ê³¼ë¥¼ RAGPipeline í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (doc_id, snippet í•„ë“œ ì¶”ê°€)
                converted_results = []
                for result in bm25_results:
                    converted_results.append({
                        "doc_id": result.get("filename", "unknown"),
                        "snippet": result.get("content", "")[:800],  # content -> snippet
                        "score": result.get("score", 0.0),
                        "page": 1,
                        "filename": result.get("filename"),  # ì›ë³¸ filename ìœ ì§€
                        "file_path": result.get("path"),  # path -> file_path
                        "meta": {
                            "filename": result.get("filename"),
                            "date": result.get("date"),
                            "drafter": result.get("drafter"),
                            "category": result.get("category"),
                        }
                    })

                # DOC_ANCHORED í•„í„°ë§: ì¥ë¹„ ê´€ë ¨ í‚¤ì›Œë“œë§Œ í†µê³¼
                if mode.lower() == "doc_anchored":
                    filtered = []
                    for result in converted_results:
                        text = result.get("snippet", "") + " " + result.get("doc_id", "")
                        if re.search(self.device_pattern, text, re.IGNORECASE):
                            filtered.append(result)

                    # í•„í„° ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ìƒìœ„ N*3 ì‚¬ìš© (ë¯¸íƒ ë°©ì§€)
                    if not filtered:
                        logger.warning("âš ï¸ DOC_ANCHORED í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ì›ë³¸ ìƒìœ„ ì‚¬ìš©")
                        normalized = converted_results[:top_k * 3]
                    else:
                        logger.info(f"ğŸ¯ DOC_ANCHORED í•„í„°ë§: {len(converted_results)}ê°œ â†’ {len(filtered)}ê°œ")
                        normalized = filtered[:top_k]
                else:
                    normalized = converted_results

                # ì„ íƒëœ ë¬¸ì„œ ê°•ì œ ì¶”ê°€ (ì‚¬ìš©ì ìš”ì²­ ìš°ì„  ì²˜ë¦¬)
                if selected_filename:
                    selected_doc = None
                    # 1. BM25 ê²°ê³¼ì—ì„œ ë¨¼ì € ì°¾ê¸°
                    for result in converted_results:
                        if result.get("filename") == selected_filename:
                            selected_doc = result
                            break

                    # 2. BM25ì— ì—†ìœ¼ë©´ MetadataDBì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                    if not selected_doc:
                        logger.info(f"ğŸ” BM25ì— ì—†ìŒ, MetadataDBì—ì„œ ì§ì ‘ ê²€ìƒ‰: {selected_filename}")
                        all_docs = self.metadata_db.search_documents(limit=500)
                        for doc in all_docs:
                            if doc.get("filename") == selected_filename:
                                # BM25 result í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                selected_doc = {
                                    "doc_id": doc.get("filename", "unknown"),
                                    "snippet": (doc.get("text_preview") or "")[:800],
                                    "score": 0.0,
                                    "page": 1,
                                    "filename": doc.get("filename"),
                                    "file_path": doc.get("path"),
                                    "meta": {
                                        "filename": doc.get("filename"),
                                        "date": doc.get("date"),
                                        "drafter": doc.get("drafter"),
                                        "category": doc.get("category"),
                                    }
                                }
                                logger.info(f"âœ… MetadataDBì—ì„œ ë°œê²¬: {selected_filename}")
                                break

                    # 3. ì°¾ì•˜ìœ¼ë©´ ìµœìƒìœ„ì— ê°•ì œ ì¶”ê°€
                    if selected_doc:
                        # ê¸°ì¡´ ê²°ê³¼ì—ì„œ ì œê±° (ì¤‘ë³µ ë°©ì§€)
                        normalized = [r for r in normalized if r.get("filename") != selected_filename]
                        # ìµœìƒìœ„ì— ê°•ì œ ì¶”ê°€ (score=99.9ë¡œ ìµœìš°ì„ )
                        selected_doc_priority = selected_doc.copy()
                        selected_doc_priority["score"] = 99.9
                        normalized = [selected_doc_priority] + normalized[:top_k-1]
                        logger.info(f"ğŸ¯ ì„ íƒëœ ë¬¸ì„œ ìµœìƒìœ„ ê°•ì œ ì¶”ê°€: {selected_filename} (score=99.9)")
                    else:
                        logger.warning(f"âš ï¸ ì„ íƒëœ ë¬¸ì„œ '{selected_filename}'ë¥¼ ì°¾ì§€ ëª»í•¨ (BM25/MetadataDB ëª¨ë‘)")

            else:
                # Fallback: MetadataDB ê¸°ë°˜ (ë¹„ê¶Œì¥, 500ì ì œí•œ)
                logger.warning("âš ï¸ BM25 ë¹„í™œì„±í™”, MetadataDB í´ë°± ëª¨ë“œ (text_preview 500ì ì œí•œ)")
                filters = self.parser.parse_filters(query)
                year = filters.get('year')
                drafter = filters.get('drafter')

                results = self.metadata_db.search_documents(
                    year=year,
                    drafter=drafter,
                    limit=top_k * 3
                )

                normalized = []
                for doc in results:
                    snippet = (doc.get('text_preview') or doc.get('content') or "")[:800]
                    if not snippet:
                        snippet = f"[{doc.get('filename', 'unknown')}]"

                    relevance_score = self._calculate_relevance_score(query, doc)

                    normalized.append({
                        "doc_id": doc.get("filename", "unknown"),
                        "page": 1,
                        "score": relevance_score,
                        "snippet": snippet,
                        "meta": {
                            "filename": doc.get("filename", ""),
                            "drafter": doc.get("drafter", ""),
                            "date": doc.get("date", ""),
                            "category": doc.get("category", "pdf"),
                            "doc_id": doc.get("filename", "unknown"),
                        }
                    })

                normalized.sort(key=lambda x: x['score'], reverse=True)
                normalized = normalized[:top_k]

            # ìŠ¤ì½”ì–´ ë¶„í¬ í†µê³„ ê³„ì‚° (low-confidence ê°€ë“œë ˆì¼ìš©)
            scores = [r["score"] for r in normalized]
            top1 = scores[0] if len(scores) > 0 else 0.0
            top2 = scores[1] if len(scores) > 1 else 0.0
            top3 = scores[2] if len(scores) > 2 else 0.0

            score_stats = {
                "hits": len(normalized),
                "top1": top1,
                "top2": top2,
                "top3": top3,
                "delta12": max(0.0, top1 - top2),
                "delta13": max(0.0, top1 - top3)
            }

            # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— score_stats ì†ì„± ì¶”ê°€ (duck typing)
            class ResultsWithStats(list):
                def __init__(self, items, stats):
                    super().__init__(items)
                    self.score_stats = stats

            results_with_stats = ResultsWithStats(normalized, score_stats)

            backend = "BM25" if (self.use_bm25 and self.bm25) else "MetadataDB"
            logger.info(
                f"ğŸ” HybridRetriever ({backend}): {len(normalized)}ê±´ ê²€ìƒ‰ ì™„ë£Œ "
                f"(top1={top1:.2f}, delta12={score_stats['delta12']:.2f})"
            )
            return results_with_stats

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
