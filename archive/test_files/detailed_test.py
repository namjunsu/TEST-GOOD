#!/usr/bin/env python3
"""
AI-CHAT RAG ì‹œìŠ¤í…œ ìƒì„¸ í…ŒìŠ¤íŠ¸
ëª¨ë“  ê°œì„ ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ì„ ê²€ì¦
"""

import sys
import time
import logging
from pathlib import Path
from typing import Dict, List, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_separator(title: str):
    """í…ŒìŠ¤íŠ¸ êµ¬ë¶„ì„  ì¶œë ¥"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª {title}")
    print('='*80)

def test_bm25_store():
    """BM25 ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸"""
    test_separator("BM25 ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.bm25_store import BM25Store
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. BM25 ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        bm25 = BM25Store(index_path="test_bm25.pkl")
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. ìƒìˆ˜ ê°’ í™•ì¸...")
        print(f"   - DEFAULT_K1: {bm25.DEFAULT_K1}")
        print(f"   - DEFAULT_B: {bm25.DEFAULT_B}")
        print(f"   - ì‹¤ì œ k1: {bm25.k1}")
        print(f"   - ì‹¤ì œ b: {bm25.b}")
        
        # 3. ë¬¸ì„œ ì¶”ê°€
        print("\n3. ë¬¸ì„œ ì¶”ê°€ í…ŒìŠ¤íŠ¸...")
        test_docs = [
            "AI ì±—ë´‡ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë°©ë²•",
            "í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ì˜ ë°œì „",
            "ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ìµœì í™” ê¸°ë²•"
        ]
        test_metadata = [
            {"doc_id": f"doc_{i}", "source": "test"} 
            for i in range(len(test_docs))
        ]
        
        bm25.add_documents(test_docs, test_metadata)
        print(f"   âœ… {len(test_docs)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
        
        # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
        queries = ["AI ì„±ëŠ¥", "í•œêµ­ì–´ ì²˜ë¦¬", "ìµœì í™”"]
        for query in queries:
            results = bm25.search(query, top_k=2)
            print(f"   - '{query}' ê²€ìƒ‰: {len(results)}ê°œ ê²°ê³¼")
            if results:
                print(f"     ìµœê³  ìŠ¤ì½”ì–´: {results[0]['score']:.3f}")
        
        # 5. í†µê³„
        print("\n5. ì¸ë±ìŠ¤ í†µê³„...")
        stats = bm25.get_stats()
        print(f"   - ì´ ë¬¸ì„œ: {stats['total_documents']}")
        print(f"   - ì–´íœ˜ í¬ê¸°: {stats['vocab_size']}")
        print(f"   - í‰ê·  ë¬¸ì„œ ê¸¸ì´: {stats['avg_doc_length']:.1f}")
        
        return True, "BM25 ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"BM25 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_document_compression():
    """ë¬¸ì„œ ì••ì¶• í…ŒìŠ¤íŠ¸"""
    test_separator("ë¬¸ì„œ ì••ì¶• í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.document_compression import DocumentCompression
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. ì••ì¶•ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        compressor = DocumentCompression()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. ìƒìˆ˜ ê°’ í™•ì¸...")
        print(f"   - DEFAULT_TARGET_LENGTH: {compressor.DEFAULT_TARGET_LENGTH}")
        print(f"   - DEFAULT_COMPRESSION_RATIO: {compressor.DEFAULT_COMPRESSION_RATIO}")
        print(f"   - QUERY_MATCH_WEIGHT: {compressor.QUERY_MATCH_WEIGHT}")
        
        # 3. ë¬¸ì„œ ì••ì¶• í…ŒìŠ¤íŠ¸
        print("\n3. ë¬¸ì„œ ì••ì¶• í…ŒìŠ¤íŠ¸...")
        test_documents = [
            {
                'content': 'ì´ê²ƒì€ ë§¤ìš° ê¸´ ë¬¸ì„œì…ë‹ˆë‹¤. ' * 50,  # ê¸´ ë¬¸ì„œ
                'metadata': {'filename': 'long_doc.txt'}
            },
            {
                'content': 'í•µì‹¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë¬¸ì„œ. ì¤‘ìš”í•œ ì •ë³´ê°€ ì—¬ê¸° ìˆìŠµë‹ˆë‹¤.',
                'metadata': {'filename': 'short_doc.txt'}
            }
        ]
        
        compressed = compressor.compress_documents(
            documents=test_documents,
            query='í•µì‹¬ í‚¤ì›Œë“œ',
            compression_ratio=0.5
        )
        
        print(f"   - ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(test_documents)}")
        print(f"   - ì••ì¶• í›„ ë¬¸ì„œ ìˆ˜: {len(compressed)}")
        print(f"   - ì²« ë²ˆì§¸ ë¬¸ì„œ ì›ë³¸ ê¸¸ì´: {len(test_documents[0]['content'])}")
        
        return True, "ë¬¸ì„œ ì••ì¶• í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"ë¬¸ì„œ ì••ì¶• í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_query_optimizer():
    """ì¿¼ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    test_separator("ì¿¼ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.query_optimizer import QueryOptimizer
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. ìµœì í™”ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        optimizer = QueryOptimizer()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. ê°€ì¤‘ì¹˜ ìƒìˆ˜ í™•ì¸...")
        print(f"   - DEFAULT_VECTOR_WEIGHT: {optimizer.DEFAULT_VECTOR_WEIGHT}")
        print(f"   - DEFAULT_BM25_WEIGHT: {optimizer.DEFAULT_BM25_WEIGHT}")
        
        # 3. ì¿¼ë¦¬ ì •ì œ í…ŒìŠ¤íŠ¸
        print("\n3. ì¿¼ë¦¬ ì •ì œ í…ŒìŠ¤íŠ¸...")
        test_queries = [
            "ë­ì•¼ ì´ê±°??",
            "~!@# íŠ¹ìˆ˜ë¬¸ì $%^ í¬í•¨",
            "ì¤‘ê³„ì°¨ëŠ” ì–´ë–¤ ì¥ë¹„ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”?"
        ]
        
        for query in test_queries:
            cleaned = optimizer.clean_query_for_search(query)
            print(f"   ì›ë³¸: '{query}'")
            print(f"   ì •ì œ: '{cleaned}'")
        
        # 4. ê°€ì¤‘ì¹˜ ê²°ì • í…ŒìŠ¤íŠ¸
        print("\n4. ê°€ì¤‘ì¹˜ ê²°ì • í…ŒìŠ¤íŠ¸...")
        queries_for_weight = [
            "HD",  # ì§§ì€ ì¿¼ë¦¬
            "ì¤‘ê³„ì°¨ ì¥ë¹„ ëª©ë¡ ìƒì„¸",  # ì¤‘ê°„ ì¿¼ë¦¬
            "2023ë…„ë„ì— êµ¬ë§¤í•œ ë°©ì†¡ ì¥ë¹„ ì¤‘ 1ì–µì› ì´ìƒ ì œí’ˆ"  # ê¸´ ì¿¼ë¦¬
        ]
        
        for query in queries_for_weight:
            vector_weight, bm25_weight = optimizer.get_optimal_weights(query)
            print(f"   '{query[:20]}...'")
            print(f"     Vector: {vector_weight:.2f}, BM25: {bm25_weight:.2f}")
        
        return True, "ì¿¼ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"ì¿¼ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_query_expansion():
    """ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸"""
    test_separator("ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.query_expansion import QueryExpansion
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. í™•ì¥ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        expander = QueryExpansion()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. í™•ì¥ ì œí•œ ìƒìˆ˜ í™•ì¸...")
        print(f"   - MAX_SYNONYMS_EXPANSIONS: {expander.MAX_SYNONYMS_EXPANSIONS}")
        print(f"   - MAX_PATTERN_EXPANSIONS: {expander.MAX_PATTERN_EXPANSIONS}")
        
        # 3. ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸
        print("\n3. ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸...")
        test_queries = [
            "HD ì¹´ë©”ë¼",
            "ëª¨ë‹ˆí„° êµ¬ë§¤",
            "LED ì¡°ëª…"
        ]
        
        for query in test_queries:
            expanded = expander.expand_query(query)
            print(f"   ì›ë³¸: '{query}'")
            print(f"   í™•ì¥: {expanded['expanded_queries'][:3]}...")  # ì²˜ìŒ 3ê°œë§Œ
            print(f"   ë°©ë²•: {expanded['methods_used']}")
        
        return True, "ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_korean_reranker():
    """í•œêµ­ì–´ ì¬ìˆœìœ„ í…ŒìŠ¤íŠ¸"""
    test_separator("í•œêµ­ì–´ ì¬ìˆœìœ„ í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.korean_reranker import KoreanReranker
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. ì¬ìˆœìœ„ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        reranker = KoreanReranker()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. ê°€ì¤‘ì¹˜ ìƒìˆ˜ í™•ì¸...")
        print(f"   - JACCARD_WEIGHT: {reranker.JACCARD_WEIGHT}")
        print(f"   - TF_WEIGHT: {reranker.TF_WEIGHT}")
        print(f"   - MAX_TOKEN_LENGTH: {reranker.MAX_TOKEN_LENGTH}")
        
        # 3. ì¬ìˆœìœ„ í…ŒìŠ¤íŠ¸
        print("\n3. ì¬ìˆœìœ„ í…ŒìŠ¤íŠ¸...")
        test_documents = [
            {'content': 'ì¤‘ê³„ì°¨ HD ì¹´ë©”ë¼ ì¥ë¹„', 'metadata': {'score': 0.5}},
            {'content': 'HD ê³ í™”ì§ˆ ì¹´ë©”ë¼ ì‹œìŠ¤í…œ', 'metadata': {'score': 0.6}},
            {'content': 'ë°©ì†¡ìš© ì¹´ë©”ë¼ ì¥ë¹„ ëª©ë¡', 'metadata': {'score': 0.4}}
        ]
        
        reranked = reranker.rerank(
            query="HD ì¹´ë©”ë¼",
            results=test_documents,
            top_k=2
        )
        
        print(f"   - ì›ë³¸ ë¬¸ì„œ: {len(test_documents)}ê°œ")
        print(f"   - ì¬ìˆœìœ„ í›„: {len(reranked)}ê°œ")
        for i, doc in enumerate(reranked[:2]):
            print(f"   {i+1}. ìŠ¤ì½”ì–´: {doc.get('rerank_score', 0):.3f}")
        
        return True, "í•œêµ­ì–´ ì¬ìˆœìœ„ í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"í•œêµ­ì–´ ì¬ìˆœìœ„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_metadata_extractor():
    """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    test_separator("ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.metadata_extractor import MetadataExtractor
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        extractor = MetadataExtractor()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. ê²€ì¦ ìƒìˆ˜ í™•ì¸...")
        print(f"   - CONFIDENCE_HIGH: {extractor.CONFIDENCE_HIGH}")
        print(f"   - AUTHOR_MIN_LENGTH: {extractor.AUTHOR_MIN_LENGTH}")
        print(f"   - AUTHOR_MAX_LENGTH: {extractor.AUTHOR_MAX_LENGTH}")
        print(f"   - AMOUNT_MIN: {extractor.AMOUNT_MIN}")
        print(f"   - AMOUNT_MAX: {extractor.AMOUNT_MAX}")
        
        # 3. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        print("\n3. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
        test_texts = [
            "ì‘ì„±ì: ê¹€ì² ìˆ˜ ì°¨ì¥ / ë‚ ì§œ: 2024-03-15 / ê¸ˆì•¡: 1,500,000ì›",
            "ë‹´ë‹¹: ì´ì˜í¬ ëŒ€ë¦¬ | 2023ë…„ 12ì›” | ì´ 350ë§Œì›",
            "ê¸°ì•ˆì: ë°•ì§€ì„± / ê²°ì¬ì¼: 2024.01.20"
        ]
        
        for text in test_texts:
            metadata = extractor.extract_metadata(text)
            print(f"   í…ìŠ¤íŠ¸: '{text[:30]}...'")
            if metadata.get('author'):
                print(f"     ì‘ì„±ì: {metadata['author']}")
            if metadata.get('date'):
                print(f"     ë‚ ì§œ: {metadata['date']}")
            if metadata.get('amount'):
                print(f"     ê¸ˆì•¡: {metadata['amount']:,}ì›")
        
        return True, "ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_multilevel_filter():
    """ë‹¤ë‹¨ê³„ í•„í„°ë§ í…ŒìŠ¤íŠ¸"""
    test_separator("ë‹¤ë‹¨ê³„ í•„í„°ë§ í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.multilevel_filter import MultilevelFilter
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. í•„í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        filter = MultilevelFilter()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. í•„í„°ë§ ìƒìˆ˜ í™•ì¸...")
        print(f"   - PHASE1_MAX_CANDIDATES: {filter.PHASE1_MAX_CANDIDATES}")
        print(f"   - PHASE2_MAX_CANDIDATES: {filter.PHASE2_MAX_CANDIDATES}")
        print(f"   - PHASE3_TOP_K: {filter.PHASE3_TOP_K}")
        print(f"   - MIN_RELEVANCE_SCORE: {filter.MIN_RELEVANCE_SCORE}")
        
        # 3. ë³µì¡ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸
        print("\n3. ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„...")
        queries = [
            "HD ì¹´ë©”ë¼",
            "2023ë…„ êµ¬ë§¤í•œ ì¥ë¹„ ì¤‘ 1ì–µì› ì´ìƒ",
            "ì¤‘ê³„ì°¨ì™€ ìŠ¤íŠœë””ì˜¤ ì¥ë¹„ ë¹„êµ"
        ]
        
        for query in queries:
            complexity = filter.complexity_analyzer.analyze(query)
            print(f"   '{query}'")
            print(f"     ë³µì¡ë„: {complexity['complexity_level']}")
            print(f"     íƒ€ì…: {complexity['type']}")
        
        return True, "ë‹¤ë‹¨ê³„ í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"ë‹¤ë‹¨ê³„ í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_hybrid_search():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸"""
    test_separator("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸")
    
    try:
        from rag_system.hybrid_search import HybridSearch
        
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        print("1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
        search = HybridSearch()
        print("   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. ìƒìˆ˜ í™•ì¸
        print("\n2. ê²€ìƒ‰ ìƒìˆ˜ í™•ì¸...")
        print(f"   - DEFAULT_VECTOR_WEIGHT: {search.DEFAULT_VECTOR_WEIGHT}")
        print(f"   - DEFAULT_BM25_WEIGHT: {search.DEFAULT_BM25_WEIGHT}")
        print(f"   - DEFAULT_TOP_K: {search.DEFAULT_TOP_K}")
        
        # 3. ë¬¸ì„œ ì¶”ê°€ í…ŒìŠ¤íŠ¸
        print("\n3. ë¬¸ì„œ ì¸ë±ì‹± í…ŒìŠ¤íŠ¸...")
        test_docs = [
            {
                'content': 'HD ì¹´ë©”ë¼ ì‹œìŠ¤í…œì€ ê³ í™”ì§ˆ ë°©ì†¡ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.',
                'doc_id': 'test1',
                'chunk_id': 'chunk1',
                'filename': 'camera.pdf'
            },
            {
                'content': 'ì¤‘ê³„ì°¨ëŠ” ì‹¤ì‹œê°„ ë°©ì†¡ì„ ìœ„í•œ ì´ë™í˜• ìŠ¤íŠœë””ì˜¤ì…ë‹ˆë‹¤.',
                'doc_id': 'test2', 
                'chunk_id': 'chunk2',
                'filename': 'van.pdf'
            }
        ]
        
        search.add_documents(test_docs)
        print(f"   âœ… {len(test_docs)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ")
        
        # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
        results = search.search("HD ë°©ì†¡", top_k=2)
        print(f"   - ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        for i, result in enumerate(results):
            print(f"   {i+1}. {result['filename']} (ìŠ¤ì½”ì–´: {result.get('final_score', 0):.3f})")
        
        return True, "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ"
        
    except Exception as e:
        return False, f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
    test_separator("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸")
    
    try:
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        
        # 1. ì´ˆê¸° ë©”ëª¨ë¦¬
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        print(f"1. ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory:.1f} MB")
        
        # 2. ëª¨ë“ˆ ë¡œë“œ í›„
        from rag_system.bm25_store import BM25Store
        from rag_system.document_compression import DocumentCompression
        from rag_system.query_optimizer import QueryOptimizer
        
        loaded_memory = process.memory_info().rss / 1024 / 1024
        print(f"2. ëª¨ë“ˆ ë¡œë“œ í›„: {loaded_memory:.1f} MB (+{loaded_memory-initial_memory:.1f} MB)")
        
        # 3. ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„
        bm25 = BM25Store()
        compressor = DocumentCompression()
        optimizer = QueryOptimizer()
        
        instance_memory = process.memory_info().rss / 1024 / 1024
        print(f"3. ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„: {instance_memory:.1f} MB (+{instance_memory-loaded_memory:.1f} MB)")
        
        # 4. ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ í™•ì¸
        total_increase = instance_memory - initial_memory
        print(f"\nì´ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰: {total_increase:.1f} MB")
        
        if total_increase < 500:  # 500MB ë¯¸ë§Œì´ë©´ ì •ìƒ
            return True, f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ ({total_increase:.1f} MB)"
        else:
            return False, f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³¼ë‹¤ ({total_increase:.1f} MB)"
            
    except Exception as e:
        return False, f"ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def test_error_handling():
    """ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    test_separator("ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    
    results = []
    
    # 1. ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œ
    print("1. ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬...")
    try:
        from rag_system.bm25_store import BM25Store
        bm25 = BM25Store(index_path="/invalid/path/index.pkl")
        bm25.load_index()
        results.append("âŒ ì˜ˆì™¸ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ")
    except:
        results.append("âœ… ì˜ˆì™¸ ì²˜ë¦¬ ì„±ê³µ")
    
    # 2. ë¹ˆ ë¬¸ì„œ ì²˜ë¦¬
    print("2. ë¹ˆ ë¬¸ì„œ ì²˜ë¦¬...")
    try:
        from rag_system.document_compression import DocumentCompression
        compressor = DocumentCompression()
        compressed = compressor.compress_documents([], "test", 0.5)
        results.append("âœ… ë¹ˆ ë¬¸ì„œ ì²˜ë¦¬ ì„±ê³µ")
    except:
        results.append("âŒ ë¹ˆ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨")
    
    # 3. None ì¿¼ë¦¬ ì²˜ë¦¬
    print("3. None ì¿¼ë¦¬ ì²˜ë¦¬...")
    try:
        from rag_system.query_optimizer import QueryOptimizer
        optimizer = QueryOptimizer()
        result = optimizer.clean_query_for_search(None) if hasattr(optimizer, 'clean_query_for_search') else ""
        if result == "":
            results.append("âœ… None ì²˜ë¦¬ ì„±ê³µ")
        else:
            results.append("âŒ None ì²˜ë¦¬ ì‹¤íŒ¨")
    except:
        results.append("âŒ ì˜ˆì™¸ ë°œìƒ")
    
    # ê²°ê³¼ ì§‘ê³„
    success = all("âœ…" in r for r in results)
    return success, f"ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸: {results}"

def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ AI-CHAT RAG ì‹œìŠ¤í…œ ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"   ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # í…ŒìŠ¤íŠ¸ ëª©ë¡
    tests = [
        ("BM25 ìŠ¤í† ì–´", test_bm25_store),
        ("ë¬¸ì„œ ì••ì¶•", test_document_compression),
        ("ì¿¼ë¦¬ ìµœì í™”", test_query_optimizer),
        ("ì¿¼ë¦¬ í™•ì¥", test_query_expansion),
        ("í•œêµ­ì–´ ì¬ìˆœìœ„", test_korean_reranker),
        ("ë©”íƒ€ë°ì´í„° ì¶”ì¶œ", test_metadata_extractor),
        ("ë‹¤ë‹¨ê³„ í•„í„°ë§", test_multilevel_filter),
        ("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", test_hybrid_search),
        ("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", test_memory_usage),
        ("ì˜¤ë¥˜ ì²˜ë¦¬", test_error_handling)
    ]
    
    results = []
    failed = []
    
    for name, test_func in tests:
        try:
            success, message = test_func()
            if success:
                results.append(f"âœ… {name}: {message}")
            else:
                results.append(f"âŒ {name}: {message}")
                failed.append(name)
        except Exception as e:
            results.append(f"âŒ {name}: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ - {str(e)}")
            failed.append(name)
    
    # ìµœì¢… ê²°ê³¼
    print("\n" + "="*80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    
    for result in results:
        print(result)
    
    print("\n" + "="*80)
    total = len(tests)
    passed = total - len(failed)
    print(f"âœ… ì„±ê³µ: {passed}/{total}")
    print(f"âŒ ì‹¤íŒ¨: {len(failed)}/{total}")
    
    if failed:
        print(f"\nì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {', '.join(failed)}")
    else:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    
    print("="*80)

if __name__ == "__main__":
    run_all_tests()