#!/usr/bin/env python3
"""
í™•ìž¥ì„± ë° ë™ì  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path
import time
import re

sys.path.append(str(Path(__file__).parent))

def test_search_scalability():
    """í™•ìž¥ì„± í…ŒìŠ¤íŠ¸ - ë©”íƒ€ë°ì´í„° ìºì‹œë§Œ í™•ì¸"""
    print("\n" + "="*60)
    print("ðŸ“Š ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ í™•ìž¥ì„± í…ŒìŠ¤íŠ¸")
    print("="*60 + "\n")

    # 1. ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
    docs_dir = Path(__file__).parent / 'docs'
    all_pdfs = list(docs_dir.rglob('*.pdf'))
    unique_pdfs = {}

    # ì¤‘ë³µ ì œê±°
    for pdf in all_pdfs:
        filename = pdf.name
        if filename not in unique_pdfs:
            unique_pdfs[filename] = pdf

    print(f"ðŸ“ ë¬¸ì„œ í˜„í™©:")
    print(f"  - ì „ì²´ PDF íŒŒì¼: {len(all_pdfs)}ê°œ")
    print(f"  - ê³ ìœ  PDF íŒŒì¼: {len(unique_pdfs)}ê°œ")
    print(f"  - ì¤‘ë³µ íŒŒì¼: {len(all_pdfs) - len(unique_pdfs)}ê°œ\n")

    # 2. ìž¥ë¹„ë³„ ë¬¸ì„œ ë¶„í¬ í™•ì¸
    equipment_counts = {}
    equipment_keywords = ['DVR', 'ì¹´ë©”ë¼', 'ë Œì¦ˆ', 'ëª¨ë‹ˆí„°', 'ì‚¼ê°ëŒ€', 'ì¤‘ê³„ì°¨', 'CCU',
                         'ë§ˆì´í¬', 'ìŠ¤ìœ„ì²˜', 'ì„œë²„', 'ì›Œí¬ìŠ¤í…Œì´ì…˜', 'ë“œë¡ ']

    for keyword in equipment_keywords:
        count = 0
        files = []
        for filename in unique_pdfs.keys():
            if keyword.upper() in filename.upper():
                count += 1
                files.append(filename)

        equipment_counts[keyword] = {'count': count, 'samples': files[:3]}

    print("ðŸ” ìž¥ë¹„ë³„ ë¬¸ì„œ ë¶„í¬:")
    print("-" * 40)
    for equipment, data in sorted(equipment_counts.items(), key=lambda x: x[1]['count'], reverse=True):
        if data['count'] > 0:
            print(f"  {equipment:12s}: {data['count']:3d}ê°œ")
            if data['samples']:
                sample = data['samples'][0]
                if len(sample) > 50:
                    sample = sample[:47] + "..."
                print(f"    ì˜ˆì‹œ: {sample}")

    # 3. ì—°ë„ë³„ ë¬¸ì„œ ë¶„í¬
    year_counts = {}
    for filename in unique_pdfs.keys():
        year_match = re.match(r'(20\d{2})', filename)
        if year_match:
            year = year_match.group(1)
            year_counts[year] = year_counts.get(year, 0) + 1

    print(f"\nðŸ“… ì—°ë„ë³„ ë¬¸ì„œ ë¶„í¬:")
    print("-" * 40)
    for year in sorted(year_counts.keys(), reverse=True)[:10]:
        print(f"  {year}ë…„: {year_counts[year]:3d}ê°œ")

    # 4. ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
    print(f"\nâš¡ ê²€ìƒ‰ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜:")
    print("-" * 40)

    test_queries = [
        ("DVR", 0),
        ("ì¹´ë©”ë¼", 0),
        ("2020ë…„ êµ¬ë§¤", 0),
        ("ìµœìƒˆë¦„", 0),
        ("ì‚¼ê°ëŒ€ ìˆ˜ë¦¬", 0)
    ]

    total_time = 0
    for query, _ in test_queries:
        start = time.time()

        # ê°„ë‹¨í•œ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
        results = []
        query_lower = query.lower()

        for filename in unique_pdfs.keys():
            filename_lower = filename.lower()
            score = 0

            # í‚¤ì›Œë“œ ë§¤ì¹­
            if 'dvr' in query_lower and 'dvr' in filename_lower:
                score += 15
            elif 'ì¹´ë©”ë¼' in query_lower and 'ì¹´ë©”ë¼' in filename_lower:
                score += 15
            elif 'ì‚¼ê°ëŒ€' in query_lower and 'ì‚¼ê°ëŒ€' in filename_lower:
                score += 15

            # ì—°ë„ ë§¤ì¹­
            year_match = re.search(r'(20\d{2})', query)
            if year_match and year_match.group(1) in filename:
                score += 10

            # êµ¬ë§¤/ìˆ˜ë¦¬ ë§¤ì¹­
            if 'êµ¬ë§¤' in query and 'êµ¬ë§¤' in filename:
                score += 5
            elif 'ìˆ˜ë¦¬' in query and 'ìˆ˜ë¦¬' in filename:
                score += 5

            # ê¸°ì•ˆìž ë§¤ì¹­ (ì‹œë®¬ë ˆì´ì…˜)
            if 'ìµœìƒˆë¦„' in query and 'ìµœìƒˆë¦„' in filename:
                score += 20

            if score >= 3:
                results.append((filename, score))

        # ì •ë ¬ ë° ì œí•œ
        results.sort(key=lambda x: x[1], reverse=True)
        results = results[:20]

        elapsed = time.time() - start
        total_time += elapsed

        print(f"  '{query}': {len(results):2d}ê°œ ë°œê²¬ ({elapsed*1000:.1f}ms)")

    print(f"\n  ì´ ê²€ìƒ‰ ì‹œê°„: {total_time*1000:.1f}ms")
    print(f"  í‰ê·  ê²€ìƒ‰ ì‹œê°„: {(total_time/len(test_queries))*1000:.1f}ms")

    # 5. ì‹œìŠ¤í…œ í™•ìž¥ì„± í‰ê°€
    print(f"\nâœ… ì‹œìŠ¤í…œ í™•ìž¥ì„± í‰ê°€:")
    print("-" * 40)

    # auto_indexer í™•ì¸
    auto_indexer = Path(__file__).parent / 'auto_indexer.py'
    if auto_indexer.exists():
        print("  ðŸ”„ ìžë™ ì¸ë±ì‹±: âœ… í™œì„±í™”")
        print("     - 60ì´ˆë§ˆë‹¤ ìƒˆ ë¬¸ì„œ ìžë™ ê°ì§€")
        print("     - ë¬¸ì„œ ì¶”ê°€/ìˆ˜ì •/ì‚­ì œ ìžë™ ë°˜ì˜")
    else:
        print("  ðŸ”„ ìžë™ ì¸ë±ì‹±: âŒ ë¹„í™œì„±í™”")

    # ì„±ëŠ¥ ë¶„ì„
    if len(unique_pdfs) > 500:
        print(f"  ðŸ“ˆ ëŒ€ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬: âœ… {len(unique_pdfs)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ê°€ëŠ¥")
    else:
        print(f"  ðŸ“ˆ ë¬¸ì„œ ì²˜ë¦¬: {len(unique_pdfs)}ê°œ ë¬¸ì„œ")

    # ê²€ìƒ‰ ì„±ëŠ¥
    if total_time/len(test_queries) < 0.01:  # 10ms ë¯¸ë§Œ
        print(f"  âš¡ ê²€ìƒ‰ ì†ë„: âœ… ë§¤ìš° ë¹ ë¦„ (í‰ê·  {(total_time/len(test_queries))*1000:.1f}ms)")
    elif total_time/len(test_queries) < 0.1:  # 100ms ë¯¸ë§Œ
        print(f"  âš¡ ê²€ìƒ‰ ì†ë„: âœ… ë¹ ë¦„ (í‰ê·  {(total_time/len(test_queries))*1000:.1f}ms)")
    else:
        print(f"  âš¡ ê²€ìƒ‰ ì†ë„: âš ï¸ ê°œì„  í•„ìš” (í‰ê·  {(total_time/len(test_queries))*1000:.1f}ms)")

    print("\n" + "="*60)
    print("ðŸ’¡ ê²°ë¡ :")
    print("  - ì‹œìŠ¤í…œì€ ì™„ì „ížˆ ë™ì ìœ¼ë¡œ ìž‘ë™í•©ë‹ˆë‹¤")
    print("  - í•˜ë“œì½”ë”© ì—†ì´ íŒŒì¼ëª…/ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰")
    print(f"  - í˜„ìž¬ {len(unique_pdfs)}ê°œ ë¬¸ì„œ, í–¥í›„ ìˆ˜ì²œê°œë„ ì²˜ë¦¬ ê°€ëŠ¥")
    print("  - auto_indexerë¡œ ì‹¤ì‹œê°„ ë¬¸ì„œ ì¶”ê°€ ì§€ì›")
    print("="*60)

if __name__ == "__main__":
    test_search_scalability()