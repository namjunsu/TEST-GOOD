#!/usr/bin/env python3
"""
ë°±ê·¸ë¼ìš´ë“œ OCR ì²˜ë¦¬ ì‹œìŠ¤í…œ
- ìŠ¤ìº” PDFë¥¼ ì ì§„ì ìœ¼ë¡œ ì²˜ë¦¬
- ë©”íƒ€ë°ì´í„° DBì— ê²°ê³¼ ì €ì¥
"""

import time
import logging
from pathlib import Path
from typing import List, Dict, Optional, Set
import pdfplumber
from metadata_manager import MetadataManager
import threading
import json
from functools import lru_cache

logger = logging.getLogger(__name__)

class BackgroundOCRProcessor:
    # ìƒìˆ˜ ì •ì˜
    DEFAULT_BATCH_SIZE = 10
    DEFAULT_INTERVAL = 60  # ì´ˆ
    MIN_TEXT_LENGTH = 50  # ìŠ¤ìº” PDF íŒë‹¨ ê¸°ì¤€
    THREAD_JOIN_TIMEOUT = 5  # ì´ˆ
    MAX_FILENAME_DISPLAY = 50  # íŒŒì¼ëª… í‘œì‹œ ê¸¸ì´

    # ê¸°ì•ˆì ë§¤í•‘ (ì‹¤ì œë¡œëŠ” ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œí•´ì•¼ í•¨)
    DRAFTER_HINTS = {
        'ìµœìƒˆë¦„': 'ìµœìƒˆë¦„',
        'ë‚¨ì¤€ìˆ˜': 'ë‚¨ì¤€ìˆ˜',
        'ìœ ì¸í˜': 'ìœ ì¸í˜'
    }

    def __init__(self, batch_size: int = None, interval: int = None):
        self.batch_size = batch_size if batch_size is not None else self.DEFAULT_BATCH_SIZE
        self.interval = interval if interval is not None else self.DEFAULT_INTERVAL
        self.metadata_db = MetadataManager()
        self.running = False
        self.thread: Optional[threading.Thread] = None
        self.processed_count = 0

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self._start_time: Optional[float] = None
        self._total_processing_time = 0.0
        self._error_count = 0
        self._processed_files: Set[str] = set()  # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€

    def identify_scanned_pdfs(self) -> List[Path]:
        """ì²˜ë¦¬ê°€ í•„ìš”í•œ ìŠ¤ìº” PDF ì°¾ê¸° (ì„±ëŠ¥ ìµœì í™”)"""
        scanned_pdfs: List[Path] = []
        docs_dir = Path('docs')

        if not docs_dir.exists():
            logger.warning(f"docs ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            return scanned_pdfs

        for pdf_path in docs_dir.rglob('*.pdf'):
            filename = pdf_path.name

            # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ìŠ¤í‚µ
            if filename in self._processed_files:
                continue

            # ì´ë¯¸ DBì— ìˆê³  ê¸°ì•ˆì ì •ë³´ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
            db_info = self.metadata_db.get_document(filename)
            if db_info and db_info.get('drafter'):
                self._processed_files.add(filename)
                continue

            # ìŠ¤ìº” PDFì¸ì§€ í™•ì¸
            if self._is_scanned_pdf(pdf_path):
                scanned_pdfs.append(pdf_path)

        return scanned_pdfs

    @lru_cache(maxsize=256)
    def _is_scanned_pdf(self, pdf_path: Path) -> bool:
        """ìŠ¤ìº” PDFì¸ì§€ í™•ì¸ (ìºì‹œë¨)"""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                if pdf.pages:
                    text = pdf.pages[0].extract_text() or ""
                    return len(text.strip()) < self.MIN_TEXT_LENGTH
        except Exception as e:
            logger.debug(f"PDF í™•ì¸ ì‹¤íŒ¨: {pdf_path.name} - {e}")
        return False

    def process_batch(self) -> bool:
        """ë°°ì¹˜ ì²˜ë¦¬ (ì„±ëŠ¥ ì¶”ì  í¬í•¨)"""
        batch_start_time = time.time()
        scanned_pdfs = self.identify_scanned_pdfs()

        if not scanned_pdfs:
            logger.info("ëª¨ë“  PDF ì²˜ë¦¬ ì™„ë£Œ!")
            return False

        logger.info(f"ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ìº” PDF: {len(scanned_pdfs)}ê°œ")

        # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ì²˜ë¦¬
        batch = scanned_pdfs[:self.batch_size]

        for pdf_path in batch:
            filename = pdf_path.name
            display_name = filename[:self.MAX_FILENAME_DISPLAY] + ('...' if len(filename) > self.MAX_FILENAME_DISPLAY else '')
            logger.debug(f"ì²˜ë¦¬ ì¤‘: {display_name}")

            try:
                # OCR ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” OCR ì²˜ë¦¬)
                metadata = self._extract_metadata(filename)

                # DBì— ì €ì¥
                self.metadata_db.add_document(filename, **metadata)
                self.processed_count += 1
                self._processed_files.add(filename)

                logger.debug(f"ì™„ë£Œ: {display_name}")

            except Exception as e:
                self._error_count += 1
                logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {filename} - {e}")

        # ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        batch_time = time.time() - batch_start_time
        self._total_processing_time += batch_time

        logger.info(f"ì´ë²ˆ ë°°ì¹˜: {len(batch)}ê°œ ì²˜ë¦¬ ({batch_time:.2f}ì´ˆ)")
        logger.info(f"ëˆ„ì  ì²˜ë¦¬: {self.processed_count}ê°œ, ì˜¤ë¥˜: {self._error_count}ê°œ")

        return True  # ê³„ì† ì²˜ë¦¬ í•„ìš”

    def _extract_metadata(self, filename: str) -> Dict[str, any]:
        """íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {
            'status': 'scanned',
            'needs_ocr': True,
            'processed': time.time()
        }

        # íŒŒì¼ëª…ì—ì„œ ê¸°ì•ˆì íŒíŠ¸ ì°¾ê¸°
        for hint, drafter in self.DRAFTER_HINTS.items():
            if hint in filename:
                metadata['drafter'] = drafter
                break

        return metadata

    def run_background(self) -> None:
        """ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰"""
        logger.info("ë°±ê·¸ë¼ìš´ë“œ OCR ì²˜ë¦¬ ì‹œì‘")
        logger.info(f"ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ, ì²˜ë¦¬ ê°„ê²©: {self.interval}ì´ˆ")
        self._start_time = time.time()

        while self.running:
            has_more = self.process_batch()

            if not has_more:
                logger.info("ëª¨ë“  ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!")
                break

            # ëŒ€ê¸°
            logger.debug(f"{self.interval}ì´ˆ í›„ ë‹¤ìŒ ë°°ì¹˜ ì²˜ë¦¬...")
            time.sleep(self.interval)

        logger.info("ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì¢…ë£Œ")

    def start(self) -> None:
        """ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹œì‘"""
        if self.running:
            logger.warning("ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return

        self.running = True
        self.thread = threading.Thread(target=self.run_background, daemon=True)
        self.thread.start()

    def stop(self) -> None:
        """ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì¤‘ì§€"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=self.THREAD_JOIN_TIMEOUT)

    def get_stats(self) -> Dict[str, any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        uptime = time.time() - self._start_time if self._start_time else 0
        avg_time_per_file = (self._total_processing_time / self.processed_count
                            if self.processed_count > 0 else 0)

        return {
            'processed_count': self.processed_count,
            'error_count': self._error_count,
            'uptime_seconds': uptime,
            'total_processing_time': self._total_processing_time,
            'avg_time_per_file': avg_time_per_file,
            'cached_files': len(self._processed_files),
            'batch_size': self.batch_size,
            'interval': self.interval
        }


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    processor = BackgroundOCRProcessor(batch_size=5, interval=10)

    # í˜„ì¬ ìƒíƒœ í™•ì¸
    scanned = processor.identify_scanned_pdfs()
    print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ:")
    print(f"  - ì²˜ë¦¬ í•„ìš”í•œ ìŠ¤ìº” PDF: {len(scanned)}ê°œ")

    if len(scanned) > 0:
        print(f"\nìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
        for pdf in scanned[:5]:
            print(f"  - {pdf.name}")

        # í•œ ë²ˆë§Œ ë°°ì¹˜ ì²˜ë¦¬
        print("\nğŸ”§ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬ (5ê°œ)...")
        processor.process_batch()

        # í†µê³„ ì¶œë ¥
        stats = processor.get_stats()
        print("\nâš¡ ì²˜ë¦¬ í†µê³„:")
        print(f"  - ì²˜ë¦¬ëœ íŒŒì¼: {stats['processed_count']}ê°œ")
        print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {stats['avg_time_per_file']:.3f}ì´ˆ/íŒŒì¼")

    else:
        print("âœ… ëª¨ë“  ë¬¸ì„œê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")