"""
ì¿¼ë¦¬ í™•ì¥ (Query Expansion) ëª¨ë“ˆ
Advanced RAG ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ, ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í™•ì¥í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
"""

import logging
import time
import hashlib
from functools import lru_cache
from typing import List, Dict, Any, Set, Tuple
import re
from collections import defaultdict

class QueryExpansion:
    """ì¿¼ë¦¬ í™•ì¥ ëª¨ë“ˆ"""
    
    # ìƒìˆ˜ ì •ì˜
    MAX_SYNONYMS_EXPANSIONS = 3
    MAX_PATTERN_EXPANSIONS = 2
    MAX_MORPHOLOGY_EXPANSIONS = 2
    DEFAULT_METHODS = ['synonyms', 'abbreviations', 'patterns', 'morphology']
    WORD_PATTERN = r'[ê°€-í£a-zA-Z0-9]+'
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # ì„±ëŠ¥ í†µê³„
        self.expansion_count = 0
        self.total_expansion_time = 0.0
        self.method_usage = defaultdict(int)
        self.cache_hits = 0
        self.cache_misses = 0

        # í•œêµ­ì–´ ë°©ì†¡ê¸°ìˆ  ë„ë©”ì¸ ë™ì˜ì–´ ì‚¬ì „
        self.synonyms = {
            # ì¥ë¹„ ê´€ë ¨
            'ì›Œí¬ìŠ¤í…Œì´ì…˜': ['ì›Œí¬ìŠ¤í…Œì´ì…˜', 'ì»´í“¨í„°', 'PC', 'í¸ì§‘ê¸°', 'ì‘ì—…ìš©ì»´í“¨í„°'],
            'ëª¨ë‹ˆí„°': ['ëª¨ë‹ˆí„°', 'ë””ìŠ¤í”Œë ˆì´', 'í™”ë©´', 'ìŠ¤í¬ë¦°', 'ì˜ìƒí‘œì‹œì¥ì¹˜'],
            'ì¹´ë©”ë¼': ['ì¹´ë©”ë¼', 'ìº ', 'ì´¬ì˜ê¸°', 'ì˜ìƒê¸°', 'ë°©ì†¡ì¹´ë©”ë¼'],
            'ë§ˆì´í¬': ['ë§ˆì´í¬', 'ë§ˆì´í¬ë¡œí°', 'ìŒì„±ì…ë ¥', 'ìŒí–¥ì¥ë¹„', 'í•€ë§ˆì´í¬'],
            'ì¼€ì´ë¸”': ['ì¼€ì´ë¸”', 'ì„ ', 'ì—°ê²°ì„ ', 'ì¼€ì´ë¸”ë¥˜', 'ë°°ì„ '],
            'ì‚¼ê°ëŒ€': ['ì‚¼ê°ëŒ€', 'íŠ¸ë¼ì´í¬ë“œ', 'ê±°ì¹˜ëŒ€', 'ìŠ¤íƒ ë“œ'],
            'ë“œë¡ ': ['ë“œë¡ ', 'ë¬´ì¸í•­ê³µê¸°', 'í—¬ë¦¬ìº ', 'í•­ê³µì´¬ì˜ê¸°'],
            'ì¡°ëª…': ['ì¡°ëª…', 'ë¼ì´íŠ¸', 'ì¡°ëª…ê¸°', 'ë¼ì´íŒ…', 'LED'],
            
            # ê°€ê²© ê´€ë ¨
            'ê°€ê²©': ['ê°€ê²©', 'ê¸ˆì•¡', 'ë¹„ìš©', 'ì˜ˆì‚°', 'êµ¬ë§¤ë¹„', 'ì´ì•¡'],
            'ë¹„ìš©': ['ë¹„ìš©', 'ê°€ê²©', 'ê¸ˆì•¡', 'ì˜ˆì‚°', 'ì†Œìš”ë¹„ìš©', 'êµ¬ë§¤ë¹„'],
            'ê¸ˆì•¡': ['ê¸ˆì•¡', 'ê°€ê²©', 'ë¹„ìš©', 'ì˜ˆì‚°', 'ì´ì•¡', 'êµ¬ë§¤ê¸ˆì•¡'],
            
            # ë¸Œëœë“œ ê´€ë ¨
            'HP': ['HP', 'íœ´ë ›íŒ©ì»¤ë“œ', 'Hewlett-Packard'],
            'LG': ['LG', 'ì—˜ì§€', 'LGì „ì'],
            'TVLogic': ['TVLogic', 'í‹°ë¹„ë¡œì§', 'TV Logic'],
            'Sony': ['Sony', 'ì†Œë‹ˆ'],
            'Canon': ['Canon', 'ìºë…¼'],
            
            # ê¸°ìˆ  ìš©ì–´
            'êµì²´': ['êµì²´', 'ëŒ€ì²´', 'ë³€ê²½', 'ì—…ê·¸ë ˆì´ë“œ', 'ê°±ì‹ '],
            'êµ¬ë§¤': ['êµ¬ë§¤', 'êµ¬ì…', 'ì¡°ë‹¬', 'ë„ì…', 'ë§¤ì…'],
            'ìˆ˜ë¦¬': ['ìˆ˜ë¦¬', 'ì •ë¹„', 'ë³´ìˆ˜', 'ìˆ˜ì„ ', 'ë³µêµ¬'],
            'ì„¤ì¹˜': ['ì„¤ì¹˜', 'êµ¬ì¶•', 'ë„ì…', 'ë°°ì¹˜', 'ì…‹ì—…']
        }
        
        # ê¸°ìˆ  ì•½ì–´ ì‚¬ì „
        self.abbreviations = {
            'NLE': 'ì˜ìƒí¸ì§‘',
            'ENG': 'ë‰´ìŠ¤ì·¨ì¬',
            'SDI': 'ì˜ìƒì‹ í˜¸',
            'HDMI': 'ì˜ìƒì—°ê²°',
            'BNC': 'ë™ì¶•ì»¤ë„¥í„°',
            'UTP': 'ë„¤íŠ¸ì›Œí¬ì¼€ì´ë¸”',
            'LED': 'ë°œê´‘ë‹¤ì´ì˜¤ë“œ'
        }
        
        # ê´€ë ¨ ìš©ì–´ í™•ì¥ íŒ¨í„´
        self.expansion_patterns = {
            'ìµœê·¼': ['ìµœê·¼', 'ìµœì‹ ', 'ì‹ ê·œ', 'ìƒˆë¡œìš´', '2024', '2025'],
            'ê³ ì•¡': ['ê³ ì•¡', 'ë¹„ì‹¼', 'ê³ ê°€', 'ëŒ€í˜•', 'í°'],
            'ì¥ë¹„': ['ì¥ë¹„', 'ê¸°ê¸°', 'ê¸°êµ¬', 'ë„êµ¬', 'ì‹œì„¤'],
            'ë¬¸ì„œ': ['ë¬¸ì„œ', 'ê¸°ì•ˆì„œ', 'ë³´ê³ ì„œ', 'ê²€í† ì„œ', 'ê³„íšì„œ']
        }
        
        # í˜•íƒœì†Œ íŒ¨í„´ ì´ˆê¸°í™”
        self._init_morphology_patterns()
        self._compile_patterns()

    def _init_morphology_patterns(self):
        """í˜•íƒœì†Œ ë³€í˜• íŒ¨í„´ ì´ˆê¸°í™”"""
        self.morphology_patterns = [
            (r'(\w+)ì„', r'\1ë¥¼'),
            (r'(\w+)ë¥¼', r'\1ì„'),
            (r'(\w+)ì´', r'\1ê°€'),
            (r'(\w+)ê°€', r'\1ì´'),
            (r'(\w+)ì€', r'\1ëŠ”'),
            (r'(\w+)ëŠ”', r'\1ì€'),
            (r'(\w+)ì—ì„œ', r'\1ì˜'),
            (r'(\w+)ì˜', r'\1ì—ì„œ')
        ]

    def _compile_patterns(self):
        """ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼"""
        # ë‹¨ì–´ ì¶”ì¶œ íŒ¨í„´ ì»´íŒŒì¼
        self.compiled_word_pattern = re.compile(self.WORD_PATTERN)

        # í˜•íƒœì†Œ íŒ¨í„´ ì»´íŒŒì¼
        self.compiled_morphology = [(re.compile(p), r) for p, r in self.morphology_patterns]

        # ë™ì˜ì–´ ì—­ ì¸ë±ìŠ¤ êµ¬ì¶• (ë¹ ë¥¸ ê²€ìƒ‰ìš©)
        self.synonym_index = {}
        for key, synonyms in self.synonyms.items():
            for synonym in synonyms:
                if synonym not in self.synonym_index:
                    self.synonym_index[synonym] = []
                self.synonym_index[synonym].append(key)

        self.logger.info(f"íŒ¨í„´ ì»´íŒŒì¼ ì™„ë£Œ: {len(self.compiled_morphology)}ê°œ í˜•íƒœì†Œ íŒ¨í„´, {len(self.synonym_index)}ê°œ ë™ì˜ì–´ ì¸ë±ìŠ¤")
        
    def expand_query(self, query: str, methods: List[str] = None) -> Dict[str, Any]:
        """ì¿¼ë¦¬ë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í™•ì¥ (ìºì‹±ë¨)"""
        if methods is None:
            methods = self.DEFAULT_METHODS

        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = hashlib.md5(f"{query}:{':'.join(sorted(methods))}".encode()).hexdigest()
        return self._expand_query_cached(cache_key, query, tuple(methods))

    @lru_cache(maxsize=512)
    def _expand_query_cached(self, cache_key: str, query: str, methods: Tuple[str]) -> Dict[str, Any]:
        """ì‹¤ì œ ì¿¼ë¦¬ í™•ì¥ (ìºì‹±ë¨)"""
        start_time = time.time()
        methods = list(methods)  # íŠœí”Œì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        expansion_result = {
            'original_query': query,
            'expanded_queries': [],
            'expansion_methods': {},  # ë©”ì„œë“œë³„ë¡œ í™•ì¥ ê²°ê³¼ ì €ì¥
            'methods_used': methods,
            'processing_time': 0.0
        }
        
        try:
            # í™•ì¥ ë©”ì„œë“œ ë§¤í•‘
            expansion_methods = {
                'synonyms': self._expand_with_synonyms,
                'abbreviations': self._expand_abbreviations,
                'patterns': self._expand_with_patterns,
                'morphology': self._expand_morphology
            }
            
            # ê° ë©”ì„œë“œ ì‹¤í–‰
            for method in methods:
                if method in expansion_methods:
                    method_expansions = expansion_methods[method](query)
                    expansion_result['expansion_methods'][method] = method_expansions
                    expansion_result['expanded_queries'].extend(method_expansions)
            
            # ì¤‘ë³µ ì œê±°
            unique_queries = []
            seen = set()
            for q in [query] + expansion_result['expanded_queries']:
                if q not in seen:
                    unique_queries.append(q)
                    seen.add(q)
            
            expansion_result['expanded_queries'] = unique_queries[1:]  # ì›ë³¸ ì œì™¸
            expansion_result['total_queries'] = len(unique_queries)
            expansion_result['processing_time'] = time.time() - start_time

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.expansion_count += 1
            self.total_expansion_time += expansion_result['processing_time']
            for method in methods:
                self.method_usage[method] += 1

            self.logger.info(
                f"ì¿¼ë¦¬ í™•ì¥ ì™„ë£Œ: '{query}' â†’ {len(unique_queries)}ê°œ ì¿¼ë¦¬ "
                f"(ì‹œê°„: {expansion_result['processing_time']:.3f}ì´ˆ)"
            )

            return expansion_result
            
        except Exception as e:
            self.logger.error(f"ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            expansion_result['processing_time'] = time.time() - start_time
            return expansion_result
    
    def _expand_with_synonyms(self, query: str) -> List[str]:
        """ë™ì˜ì–´ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥ (ìµœì í™”)"""
        expanded = []
        words = self.compiled_word_pattern.findall(query)

        # ë™ì˜ì–´ ì¸ë±ìŠ¤ í™œìš©
        for word in words:
            if word in self.synonym_index:
                # í•´ë‹¹ ë‹¨ì–´ê°€ ì†í•œ ë™ì˜ì–´ ê·¸ë£¹ë“¤ì„ ì°¾ìŒ
                for synonym_key in self.synonym_index[word]:
                    for synonym in self.synonyms[synonym_key]:
                        if synonym != word:  # ì›ë³¸ê³¼ ë‹¤ë¥¸ ê²½ìš°ë§Œ
                            new_query = query.replace(word, synonym)
                            if new_query != query and new_query not in expanded:
                                expanded.append(new_query)

        return self._limit_expansions(expanded, self.MAX_SYNONYMS_EXPANSIONS)
    
    def _expand_abbreviations(self, query: str) -> List[str]:
        """ì•½ì–´ í™•ì¥"""
        expanded = []
        
        for abbr, full_form in self.abbreviations.items():
            if abbr in query:
                expanded_query = query.replace(abbr, full_form)
                expanded.append(expanded_query)
            elif full_form in query:
                expanded_query = query.replace(full_form, abbr)
                expanded.append(expanded_query)
        
        return expanded
    
    def _expand_with_patterns(self, query: str) -> List[str]:
        """íŒ¨í„´ ê¸°ë°˜ í™•ì¥"""
        expanded = []
        
        for pattern, alternatives in self.expansion_patterns.items():
            if pattern in query:
                for alt in alternatives:
                    if alt != pattern:
                        new_query = query.replace(pattern, alt)
                        expanded.append(new_query)
        
        return self._limit_expansions(expanded, self.MAX_PATTERN_EXPANSIONS)
    
    def _expand_morphology(self, query: str) -> List[str]:
        """í˜•íƒœì†Œ ê¸°ë°˜ í™•ì¥ (í•œêµ­ì–´ íŠ¹í™”, ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)"""
        expanded = []

        for pattern, replacement in self.compiled_morphology:
            new_query = pattern.sub(replacement, query)
            if new_query != query and new_query not in expanded:
                expanded.append(new_query)

        return self._limit_expansions(expanded, self.MAX_MORPHOLOGY_EXPANSIONS)
    
    def get_expansion_statistics(self, expansion_result: Dict[str, Any]) -> Dict[str, Any]:
        """í™•ì¥ í†µê³„ ì •ë³´"""
        stats = {
            'original_length': len(expansion_result['original_query']),
            'total_expansions': len(expansion_result['expanded_queries']),
            'methods_breakdown': {},
            'processing_time': expansion_result['processing_time'],
            'expansion_ratio': 0.0
        }
        
        # ë°©ë²•ë³„ í†µê³„ (ê°œì„ ëœ ë²„ì „)
        if 'expansion_methods' in expansion_result:
            for method, expansions in expansion_result['expansion_methods'].items():
                stats['methods_breakdown'][method] = len(expansions)
        
        # í™•ì¥ ë¹„ìœ¨
        if expansion_result['original_query']:
            total_chars = sum(len(q) for q in expansion_result['expanded_queries'])
            stats['expansion_ratio'] = total_chars / len(expansion_result['original_query'])
        
        return stats
    
    def _limit_expansions(self, expansions: List[str], max_count: int) -> List[str]:
        """í™•ì¥ ê²°ê³¼ë¥¼ ìµœëŒ€ ê°œìˆ˜ë¡œ ì œí•œ"""
        return expansions[:max_count]

    def get_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = {
            'expansion_count': self.expansion_count,
            'total_expansion_time': self.total_expansion_time,
            'avg_expansion_time': self.total_expansion_time / self.expansion_count if self.expansion_count > 0 else 0.0,
            'method_usage': dict(self.method_usage),
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'cache_hit_rate': self.cache_hits / (self.cache_hits + self.cache_misses) * 100 if (self.cache_hits + self.cache_misses) > 0 else 0.0,
            'cache_info': self._expand_query_cached.cache_info() if hasattr(self._expand_query_cached, 'cache_info') else None,
            'synonym_index_size': len(self.synonym_index),
            'compiled_patterns': len(self.compiled_morphology)
        }
        return stats

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_query_expansion():
    """ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ì¿¼ë¦¬ í™•ì¥ê¸° ì´ˆê¸°í™”
        expander = QueryExpansion()
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "HP Z8 ì›Œí¬ìŠ¤í…Œì´ì…˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ìµœê·¼ ëª¨ë‹ˆí„° êµì²´ ë¹„ìš©",
            "NLE ì¥ë¹„ êµ¬ë§¤ ê³„íš",
            "ì¹´ë©”ë¼ë¥¼ ìˆ˜ë¦¬í•œ ë¬¸ì„œ",
            "ê°€ì¥ ê³ ì•¡ì¸ ì¥ë¹„"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” ì›ë³¸ ì¿¼ë¦¬: '{query}'")
            
            # ì¿¼ë¦¬ í™•ì¥
            result = expander.expand_query(query)
            
            print(f"ğŸ“Š í™•ì¥ëœ ì¿¼ë¦¬ ìˆ˜: {len(result['expanded_queries'])}")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")
            
            # í™•ì¥ëœ ì¿¼ë¦¬ë“¤ ì¶œë ¥
            for i, expanded in enumerate(result['expanded_queries'][:5], 1):
                # ì–´ëŠ ë©”ì„œë“œì—ì„œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì°¾ê¸°
                method_name = 'unknown'
                if 'expansion_methods' in result:
                    for method, expansions in result['expansion_methods'].items():
                        if expanded in expansions:
                            method_name = method
                            break
                print(f"  {i}. [{method_name}] {expanded}")
            
            # í†µê³„ ì •ë³´
            stats = expander.get_expansion_statistics(result)
            print(f"ğŸ“ˆ ë°©ë²•ë³„ í™•ì¥ ìˆ˜: {stats['methods_breakdown']}")
            print(f"ğŸ“ í™•ì¥ ë¹„ìœ¨: {stats['expansion_ratio']:.2f}")
        
        print("\nâœ… ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    test_query_expansion()