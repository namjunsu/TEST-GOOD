#!/usr/bin/env python3
"""
AI-CHAT-V3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
Qwen2.5-7B-Instruct GGUF ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ

ì‚¬ìš©ë²•:
    python3 download_models.py
    python3 download_models.py --model-dir ./models
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from typing import Optional
import hashlib

def install_huggingface_hub():
    """huggingface_hub íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
    try:
        import huggingface_hub
        return True
    except ImportError:
        print("ğŸ“¦ huggingface-hub íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "huggingface-hub"])
            import huggingface_hub
            return True
        except Exception as e:
            print(f"âŒ huggingface-hub ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
            return False

def get_file_size_mb(filepath: Path) -> float:
    """íŒŒì¼ í¬ê¸°ë¥¼ MB ë‹¨ìœ„ë¡œ ë°˜í™˜"""
    if filepath.exists():
        return filepath.stat().st_size / (1024 * 1024)
    return 0

def verify_file_size(filepath: Path, expected_mb: float, tolerance: float = 10.0) -> bool:
    """íŒŒì¼ í¬ê¸° ê²€ì¦ (tolerance MB ì˜¤ì°¨ í—ˆìš©)"""
    if not filepath.exists():
        return False
    
    actual_mb = get_file_size_mb(filepath)
    diff = abs(actual_mb - expected_mb)
    
    if diff <= tolerance:
        return True
    else:
        print(f"âš ï¸  íŒŒì¼ í¬ê¸° ì´ìƒ: {filepath.name}")
        print(f"   ì˜ˆìƒ: {expected_mb:.1f}MB, ì‹¤ì œ: {actual_mb:.1f}MB, ì°¨ì´: {diff:.1f}MB")
        return False

def download_with_huggingface_hub(model_dir: Path) -> bool:
    """huggingface_hubë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    if not install_huggingface_hub():
        return False
    
    try:
        from huggingface_hub import hf_hub_download
        
        repo_id = "Qwen/Qwen2.5-7B-Instruct-GGUF"
        
        # ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ë“¤ê³¼ ì˜ˆìƒ í¬ê¸° (MB)
        files_to_download = [
            ("qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf", 3800.0),
            ("qwen2.5-7b-instruct-q4_k_m-00002-of-00002.gguf", 658.0)
        ]
        
        print(f"ğŸ“¥ Hugging Face Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {model_dir}")
        print(f"ğŸ”— Repository: {repo_id}")
        
        for filename, expected_size in files_to_download:
            filepath = model_dir / filename
            
            # ì´ë¯¸ ìˆê³  í¬ê¸°ê°€ ë§ìœ¼ë©´ ìŠ¤í‚µ
            if filepath.exists() and verify_file_size(filepath, expected_size):
                print(f"âœ… {filename} ì´ë¯¸ ì¡´ì¬ (í¬ê¸° í™•ì¸ë¨)")
                continue
            
            print(f"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ {expected_size:.0f}MB)")
            
            try:
                downloaded_path = hf_hub_download(
                    repo_id=repo_id,
                    filename=filename,
                    local_dir=str(model_dir),
                    local_dir_use_symlinks=False,
                    resume_download=True
                )
                
                if verify_file_size(Path(downloaded_path), expected_size):
                    print(f"âœ… {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                else:
                    print(f"âŒ {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ í¬ê¸°ê°€ ë‹¤ë¦„")
                    return False
                    
            except Exception as e:
                print(f"âŒ {filename} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False
        
        print("ğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ Hugging Face Hub ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def download_with_wget_curl(model_dir: Path) -> bool:
    """wget ë˜ëŠ” curlì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    base_url = "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main"
    
    files_to_download = [
        ("qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf", 3800.0),
        ("qwen2.5-7b-instruct-q4_k_m-00002-of-00002.gguf", 658.0)
    ]
    
    # wget ë˜ëŠ” curl í™•ì¸
    download_cmd = None
    if subprocess.run(["which", "wget"], capture_output=True).returncode == 0:
        download_cmd = "wget"
    elif subprocess.run(["which", "curl"], capture_output=True).returncode == 0:
        download_cmd = "curl"
    else:
        print("âŒ wget ë˜ëŠ” curlì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return False
    
    print(f"ğŸ“¥ {download_cmd}ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    for filename, expected_size in files_to_download:
        filepath = model_dir / filename
        url = f"{base_url}/{filename}"
        
        # ì´ë¯¸ ìˆê³  í¬ê¸°ê°€ ë§ìœ¼ë©´ ìŠ¤í‚µ
        if filepath.exists() and verify_file_size(filepath, expected_size):
            print(f"âœ… {filename} ì´ë¯¸ ì¡´ì¬ (í¬ê¸° í™•ì¸ë¨)")
            continue
        
        print(f"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ {expected_size:.0f}MB)")
        
        try:
            if download_cmd == "wget":
                cmd = [
                    "wget", "--progress=bar:force:noscroll", 
                    "--continue", "-O", str(filepath), url
                ]
            else:  # curl
                cmd = [
                    "curl", "-L", "--progress-bar", 
                    "--continue-at", "-", "-o", str(filepath), url
                ]
            
            result = subprocess.run(cmd, check=True)
            
            if verify_file_size(filepath, expected_size):
                print(f"âœ… {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âŒ {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ í¬ê¸°ê°€ ë‹¤ë¦„")
                return False
                
        except subprocess.CalledProcessError as e:
            print(f"âŒ {filename} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    print("ğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    return True

def main():
    parser = argparse.ArgumentParser(description="AI-CHAT-V3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
    parser.add_argument(
        "--model-dir", 
        type=str, 
        default="./models",
        help="ëª¨ë¸ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ./models)"
    )
    parser.add_argument(
        "--method",
        choices=["auto", "huggingface", "wget"],
        default="auto",
        help="ë‹¤ìš´ë¡œë“œ ë°©ë²• ì„ íƒ (ê¸°ë³¸ê°’: auto)"
    )
    
    args = parser.parse_args()
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
    model_dir = Path(args.model_dir).resolve()
    model_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸš€ AI-CHAT-V3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    print("=" * 40)
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {model_dir}")
    
    # í˜„ì¬ ê³µê°„ í™•ì¸
    import shutil
    free_space_gb = shutil.disk_usage(model_dir).free / (1024**3)
    print(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ ê³µê°„: {free_space_gb:.1f}GB")
    
    if free_space_gb < 5:
        print("âš ï¸  ë””ìŠ¤í¬ ê³µê°„ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (5GB ì´ìƒ ê¶Œì¥)")
        response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != 'y':
            print("âŒ ë‹¤ìš´ë¡œë“œ ì·¨ì†Œë¨")
            return 1
    
    print()
    
    # ë‹¤ìš´ë¡œë“œ ë°©ë²• ì„ íƒ
    success = False
    
    if args.method == "auto":
        # 1. huggingface_hub ì‹œë„
        print("ğŸ”„ ë°©ë²• 1: Hugging Face Hub ì‹œë„...")
        success = download_with_huggingface_hub(model_dir)
        
        # 2. wget/curl ì‹œë„
        if not success:
            print("\nğŸ”„ ë°©ë²• 2: wget/curl ì‹œë„...")
            success = download_with_wget_curl(model_dir)
            
    elif args.method == "huggingface":
        success = download_with_huggingface_hub(model_dir)
    elif args.method == "wget":
        success = download_with_wget_curl(model_dir)
    
    if success:
        print("\nğŸ‰ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ìœ„ì¹˜: {model_dir}")
        
        # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í™•ì¸
        total_size = 0
        for file_path in model_dir.glob("*.gguf"):
            size_mb = get_file_size_mb(file_path)
            total_size += size_mb
            print(f"   ğŸ“„ {file_path.name}: {size_mb:.1f}MB")
        
        print(f"ğŸ’¾ ì´ í¬ê¸°: {total_size:.1f}MB ({total_size/1024:.1f}GB)")
        print("\nâœ… ì´ì œ build_index.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹œìŠ¤í…œì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return 0
    else:
        print("\nâŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        print("ğŸ’¡ í•´ê²°ë°©ë²•:")
        print("   1. ì¸í„°ë„· ì—°ê²° í™•ì¸")
        print("   2. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (5GB ì´ìƒ)")
        print("   3. ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ:")
        print("      https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/tree/main")
        return 1

if __name__ == "__main__":
    sys.exit(main())