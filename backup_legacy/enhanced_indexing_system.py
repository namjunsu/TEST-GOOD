#!/usr/bin/env python3
"""
í–¥ìƒëœ ì¸ë±ì‹± ì‹œìŠ¤í…œ
- ì¦ë¶„ ì¸ë±ì‹±
- ë³‘ë ¬ ì²˜ë¦¬
- ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
"""

import asyncio
import concurrent.futures
from pathlib import Path
from typing import List, Dict, Any
import hashlib
import json
import time
from datetime import datetime
import sqlite3
import numpy as np
from collections import defaultdict

class EnhancedIndexingSystem:
    def __init__(self, docs_dir: str = "docs", max_workers: int = 4):
        self.docs_dir = Path(docs_dir)
        self.max_workers = max_workers
        self.index_db = Path("rag_system/cache/enhanced_index.db")
        self.index_db.parent.mkdir(parents=True, exist_ok=True)

        # ì¸ë±ìŠ¤ íƒ€ì…
        self.index_types = {
            'text': {},      # í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤
            'metadata': {},  # ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤
            'vector': {},    # ë²¡í„° ì¸ë±ìŠ¤
            'asset': {}      # ìì‚° ì „ìš© ì¸ë±ìŠ¤
        }

        self._init_db()
        self.load_indexes()

    def _init_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.index_db) as conn:
            # ë¬¸ì„œ ì¸ë±ìŠ¤
            conn.execute("""
                CREATE TABLE IF NOT EXISTS document_index (
                    filepath TEXT PRIMARY KEY,
                    file_hash TEXT,
                    file_type TEXT,
                    file_size INTEGER,
                    last_modified REAL,
                    indexed_at REAL,
                    title TEXT,
                    content_hash TEXT,
                    metadata TEXT,
                    keywords TEXT,
                    category TEXT
                )
            """)

            # ìì‚° ì¸ë±ìŠ¤
            conn.execute("""
                CREATE TABLE IF NOT EXISTS asset_index (
                    equipment_id TEXT PRIMARY KEY,
                    equipment_name TEXT,
                    manufacturer TEXT,
                    model TEXT,
                    serial_number TEXT,
                    location TEXT,
                    manager TEXT,
                    purchase_date TEXT,
                    price REAL,
                    status TEXT,
                    metadata TEXT
                )
            """)

            # ê²€ìƒ‰ ì¸ë±ìŠ¤
            conn.execute("""
                CREATE TABLE IF NOT EXISTS search_index (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    filepath TEXT,
                    chunk_id INTEGER,
                    content TEXT,
                    embedding BLOB,
                    FOREIGN KEY (filepath) REFERENCES document_index(filepath)
                )
            """)

            # ì¸ë±ìŠ¤ ìƒì„±
            conn.execute("CREATE INDEX IF NOT EXISTS idx_file_hash ON document_index(file_hash)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_category ON document_index(category)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_equipment_location ON asset_index(location)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_equipment_manager ON asset_index(manager)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_search_content ON search_index(content)")

            conn.commit()

    def calculate_file_hash(self, filepath: Path) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        stat = filepath.stat()
        return hashlib.md5(f"{filepath.name}_{stat.st_size}_{stat.st_mtime}".encode()).hexdigest()

    def needs_reindex(self, filepath: Path) -> bool:
        """ì¬ì¸ë±ì‹± í•„ìš” ì—¬ë¶€ í™•ì¸"""
        current_hash = self.calculate_file_hash(filepath)

        with sqlite3.connect(self.index_db) as conn:
            cursor = conn.execute(
                "SELECT file_hash FROM document_index WHERE filepath = ?",
                (str(filepath),)
            )
            row = cursor.fetchone()

            if row and row[0] == current_hash:
                return False

        return True

    def index_document(self, filepath: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ ë¬¸ì„œ ì¸ë±ì‹±"""
        print(f"  ğŸ“„ ì¸ë±ì‹±: {filepath.name}")

        file_hash = self.calculate_file_hash(filepath)
        file_type = filepath.suffix.lower()
        metadata = {}

        # íŒŒì¼ íƒ€ì…ë³„ ì²˜ë¦¬
        if file_type == '.pdf':
            metadata = self._index_pdf(filepath)
        elif file_type == '.txt':
            metadata = self._index_txt(filepath)
        elif file_type in ['.xlsx', '.xls']:
            metadata = self._index_excel(filepath)

        # DBì— ì €ì¥
        with sqlite3.connect(self.index_db) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO document_index
                (filepath, file_hash, file_type, file_size, last_modified, indexed_at,
                 title, category, metadata, keywords)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                str(filepath),
                file_hash,
                file_type,
                filepath.stat().st_size,
                filepath.stat().st_mtime,
                time.time(),
                metadata.get('title', filepath.stem),
                metadata.get('category', 'ê¸°íƒ€'),
                json.dumps(metadata, ensure_ascii=False),
                json.dumps(metadata.get('keywords', []), ensure_ascii=False)
            ))
            conn.commit()

        return metadata

    def _index_pdf(self, filepath: Path) -> Dict:
        """PDF ë¬¸ì„œ ì¸ë±ì‹±"""
        metadata = {
            'title': filepath.stem,
            'type': 'pdf',
            'category': self._detect_category(filepath.name)
        }

        # ë‚ ì§œ ì¶”ì¶œ
        if '_' in filepath.stem:
            parts = filepath.stem.split('_', 1)
            if len(parts[0]) >= 8:
                metadata['date'] = parts[0][:10]
                metadata['year'] = parts[0][:4]

        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        if 'êµ¬ë§¤' in filepath.name:
            keywords.append('êµ¬ë§¤')
        if 'ìˆ˜ë¦¬' in filepath.name:
            keywords.append('ìˆ˜ë¦¬')
        if 'ê²€í† ' in filepath.name:
            keywords.append('ê²€í† ')

        metadata['keywords'] = keywords

        return metadata

    def _index_txt(self, filepath: Path) -> Dict:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì¸ë±ì‹± (ì£¼ë¡œ ìì‚° ë°ì´í„°)"""
        metadata = {
            'title': filepath.stem,
            'type': 'txt',
            'category': 'ìì‚°'
        }

        # ìì‚° íŒŒì¼ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if 'ìì‚°' in filepath.name or '7904' in filepath.name:
            metadata['is_asset'] = True
            metadata['asset_type'] = 'equipment_list'

            # ë¹ ë¥¸ í†µê³„ ìƒì„±
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    metadata['total_items'] = content.count('[')
                    metadata['locations'] = []

                    # ì£¼ìš” ìœ„ì¹˜ ì¶”ì¶œ
                    for location in ['ì¤‘ê³„ì°¨', 'ê´‘í™”ë¬¸', 'ëŒ€í˜•ìŠ¤íŠœë””ì˜¤', 'ì†Œí˜•ë¶€ì¡°ì •ì‹¤']:
                        if location in content:
                            metadata['locations'].append(location)

            except Exception as e:
                print(f"  âš ï¸ ìì‚° íŒŒì¼ ì¸ë±ì‹± ì˜¤ë¥˜: {e}")

        return metadata

    def _index_excel(self, filepath: Path) -> Dict:
        """ì—‘ì…€ íŒŒì¼ ì¸ë±ì‹±"""
        metadata = {
            'title': filepath.stem,
            'type': 'excel',
            'category': 'ë°ì´í„°'
        }

        if 'equipment' in filepath.name.lower():
            metadata['is_asset'] = True
            metadata['asset_type'] = 'equipment_database'

        return metadata

    def _detect_category(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€"""
        filename_lower = filename.lower()

        if 'êµ¬ë§¤' in filename_lower:
            return 'êµ¬ë§¤'
        elif 'ìˆ˜ë¦¬' in filename_lower or 'ë³´ìˆ˜' in filename_lower:
            return 'ìˆ˜ë¦¬'
        elif 'ê²€í† ' in filename_lower:
            return 'ê²€í† '
        elif 'íê¸°' in filename_lower:
            return 'íê¸°'
        elif 'ìì‚°' in filename_lower:
            return 'ìì‚°'
        else:
            return 'ê¸°íƒ€'

    def parallel_index_documents(self, filepaths: List[Path]) -> Dict[str, Any]:
        """ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ë¬¸ì„œ ì¸ë±ì‹±"""
        results = {
            'success': [],
            'failed': [],
            'skipped': []
        }

        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_filepath = {}

            for filepath in filepaths:
                if not self.needs_reindex(filepath):
                    results['skipped'].append(filepath.name)
                    continue

                future = executor.submit(self.index_document, filepath)
                future_to_filepath[future] = filepath

            for future in concurrent.futures.as_completed(future_to_filepath):
                filepath = future_to_filepath[future]
                try:
                    metadata = future.result()
                    results['success'].append(filepath.name)
                except Exception as e:
                    print(f"  âŒ {filepath.name}: {e}")
                    results['failed'].append(filepath.name)

        return results

    def build_full_index(self):
        """ì „ì²´ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        print("ğŸš€ ì „ì²´ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")
        start_time = time.time()

        # ëª¨ë“  íŒŒì¼ ìˆ˜ì§‘
        all_files = []
        all_files.extend(self.docs_dir.glob("*.pdf"))
        all_files.extend(self.docs_dir.glob("*.txt"))
        all_files.extend(self.docs_dir.glob("*.xlsx"))
        all_files.extend(self.docs_dir.glob("**/*.pdf"))  # í•˜ìœ„ í´ë”ë„ í¬í•¨

        print(f"ğŸ“ ì´ {len(all_files)}ê°œ íŒŒì¼ ë°œê²¬")

        # ë³‘ë ¬ ì¸ë±ì‹±
        results = self.parallel_index_documents(all_files)

        elapsed = time.time() - start_time
        print(f"\nâœ… ì¸ë±ì‹± ì™„ë£Œ!")
        print(f"  - ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print(f"  - ì„±ê³µ: {len(results['success'])}ê°œ")
        print(f"  - ìŠ¤í‚µ: {len(results['skipped'])}ê°œ")
        print(f"  - ì‹¤íŒ¨: {len(results['failed'])}ê°œ")

        return results

    def search_by_category(self, category: str) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰"""
        with sqlite3.connect(self.index_db) as conn:
            cursor = conn.execute(
                """SELECT filepath, title, metadata
                   FROM document_index
                   WHERE category = ?
                   ORDER BY last_modified DESC""",
                (category,)
            )
            results = []
            for row in cursor:
                results.append({
                    'filepath': row[0],
                    'title': row[1],
                    'metadata': json.loads(row[2])
                })
            return results

    def search_assets(self, location: str = None, manager: str = None) -> List[Dict]:
        """ìì‚° ê²€ìƒ‰"""
        query = "SELECT * FROM asset_index WHERE 1=1"
        params = []

        if location:
            query += " AND location LIKE ?"
            params.append(f"%{location}%")

        if manager:
            query += " AND manager LIKE ?"
            params.append(f"%{manager}%")

        with sqlite3.connect(self.index_db) as conn:
            cursor = conn.execute(query, params)
            columns = [description[0] for description in cursor.description]
            results = []
            for row in cursor:
                results.append(dict(zip(columns, row)))
            return results

    def load_indexes(self):
        """ì¸ë±ìŠ¤ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
        with sqlite3.connect(self.index_db) as conn:
            cursor = conn.execute("SELECT filepath, title, category FROM document_index")
            for row in cursor:
                self.index_types['metadata'][row[0]] = {
                    'title': row[1],
                    'category': row[2]
                }

    def get_statistics(self) -> Dict:
        """ì¸ë±ìŠ¤ í†µê³„"""
        with sqlite3.connect(self.index_db) as conn:
            stats = {}

            # ì „ì²´ ë¬¸ì„œ ìˆ˜
            cursor = conn.execute("SELECT COUNT(*) FROM document_index")
            stats['total_documents'] = cursor.fetchone()[0]

            # ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ìˆ˜
            cursor = conn.execute("""
                SELECT category, COUNT(*) FROM document_index
                GROUP BY category
            """)
            stats['by_category'] = dict(cursor.fetchall())

            # íŒŒì¼ íƒ€ì…ë³„
            cursor = conn.execute("""
                SELECT file_type, COUNT(*) FROM document_index
                GROUP BY file_type
            """)
            stats['by_type'] = dict(cursor.fetchall())

            # ìì‚° ë°ì´í„°
            cursor = conn.execute("SELECT COUNT(*) FROM asset_index")
            stats['total_assets'] = cursor.fetchone()[0]

            return stats

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    indexer = EnhancedIndexingSystem()
    indexer.build_full_index()
    stats = indexer.get_statistics()
    print(f"\nğŸ“Š ì¸ë±ìŠ¤ í†µê³„: {json.dumps(stats, indent=2, ensure_ascii=False)}")