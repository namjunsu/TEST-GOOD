#!/usr/bin/env python3
"""
LLM ëª¨ë¸ ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
Qwen2.5-7B ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¤ì¹˜í•©ë‹ˆë‹¤
"""

import os
import sys
import urllib.request
import hashlib
from pathlib import Path
import json
import time

# ìƒ‰ìƒ ì½”ë“œ
GREEN = "\033[92m"
YELLOW = "\033[93m"
RED = "\033[91m"
BLUE = "\033[94m"
RESET = "\033[0m"


class ModelInstaller:
    def __init__(self):
        self.models_dir = Path("models")
        self.model_configs = {
            "qwen2.5-7b": {
                "filename": "qwen2.5-7b-instruct-q5_k_m.gguf",
                "urls": [
                    # Hugging Face ë¯¸ëŸ¬
                    "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q5_k_m.gguf",
                    # ëŒ€ì²´ URL (ë°±ì—…)
                    "https://huggingface.co/TheBloke/Qwen-7B-Chat-GGUF/resolve/main/qwen-7b-chat.Q5_K_M.gguf"
                ],
                "size_gb": 5.4,
                "sha256": None  # ì‹¤ì œ í•´ì‹œê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•„ìš”
            },
            "qwen2.5-7b-small": {
                "filename": "qwen2.5-7b-instruct-q4_k_m.gguf",
                "urls": [
                    "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf"
                ],
                "size_gb": 4.5,
                "sha256": None
            },
            "fallback-3b": {
                "filename": "qwen2.5-3b-instruct-q5_k_m.gguf",
                "urls": [
                    "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q5_k_m.gguf"
                ],
                "size_gb": 2.4,
                "sha256": None
            }
        }

    def check_disk_space(self, required_gb):
        """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸"""
        stat = os.statvfs(".")
        available_gb = (stat.f_bavail * stat.f_frsize) / (1024**3)

        if available_gb < required_gb * 1.2:  # 20% ì—¬ìœ  ê³µê°„
            print(f"{RED}âŒ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±: {available_gb:.1f}GB ì‚¬ìš© ê°€ëŠ¥, {required_gb:.1f}GB í•„ìš”{RESET}")
            return False

        print(f"{GREEN}âœ… ë””ìŠ¤í¬ ê³µê°„ ì¶©ë¶„: {available_gb:.1f}GB ì‚¬ìš© ê°€ëŠ¥{RESET}")
        return True

    def download_with_progress(self, url, filepath, expected_size_gb=None):
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ"""
        try:
            print(f"{BLUE}ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}{RESET}")

            # íŒŒì¼ í¬ê¸° í™•ì¸
            with urllib.request.urlopen(url) as response:
                total_size = int(response.headers.get('Content-Length', 0))

                if total_size == 0:
                    print(f"{YELLOW}âš ï¸ íŒŒì¼ í¬ê¸°ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤{RESET}")

                downloaded = 0
                chunk_size = 1024 * 1024  # 1MB chunks

                with open(filepath, 'wb') as f:
                    while True:
                        chunk = response.read(chunk_size)
                        if not chunk:
                            break

                        f.write(chunk)
                        downloaded += len(chunk)

                        # ì§„í–‰ë¥  í‘œì‹œ
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            downloaded_gb = downloaded / (1024**3)
                            total_gb = total_size / (1024**3)

                            print(f"\rì§„í–‰ë¥ : {progress:.1f}% ({downloaded_gb:.2f}/{total_gb:.2f} GB)", end="")

            print(f"\n{GREEN}âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath.name}{RESET}")
            return True

        except Exception as e:
            print(f"\n{RED}âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}{RESET}")
            return False

    def verify_model(self, filepath, expected_hash=None):
        """ëª¨ë¸ íŒŒì¼ ê²€ì¦"""
        if not filepath.exists():
            return False

        # íŒŒì¼ í¬ê¸° í™•ì¸
        size_gb = filepath.stat().st_size / (1024**3)
        print(f"íŒŒì¼ í¬ê¸°: {size_gb:.2f} GB")

        if size_gb < 0.1:
            print(f"{RED}âŒ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤{RESET}")
            return False

        # SHA256 í•´ì‹œ í™•ì¸ (ì„ íƒì )
        if expected_hash:
            print("í•´ì‹œ ê²€ì¦ ì¤‘...")
            sha256 = hashlib.sha256()
            with open(filepath, 'rb') as f:
                while chunk := f.read(8192):
                    sha256.update(chunk)

            if sha256.hexdigest() != expected_hash:
                print(f"{RED}âŒ í•´ì‹œ ë¶ˆì¼ì¹˜{RESET}")
                return False

        return True

    def install_model(self, model_name="qwen2.5-7b"):
        """ëª¨ë¸ ì„¤ì¹˜"""
        if model_name not in self.model_configs:
            print(f"{RED}âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model_name}{RESET}")
            return False

        config = self.model_configs[model_name]

        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        self.models_dir.mkdir(exist_ok=True)
        model_path = self.models_dir / config["filename"]

        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if model_path.exists():
            print(f"{YELLOW}âš ï¸ ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {model_path}{RESET}")
            if self.verify_model(model_path, config.get("sha256")):
                print(f"{GREEN}âœ… ê¸°ì¡´ ëª¨ë¸ì´ ìœ íš¨í•©ë‹ˆë‹¤{RESET}")
                return True
            else:
                print(f"{YELLOW}ê¸°ì¡´ ëª¨ë¸ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...{RESET}")
                model_path.unlink()

        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        if not self.check_disk_space(config["size_gb"]):
            return False

        # URL ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
        for url in config["urls"]:
            print(f"\n{BLUE}ì‹œë„ ì¤‘: {model_name}{RESET}")

            if self.download_with_progress(url, model_path, config["size_gb"]):
                if self.verify_model(model_path, config.get("sha256")):
                    print(f"{GREEN}âœ… ëª¨ë¸ ì„¤ì¹˜ ì„±ê³µ!{RESET}")
                    return True
                else:
                    print(f"{YELLOW}âš ï¸ ê²€ì¦ ì‹¤íŒ¨, ë‹¤ìŒ URL ì‹œë„...{RESET}")
                    model_path.unlink(missing_ok=True)

        return False

    def create_config_update(self):
        """config.yaml ì—…ë°ì´íŠ¸"""
        config_file = Path("config.yaml")

        if config_file.exists():
            import yaml
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)

            # ëª¨ë¸ ê²½ë¡œ ì—…ë°ì´íŠ¸
            if 'models' in config and 'qwen' in config['models']:
                config['models']['qwen']['path'] = str(self.models_dir / "qwen2.5-7b-instruct-q5_k_m.gguf")

                with open(config_file, 'w') as f:
                    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

                print(f"{GREEN}âœ… config.yaml ì—…ë°ì´íŠ¸ ì™„ë£Œ{RESET}")

    def install_fallback_model(self):
        """ë” ì‘ì€ í´ë°± ëª¨ë¸ ì„¤ì¹˜"""
        print(f"\n{YELLOW}ê¸°ë³¸ ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨. ë” ì‘ì€ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤...{RESET}")

        # 3B ëª¨ë¸ ì‹œë„
        if self.install_model("fallback-3b"):
            # config ì—…ë°ì´íŠ¸
            self.update_config_for_fallback()
            return True

        return False

    def update_config_for_fallback(self):
        """í´ë°± ëª¨ë¸ìš© ì„¤ì • ì—…ë°ì´íŠ¸"""
        config_file = Path("config.yaml")
        if config_file.exists():
            import yaml
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)

            config['models']['qwen']['path'] = str(self.models_dir / "qwen2.5-3b-instruct-q5_k_m.gguf")
            config['models']['qwen']['name'] = "Qwen2.5-3B (Fallback)"

            with open(config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)


def main():
    print(f"{BLUE}{'='*60}{RESET}")
    print(f"{BLUE}LLM ëª¨ë¸ ìë™ ì„¤ì¹˜ ì‹œìŠ¤í…œ{RESET}")
    print(f"{BLUE}{'='*60}{RESET}\n")

    installer = ModelInstaller()

    # ì„¤ì¹˜ ì˜µì…˜ ì„ íƒ
    print("ì„¤ì¹˜í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. Qwen2.5-7B (ê¶Œì¥, 5.4GB)")
    print("2. Qwen2.5-7B Small (4.5GB)")
    print("3. Qwen2.5-3B (ê²½ëŸ‰, 2.4GB)")
    print("4. ìë™ ì„ íƒ (ë””ìŠ¤í¬ ê³µê°„ì— ë”°ë¼)")

    choice = input("\nì„ íƒ (1-4, ê¸°ë³¸ê°’ 4): ").strip() or "4"

    model_map = {
        "1": "qwen2.5-7b",
        "2": "qwen2.5-7b-small",
        "3": "fallback-3b",
        "4": "auto"
    }

    selected_model = model_map.get(choice, "auto")

    if selected_model == "auto":
        # ë””ìŠ¤í¬ ê³µê°„ì— ë”°ë¼ ìë™ ì„ íƒ
        stat = os.statvfs(".")
        available_gb = (stat.f_bavail * stat.f_frsize) / (1024**3)

        if available_gb > 10:
            selected_model = "qwen2.5-7b"
        elif available_gb > 6:
            selected_model = "qwen2.5-7b-small"
        else:
            selected_model = "fallback-3b"

        print(f"\nìë™ ì„ íƒ: {selected_model} (ì‚¬ìš© ê°€ëŠ¥ ê³µê°„: {available_gb:.1f}GB)")

    # ëª¨ë¸ ì„¤ì¹˜
    success = installer.install_model(selected_model)

    if not success and selected_model != "fallback-3b":
        # í´ë°± ì‹œë„
        success = installer.install_fallback_model()

    if success:
        installer.create_config_update()
        print(f"\n{GREEN}ğŸ‰ ëª¨ë¸ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!{RESET}")
        print(f"ì´ì œ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return 0
    else:
        print(f"\n{RED}âŒ ëª¨ë¸ ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.{RESET}")
        print("ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”:")
        print("https://huggingface.co/Qwen/")
        return 1


if __name__ == "__main__":
    sys.exit(main())