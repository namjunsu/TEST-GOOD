#!/usr/bin/env python3
"""
ëª¨ë“  PDFì—ì„œ ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì¶œí•˜ì—¬ DB êµ¬ì¶•
- í…ìŠ¤íŠ¸ PDF: ì¦‰ì‹œ ì¶”ì¶œ
- ìŠ¤ìº” PDF: ë‚˜ì¤‘ì— ì²˜ë¦¬ (í‘œì‹œë§Œ)
"""

import logging
import pdfplumber
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from metadata_manager import MetadataManager
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from functools import lru_cache
from tqdm import tqdm

logger = logging.getLogger(__name__)

class MetadataDBBuilder:
    """ë©”íƒ€ë°ì´í„° DB êµ¬ì¶• í´ë˜ìŠ¤"""

    # ìƒìˆ˜ ì •ì˜
    MIN_TEXT_LENGTH = 50  # ìŠ¤ìº” PDF íŒë‹¨ ê¸°ì¤€
    MAX_WORKERS = 4  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
    MAX_FILENAME_DISPLAY = 50  # íŒŒì¼ëª… í‘œì‹œ ê¸¸ì´
    DEFAULT_BATCH_SIZE = 100  # ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° (í…ŒìŠ¤íŠ¸ìš©)

    def __init__(self, batch_size: Optional[int] = None):
        self.manager = MetadataManager()
        self.batch_size = batch_size

        # í†µê³„
        self.text_count = 0
        self.scan_count = 0
        self.drafter_count = 0
        self.error_count = 0
        self.processing_times: List[float] = []

    def extract_metadata_from_pdf(self, pdf_path: Path) -> Dict:
        """PDFì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì„±ëŠ¥ ì¶”ì  í¬í•¨)"""
        start_time = time.time()
        filename = pdf_path.name
        metadata = {'filename': filename, 'path': str(pdf_path)}

        try:
            if self._is_scanned_pdf(pdf_path):
                # ìŠ¤ìº” PDF
                metadata['status'] = 'scanned'
                metadata['needs_ocr'] = True
                display_name = self._truncate_filename(filename)
                logger.info(f"ìŠ¤ìº” PDF ê°ì§€: {display_name}")
            else:
                # í…ìŠ¤íŠ¸ PDF - ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                metadata['status'] = 'text'

                with pdfplumber.open(pdf_path) as pdf:
                    if pdf.pages:
                        text = pdf.pages[0].extract_text() or ""
                        # MetadataManagerì˜ ì¶”ì¶œ í•¨ìˆ˜ í™œìš©
                        extracted = self.manager.extract_from_text(text)
                        metadata.update(extracted)

                # ê¸°ì•ˆì ì°¾ì•˜ìœ¼ë©´ í‘œì‹œ
                display_name = self._truncate_filename(filename)
                if metadata.get('drafter'):
                    logger.info(f"{display_name} â†’ ê¸°ì•ˆì: {metadata['drafter']}")
                else:
                    logger.debug(f"{display_name} â†’ ê¸°ì•ˆì ì •ë³´ ì—†ìŒ")

        except Exception as e:
            metadata['status'] = 'error'
            metadata['error'] = str(e)
            self.error_count += 1
            logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {filename} - {e}")

        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)
        metadata['processing_time'] = processing_time

        return metadata

    @lru_cache(maxsize=512)
    def _is_scanned_pdf(self, pdf_path: Path) -> bool:
        """ìŠ¤ìº” PDFì¸ì§€ í™•ì¸ (ìºì‹œë¨)"""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                if not pdf.pages:
                    return False

                # ì²« í˜ì´ì§€ë§Œ ë¹ ë¥´ê²Œ í™•ì¸
                text = pdf.pages[0].extract_text() or ""
                return len(text.strip()) < self.MIN_TEXT_LENGTH

        except Exception:
            return False

    def _truncate_filename(self, filename: str) -> str:
        """íŒŒì¼ëª… ê¸¸ì´ ì œí•œ"""
        if len(filename) > self.MAX_FILENAME_DISPLAY:
            return filename[:self.MAX_FILENAME_DISPLAY] + "..."
        return filename

    def build_database(self, docs_dir: Path = None) -> Tuple[int, int, int]:
        """ì „ì²´ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° DB êµ¬ì¶• (ë³‘ë ¬ ì²˜ë¦¬)"""
        if docs_dir is None:
            docs_dir = Path('docs')

        logger.info("="*60)
        logger.info("ë©”íƒ€ë°ì´í„° DB êµ¬ì¶• ì‹œì‘")
        logger.info("="*60)

        # ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
        pdf_files = list(docs_dir.rglob('*.pdf'))

        # ë°°ì¹˜ í¬ê¸° ì ìš©
        if self.batch_size:
            pdf_files = pdf_files[:self.batch_size]
            logger.info(f"ë°°ì¹˜ ëª¨ë“œ: {self.batch_size}ê°œë§Œ ì²˜ë¦¬")

        logger.info(f"ì´ {len(pdf_files)}ê°œ PDF íŒŒì¼ ë°œê²¬")

        # í†µê³„ ì´ˆê¸°í™”
        self.text_count = 0
        self.scan_count = 0
        self.drafter_count = 0

        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥´ê²Œ
        logger.info("ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...")

        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì‚¬ìš© (tqdm ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            from tqdm import tqdm
            use_tqdm = True
        except ImportError:
            use_tqdm = False

        with ThreadPoolExecutor(max_workers=self.MAX_WORKERS) as executor:
            futures = {
                executor.submit(self.extract_metadata_from_pdf, pdf_path): pdf_path
                for pdf_path in pdf_files
            }

            # í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ í•¨ê»˜ ì²˜ë¦¬
            completed_futures = tqdm(as_completed(futures), total=len(futures), desc="ì²˜ë¦¬ ì¤‘") if use_tqdm else as_completed(futures)

            for future in completed_futures:
                pdf_path = futures[future]
                try:
                    metadata = future.result()
                    filename = pdf_path.name

                    # DBì— ì €ì¥ (filenameì€ metadataì—ì„œ ì œê±°)
                    if 'filename' in metadata:
                        del metadata['filename']
                    self.manager.add_document(filename, **metadata)

                    # í†µê³„ ì—…ë°ì´íŠ¸
                    if metadata.get('status') == 'text':
                        self.text_count += 1
                    elif metadata.get('status') == 'scanned':
                        self.scan_count += 1

                    if metadata.get('drafter'):
                        self.drafter_count += 1

                except Exception as e:
                    logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {pdf_path.name} - {e}")
                    self.error_count += 1

        # ì €ì¥
        self.manager.save_metadata()

        # ê²°ê³¼ ë¡œê¹…
        logger.info("="*60)
        logger.info("ë©”íƒ€ë°ì´í„° DB êµ¬ì¶• ì™„ë£Œ!")
        logger.info("="*60)

        self._print_statistics()

        return self.text_count, self.scan_count, self.drafter_count

    def _print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        total_docs = self.text_count + self.scan_count

        print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"  - ì´ ë¬¸ì„œ: {total_docs}ê°œ")
        print(f"  - í…ìŠ¤íŠ¸ PDF: {self.text_count}ê°œ")
        print(f"  - ìŠ¤ìº” PDF: {self.scan_count}ê°œ (OCR í•„ìš”)")
        print(f"  - ê¸°ì•ˆì í™•ì¸: {self.drafter_count}ê°œ")
        print(f"  - ì²˜ë¦¬ ì˜¤ë¥˜: {self.error_count}ê°œ")

        # ì„±ëŠ¥ í†µê³„
        if self.processing_times:
            avg_time = sum(self.processing_times) / len(self.processing_times)
            print(f"\nâš¡ ì„±ëŠ¥:")
            print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.3f}ì´ˆ/íŒŒì¼")
            print(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {sum(self.processing_times):.1f}ì´ˆ")

        # ê¸°ì•ˆìë³„ í†µê³„
        stats = self.manager.get_statistics()
        if stats['drafters']:
            print("\nğŸ‘¥ ê¸°ì•ˆìë³„ ë¬¸ì„œ ìˆ˜:")
            for drafter, count in sorted(stats['drafters'].items(), key=lambda x: x[1], reverse=True)[:10]:
                print(f"  - {drafter}: {count}ê°œ")

        print(f"\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼: document_metadata.json")
        print(f"ğŸ“ {len(self.manager.metadata)}ê°œ ë¬¸ì„œ ì •ë³´ ì €ì¥ë¨")

        # ìºì‹œ í†µê³„ (MetadataManagerì— ìˆëŠ” ê²½ìš°)
        if hasattr(self.manager, 'get_performance_stats'):
            perf_stats = self.manager.get_performance_stats()
            print(f"\nğŸ” ê²€ìƒ‰ ì„±ëŠ¥:")
            print(f"  - ìºì‹œ íˆíŠ¸ìœ¨: {perf_stats.get('cache_hit_rate', 0):.1f}%")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    import argparse
    parser = argparse.ArgumentParser(description='ë©”íƒ€ë°ì´í„° DB êµ¬ì¶•')
    parser.add_argument('--batch-size', type=int, help='ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ ì œí•œ')
    parser.add_argument('--docs-dir', type=str, default='docs', help='ë¬¸ì„œ ë””ë ‰í† ë¦¬')
    args = parser.parse_args()

    start = time.time()

    builder = MetadataDBBuilder(batch_size=args.batch_size)
    text_count, scan_count, drafter_count = builder.build_database(Path(args.docs_dir))

    elapsed = time.time() - start
    print(f"\nâ±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {elapsed:.1f}ì´ˆ")

    return 0

if __name__ == "__main__":
    exit(main())