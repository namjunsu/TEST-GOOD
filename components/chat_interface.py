"""
Chat Interface Component
ChatGPT ìŠ¤íƒ€ì¼ì˜ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ UIë¥¼ ë Œë”ë§í•˜ëŠ” ì»´í¬ë„ŒíŠ¸

ê°œì„  ì‚¬í•­:
- ì™„ë²½í•œ íƒ€ì… ì‹œìŠ¤í…œ (TypedDict, Protocol)
- ìƒìˆ˜ ì •ì˜ë¡œ ë§¤ì§ ë„˜ë²„/ë¬¸ìì—´ ì œê±°
- í—¬í¼ í•¨ìˆ˜ ë¶„ë¦¬ (Single Responsibility Principle)
- ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬ (íƒ€ì…ë³„ ì²˜ë¦¬, ë¡œê¹…)
- ë©”ëª¨ë¦¬ ê´€ë¦¬ (ìë™ ë©”ì‹œì§€ ì •ë¦¬)
- ì…ë ¥ ê²€ì¦ ë° ë³´ì•ˆ ê°•í™”
- í¬ê´„ì ì¸ ë¬¸ì„œí™”
"""

import os
import streamlit as st
import requests
from typing import List, Dict, Optional, Protocol, Any
from typing_extensions import TypedDict, Literal
from datetime import datetime
from functools import lru_cache
from pathlib import Path

from app.core.logging import get_logger
from utils.streaming import stream_text_smart


# ===== ë¡œê¹… ì„¤ì • =====
logger = get_logger(__name__)

# ì§„ë‹¨ ëª¨ë“œ ì„¤ì •
DIAG_RAG = os.getenv('DIAG_RAG', 'false').lower() == 'true'


# ===== íƒ€ì… ì •ì˜ =====
class ChatMessage(TypedDict):
    """ì±„íŒ… ë©”ì‹œì§€ êµ¬ì¡°"""
    role: Literal["user", "assistant"]
    content: str
    timestamp: str


class RAGProtocol(Protocol):
    """RAG Pipeline ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (Evidence í¬í•¨)"""
    def answer(self, query: str, top_k: Optional[int] = None) -> dict:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±

        Returns:
            dict: {
                "text": ë‹µë³€ í…ìŠ¤íŠ¸,
                "evidence": [{"doc_id": str, "page": int, "snippet": str, "meta": dict}, ...]
            }
        """
        ...


# ===== ìƒìˆ˜ ì •ì˜ =====
class ChatConfig:
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ìƒìˆ˜"""
    # ì—­í•  ì •ì˜
    ROLE_USER = "user"
    ROLE_ASSISTANT = "assistant"

    # í•œê¸€ ì—­í• ëª…
    ROLE_DISPLAY_USER = "ì‚¬ìš©ì"
    ROLE_DISPLAY_ASSISTANT = "AI"

    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    MAX_MESSAGES = 100  # ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
    MAX_CONTEXT_TURNS = 3  # ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨í•  ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜
    MAX_MESSAGE_LENGTH = 10000  # ìµœëŒ€ ë©”ì‹œì§€ ê¸¸ì´

    # UI ë¬¸ìì—´
    INPUT_PLACEHOLDER = "ğŸ’¬ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    SPINNER_TEXT = "ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘... (ìºì‹œ í™•ì¸ â†’ ì¸ë±ìŠ¤ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±)"
    DIVIDER = "---"

    # ì—ëŸ¬ ë©”ì‹œì§€
    ERROR_GENERIC = "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    ERROR_TIMEOUT = "â±ï¸ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    ERROR_MEMORY = "ğŸ’¾ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€í™” ë‚´ì—­ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”."
    ERROR_NETWORK = "ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    ERROR_INITIALIZATION = "âš™ï¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    ERROR_INVALID_INPUT = "âš ï¸ ì…ë ¥ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë” ì§§ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    CONTEXT_PREFIX = "ì´ì „ ëŒ€í™” ë§¥ë½:"
    CURRENT_QUERY_PREFIX = "í˜„ì¬ ì§ˆë¬¸:"


# ===== í—¬í¼ í•¨ìˆ˜ =====

@lru_cache(maxsize=1)
def _get_api_base_url() -> str:
    """FastAPI ê¸°ì¤€ URLì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´ (ìºì‹œ ì ìš©)

    ìš°ì„ ìˆœìœ„:
    1. í™˜ê²½ë³€ìˆ˜ PUBLIC_API_BASE
    2. FastAPI /api/config ì—”ë“œí¬ì¸íŠ¸
    3. ê¸°ë³¸ê°’ (localhost:7860)

    Returns:
        str: API ê¸°ì¤€ URL
    """
    # 1. í™˜ê²½ë³€ìˆ˜ ìš°ì„ 
    env_base = os.getenv("PUBLIC_API_BASE")
    if env_base:
        logger.info(f"Using PUBLIC_API_BASE from env: {env_base}")
        return env_base.rstrip("/")

    # 2. FastAPIì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
    try:
        # Streamlitì´ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°, FastAPIëŠ” ê°™ì€ ë¨¸ì‹ ì˜ 7860 í¬íŠ¸
        api_url = "http://localhost:7860/api/config"
        response = requests.get(api_url, timeout=2)
        if response.status_code == 200:
            config = response.json()
            base_url = config.get("base_url", "http://localhost:7860")
            logger.info(f"Fetched API base URL from FastAPI: {base_url}")
            return base_url
    except Exception as e:
        logger.warning(f"Failed to fetch API config from FastAPI: {e}")

    # 3. ê¸°ë³¸ê°’
    default_url = "http://localhost:7860"
    logger.info(f"Using default API base URL: {default_url}")
    return default_url


def render_doc_card(
    index: int,
    filename: str,
    file_path: Optional[Path],
    doctype: Optional[str],
    display_date: Optional[str],
    drafter: Optional[str],
    summary: str,
    show_preview_inline: bool = False,
    msg_idx: int = 0
) -> None:
    """ë¬¸ì„œ ì¹´ë“œ ë Œë”ë§ (ê³ ì • ë ˆì´ì•„ì›ƒ) - ì•ˆì „ê°€ë“œ + ìºì‹œ ì ìš©

    1í–‰: ğŸ“„ íŒŒì¼ëª…
    2í–‰: ë©”íƒ€ì¹© (doctype Â· date Â· drafter)
    3í–‰: LLM ìš”ì•½ (ìµœëŒ€ 2ì¤„, 160ì)
    4í–‰: ë²„íŠ¼ (ë¯¸ë¦¬ë³´ê¸° / ë‹¤ìš´ë¡œë“œ)
    5í–‰: PDF ë·°ì–´ (ì„ íƒì , ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)

    Args:
        index: ì¹´ë“œ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
        filename: íŒŒì¼ëª…
        file_path: ì‹¤ì œ íŒŒì¼ ê²½ë¡œ (Path ê°ì²´)
        doctype: ë¬¸ì„œ íƒ€ì…
        display_date: ë‚ ì§œ
        drafter: ê¸°ì•ˆì
        summary: LLM ìš”ì•½ (ì´ë¯¸ 160ìë¡œ ì œí•œëœ ìƒíƒœ)
        show_preview_inline: ì¸ë¼ì¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ ì—¬ë¶€
    """
    from utils.pdf_utils import download_pdf_button, render_pdf_preview

    # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í‘œì‹œ
    import hashlib
    # ê³ ìœ  í‚¤ ìƒì„±: msg_idxì™€ indexë¥¼ í¬í•¨í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
    file_hash = hashlib.md5(filename.encode()).hexdigest()[:8]
    unique_key = f"{msg_idx}_{index}_{file_hash}"
    session_key = f"show_preview_{unique_key}"

    # ë©”íƒ€ì •ë³´ êµ¬ì„±
    meta_parts = []
    if display_date:
        meta_parts.append(display_date)
    if drafter:
        meta_parts.append(drafter)
    meta_str = ' Â· '.join(meta_parts) if meta_parts else ""

    # ìš”ì•½ (40ìë¡œ ë‹¨ì¶•)
    summary_short = summary[:40].strip()
    if len(summary) > 40:
        summary_short += "..."

    # í•œ ì¤„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹: â€¢ íŒŒì¼ëª….pdf (ë‚ ì§œ Â· ê¸°ì•ˆì) - ìš”ì•½...
    list_line = f"**{index}.** ğŸ“„ **{filename}**"
    if meta_str:
        list_line += f" `{meta_str}`"
    if summary_short:
        list_line += f" â€” {summary_short}"

    st.markdown(list_line)

    # ì•¡ì…˜ ë²„íŠ¼ (ì‘ê²Œ, ê°™ì€ ì¤„ì—)
    if file_path:
        col1, col2, col3 = st.columns([1, 1, 8])

        with col1:
            preview_key = f"preview_btn_{unique_key}"
            current_state = st.session_state.get(session_key, False)
            icon = "ğŸ“–" if current_state else "ğŸ”"

            if st.button(icon, key=preview_key, help="ë¯¸ë¦¬ë³´ê¸°", use_container_width=True):
                st.session_state[session_key] = not current_state
                # Streamlit ìë™ ì¬ë Œë”ë§ (st.rerun() ì œê±°, 2025-11-07)

        with col2:
            download_pdf_button(
                file_path=str(file_path),
                key=f"download_{unique_key}",
                width="stretch",
                icon_only=True
            )

        # PDF ë¯¸ë¦¬ë³´ê¸° (ì„ íƒ ì‹œ)
        if st.session_state.get(session_key, False):
            st.markdown(f"**ğŸ“„ {filename}**")
            render_pdf_preview(
                file_path=str(file_path),
                height=500,
                show_download_fallback=True
            )
    else:
        st.caption("âš ï¸ íŒŒì¼ ê²½ë¡œ ì—†ìŒ")


def _normalize_rag_response(resp: Any) -> dict:
    """RAG ì‘ë‹µì„ ì•ˆì „í•˜ê²Œ dictë¡œ ì •ê·œí™”

    RAG Pipelineì´ ë°˜í™˜í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ íƒ€ì…(ê°ì²´, dict, str)ì„
    í†µì¼ëœ dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        resp: RAG Pipelineì˜ ì‘ë‹µ (RAGResponse ê°ì²´, dict, str ë“±)

    Returns:
        dict: {"text": str, "evidence": list} í˜•ì‹ì˜ ì •ê·œí™”ëœ ì‘ë‹µ

    Examples:
        >>> _normalize_rag_response(RAGResponse(text="ë‹µë³€", evidence=[...]))
        {"text": "ë‹µë³€", "evidence": [...]}

        >>> _normalize_rag_response(RAGResponse(answer="ë‹µë³€", sources=[...]))
        {"text": "ë‹µë³€", "evidence": [...]}

        >>> _normalize_rag_response({"text": "ë‹µë³€", "evidence": [...]})
        {"text": "ë‹µë³€", "evidence": [...]}

        >>> _normalize_rag_response("ì§ì ‘ ë¬¸ìì—´ ë‹µë³€")
        {"text": "ì§ì ‘ ë¬¸ìì—´ ë‹µë³€", "evidence": []}
    """
    # None ì²´í¬
    if resp is None:
        logger.warning("Received None response from RAG")
        return {"text": "", "evidence": []}

    # ë¬¸ìì—´ì¸ ê²½ìš°
    if isinstance(resp, str):
        return {"text": resp, "evidence": []}

    # ê°ì²´ì¸ ê²½ìš° (RAGResponse ë“±)
    # text, answer í•„ë“œ ëª¨ë‘ ì§€ì›
    if hasattr(resp, "text") or hasattr(resp, "answer"):
        text = getattr(resp, "text", None) or getattr(resp, "answer", "")
        # evidence, evidences, sources, sources_cited ëª¨ë‘ ì‹œë„
        evidence = (
            getattr(resp, "evidence", None) or
            getattr(resp, "evidences", None) or
            getattr(resp, "sources", None) or
            getattr(resp, "sources_cited", None) or
            []
        )
        return {"text": str(text), "evidence": evidence}

    # dictì¸ ê²½ìš°
    if isinstance(resp, dict):
        text = resp.get("text") or resp.get("answer", "")
        evidence = (
            resp.get("evidence") or
            resp.get("evidences") or
            resp.get("sources") or
            resp.get("sources_cited") or
            []
        )
        return {"text": str(text), "evidence": evidence}

    # ê·¸ ì™¸ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…
    logger.warning(f"Unknown response type: {type(resp)}")
    return {"text": str(resp), "evidence": []}


def _initialize_chat_state() -> None:
    """ì±„íŒ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

    ì„¸ì…˜ ìƒíƒœì— messages ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        logger.info("Chat session initialized")


def _display_evidence_section(evidence_list: List, msg_idx: int) -> None:
    """ì¶œì²˜ ë¬¸ì„œ ì„¹ì…˜ í‘œì‹œ

    Evidence ë¦¬ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ë©°,
    ê° ë©”ì‹œì§€ë³„ë¡œ expander ìƒíƒœë¥¼ session_stateë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

    Args:
        evidence_list: ì¶œì²˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        msg_idx: ë©”ì‹œì§€ ì¸ë±ìŠ¤ (expander ìƒíƒœ ê´€ë¦¬ìš©)
    """
    from pathlib import Path

    # Top-K=20 ì œí•œ
    MAX_DISPLAY = 20
    display_evidence = evidence_list[:MAX_DISPLAY]
    has_more = len(evidence_list) > MAX_DISPLAY

    # ExpanderëŠ” ê¸°ë³¸ ì ‘íŒ ìƒíƒœ (Streamlit ë‚´ë¶€ ìƒíƒœ ê´€ë¦¬ ì‚¬ìš©)
    # expanded íŒŒë¼ë¯¸í„°ë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½í•˜ë©´ ì¬ë Œë”ë§ ì‹œ ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆìŒ
    with st.expander(
        f"ğŸ“š ì¶œì²˜ ë¬¸ì„œ ({len(display_evidence)}ê±´)",
        expanded=False
    ):
        for i, ev in enumerate(display_evidence, 1):
            # Evidenceê°€ dict ë˜ëŠ” ê°ì²´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
            if isinstance(ev, dict):
                doc_id = ev.get("doc_id") or ev.get("chunk_id", "unknown")
                filename = ev.get("filename", doc_id)
                snippet = ev.get("snippet") or ev.get("content", "") or ev.get("text", "")
                file_path_str = ev.get("file_path")
                meta = ev.get("meta", {})
            else:
                # ê°ì²´ì¸ ê²½ìš°
                doc_id = getattr(ev, "doc_id", None) or getattr(ev, "chunk_id", "unknown")
                filename = getattr(ev, "filename", doc_id)
                snippet = getattr(ev, "snippet", None) or getattr(ev, "content", "") or getattr(ev, "text", "")
                file_path_str = getattr(ev, "file_path", None)
                meta = getattr(ev, "meta", {})

            # íŒŒì¼ ê²½ë¡œ ìƒì„± (year í´ë” ì§€ì›)
            if file_path_str:
                file_path = Path(file_path_str)
            else:
                # Fallback: year í´ë” ì¶”ì¶œ
                import re
                year_match = re.search(r'(\d{4})-', filename)
                if year_match:
                    year = year_match.group(1)
                    file_path = Path(f"docs/year_{year}") / filename
                else:
                    file_path = Path("docs") / filename

            # ë©”íƒ€ ë°ì´í„° ì¶”ì¶œ
            doctype = meta.get("doctype") if isinstance(meta, dict) else None
            display_date = meta.get("date") or meta.get("display_date") if isinstance(meta, dict) else None
            drafter = meta.get("drafter") if isinstance(meta, dict) else None

            # ì¹´ë“œ ë Œë”ë§ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹)
            render_doc_card(
                index=i,
                filename=filename,
                file_path=file_path,
                doctype=doctype,
                display_date=display_date,
                drafter=drafter,
                summary=snippet,
                show_preview_inline=False,
                msg_idx=msg_idx
            )

            # ê°„ê²°í•œ êµ¬ë¶„ (ë§ˆì§€ë§‰ ì•„ì´í…œ ì œì™¸)
            if i < len(display_evidence):
                st.markdown("")  # ì‘ì€ ì—¬ë°±ë§Œ

        # ë” ë³´ê¸° ì •ë³´ (5ê±´ ì´ˆê³¼ ì‹œ)
        if has_more:
            st.markdown("---")
            remaining = len(evidence_list) - MAX_DISPLAY
            st.info(f"ğŸ“„ {remaining}ê±´ì˜ ë¬¸ì„œê°€ ë” ìˆìŠµë‹ˆë‹¤. (í˜„ì¬ ìƒìœ„ {MAX_DISPLAY}ê±´ë§Œ í‘œì‹œ)")


def _validate_message_structure(message: Any) -> bool:
    """ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦

    Args:
        message: ê²€ì¦í•  ë©”ì‹œì§€ ê°ì²´

    Returns:
        bool: ìœ íš¨í•œ ë©”ì‹œì§€ êµ¬ì¡°ë©´ True, ì•„ë‹ˆë©´ False
    """
    if not isinstance(message, dict):
        return False

    required_keys = {'role', 'content'}
    if not required_keys.issubset(message.keys()):
        return False

    if message['role'] not in [ChatConfig.ROLE_USER, ChatConfig.ROLE_ASSISTANT]:
        return False

    if not isinstance(message['content'], str):
        return False

    return True


def _validate_input(prompt: str) -> tuple[bool, Optional[str]]:
    """ì‚¬ìš©ì ì…ë ¥ ê²€ì¦

    Args:
        prompt: ì‚¬ìš©ì ì…ë ¥ ë¬¸ìì—´

    Returns:
        tuple[bool, Optional[str]]: (ìœ íš¨ì„±, ì—ëŸ¬ ë©”ì‹œì§€)
    """
    # ë¹ˆ ë¬¸ìì—´ ì²´í¬
    if not prompt or not prompt.strip():
        return False, "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."

    # ê¸¸ì´ ì²´í¬
    if len(prompt) > ChatConfig.MAX_MESSAGE_LENGTH:
        return False, ChatConfig.ERROR_INVALID_INPUT

    # ê¸°ë³¸ ìœ„í—˜ ë¬¸ì ì²´í¬ (ì„ íƒì , í•„ìš”ì‹œ í™•ì¥)
    # dangerous_patterns = ['<script>', 'javascript:', 'onerror=']
    # if any(pattern in prompt.lower() for pattern in dangerous_patterns):
    #     return False, "ë³´ì•ˆìƒ í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì…ë ¥ì…ë‹ˆë‹¤."

    return True, None


def _cleanup_old_messages(messages: List[ChatMessage]) -> List[ChatMessage]:
    """ì˜¤ë˜ëœ ë©”ì‹œì§€ ì •ë¦¬

    ë©”ì‹œì§€ ìˆ˜ê°€ MAX_MESSAGESë¥¼ ì´ˆê³¼í•˜ë©´ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¶€í„° ì‚­ì œí•©ë‹ˆë‹¤.
    ìµœê·¼ ë©”ì‹œì§€ë“¤ë§Œ ìœ ì§€í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

    Args:
        messages: ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸

    Returns:
        List[ChatMessage]: ì •ë¦¬ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    if len(messages) > ChatConfig.MAX_MESSAGES:
        removed_count = len(messages) - ChatConfig.MAX_MESSAGES
        logger.warning(f"Message limit exceeded. Removing {removed_count} old messages.")
        return messages[-ChatConfig.MAX_MESSAGES:]
    return messages


def _build_conversation_context(messages: List[Dict[str, str]], max_turns: int = ChatConfig.MAX_CONTEXT_TURNS) -> str:
    """ëŒ€í™” ë§¥ë½ êµ¬ì„±

    ìµœê·¼ Nê°œ í„´ì˜ ëŒ€í™”ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    íš¨ìœ¨ì ì¸ ë¬¸ìì—´ ì—°ê²°ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        messages: ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        max_turns: í¬í•¨í•  ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜ (ê¸°ë³¸ê°’: 3)

    Returns:
        str: êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    # ë©”ì‹œì§€ê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ
    if len(messages) < 2:
        return ""

    # ìµœê·¼ Ní„´ = N*2ê°œ ë©”ì‹œì§€ (user + assistant ìŒ)
    # í˜„ì¬ user ë©”ì‹œì§€ëŠ” ì´ë¯¸ ì¶”ê°€ëœ ìƒíƒœì´ë¯€ë¡œ, ê·¸ ì´ì „ ë©”ì‹œì§€ë“¤ë§Œ ê°€ì ¸ì˜´
    max_messages = max_turns * 2
    recent_messages = messages[-(max_messages + 1):-1]  # ë§ˆì§€ë§‰ ë©”ì‹œì§€(í˜„ì¬ ì§ˆë¬¸) ì œì™¸

    # íš¨ìœ¨ì ì¸ ë¬¸ìì—´ êµ¬ì„± (ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)
    context_parts = []

    for msg in recent_messages:
        # ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦
        if not _validate_message_structure(msg):
            logger.warning(f"Invalid message structure in context: {msg}")
            continue

        # ì—­í•  ë³€í™˜
        role = msg['role']
        display_role = ChatConfig.ROLE_DISPLAY_USER if role == ChatConfig.ROLE_USER else ChatConfig.ROLE_DISPLAY_ASSISTANT

        # ë©”ì‹œì§€ ë‚´ìš© ì²˜ë¦¬ (ê¸´ ì‘ë‹µì€ ìš”ì•½)
        content = msg['content']

        # AI ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½ (500ì ì œí•œ)
        MAX_CONTEXT_LENGTH = 500
        if role == ChatConfig.ROLE_ASSISTANT and len(content) > MAX_CONTEXT_LENGTH:
            # ë¦¬ìŠ¤íŠ¸ ì‘ë‹µ íŒ¨í„´ ê°ì§€
            if "ê´€ë ¨ ë¬¸ì„œ" in content and "ê±´)" in content:
                # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì‘ë‹µì¸ ê²½ìš°: ê±´ìˆ˜ë§Œ ì¶”ì¶œ
                import re
                match = re.search(r'\((\d+)ê±´\)', content)
                if match:
                    doc_count = match.group(1)
                    content = f"(ì´ì „ ì‘ë‹µ: {doc_count}ê±´ì˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì œê³µë¨)"
                else:
                    content = f"(ì´ì „ ì‘ë‹µ: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì œê³µë¨ - ìƒëµ)"
            else:
                # ì¼ë°˜ ê¸´ ì‘ë‹µ: ì•ë¶€ë¶„ë§Œ ìœ ì§€
                content = content[:MAX_CONTEXT_LENGTH] + "...(ìƒëµ)"

        # ë©”ì‹œì§€ ì¶”ê°€
        context_parts.append(f"{display_role}: {content}")

    # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    if not context_parts:
        return ""

    # ì¡°ì¸í•˜ì—¬ ë°˜í™˜
    return "\n".join(context_parts)


def _create_enhanced_query(context: str, prompt: str) -> str:
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í–¥ìƒëœ ì¿¼ë¦¬ ìƒì„±

    Args:
        context: ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
        prompt: í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        str: í–¥ìƒëœ ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # ì»¨í…ìŠ¤íŠ¸ì™€ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ enhanced query ìƒì„±
    if context:
        return f"{ChatConfig.CONTEXT_PREFIX}\n{context}\n\n{ChatConfig.CURRENT_QUERY_PREFIX} {prompt}"
    else:
        return prompt


def _handle_error(error: Exception) -> dict:
    """ì˜ˆì™¸ íƒ€ì…ë³„ ì—ëŸ¬ ë©”ì‹œì§€ ë° ìƒì„¸ ì •ë³´ ìƒì„±

    ì˜ˆì™¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ëª¨ë“  ì—ëŸ¬ëŠ” ë¡œê·¸ì— ê¸°ë¡ë©ë‹ˆë‹¤.

    Args:
        error: ë°œìƒí•œ ì˜ˆì™¸ ê°ì²´

    Returns:
        dict: {"message": str, "details": str, "error_type": str}
    """
    error_type = type(error).__name__
    error_msg = str(error)

    # ë¡œê¹… (ë””ë²„ê¹…ìš©)
    logger.error(f"Chat error occurred: {error_type} - {error_msg}", exc_info=True)

    # íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, TimeoutError):
        user_message = ChatConfig.ERROR_TIMEOUT
        details = f"ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•Šê±°ë‚˜ ìš”ì²­ì´ ë„ˆë¬´ ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    elif isinstance(error, MemoryError):
        user_message = ChatConfig.ERROR_MEMORY
        details = f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€í™” ê¸°ë¡ì„ ì •ë¦¬í•˜ê±°ë‚˜ ë” ì§§ì€ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”."
    elif isinstance(error, ConnectionError):
        user_message = ChatConfig.ERROR_NETWORK
        details = f"ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
    elif isinstance(error, AttributeError):
        # UnifiedRAG ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì œì¼ ê°€ëŠ¥ì„±
        user_message = ChatConfig.ERROR_INITIALIZATION
        details = f"ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”."
    elif isinstance(error, KeyError):
        # ë©”ì‹œì§€ êµ¬ì¡° ë¬¸ì œ
        logger.error(f"Message structure error: {error_msg}")
        user_message = ChatConfig.ERROR_GENERIC
        details = f"ë©”ì‹œì§€ êµ¬ì¡°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    else:
        # ì¼ë°˜ ì—ëŸ¬ - ë¯¼ê°í•œ ì •ë³´ëŠ” ë…¸ì¶œí•˜ì§€ ì•ŠìŒ
        user_message = ChatConfig.ERROR_GENERIC
        details = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    return {
        "message": user_message,
        "details": details,
        "error_type": error_type
    }


def _display_chat_history(messages: List[Dict[str, str]]) -> None:
    """ì±„íŒ… ê¸°ë¡ í‘œì‹œ

    ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ Streamlit chat UIë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    Evidenceê°€ í¬í•¨ëœ ë©”ì‹œì§€ëŠ” ì¶œì²˜ ë¬¸ì„œë„ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤.

    Args:
        messages: í‘œì‹œí•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    for msg_idx, message in enumerate(messages):
        # ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦
        if not _validate_message_structure(message):
            logger.warning(f"Skipping invalid message: {message}")
            continue

        try:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

                # Evidence í‘œì‹œ (assistant ë©”ì‹œì§€ì—ë§Œ)
                if message["role"] == "assistant" and message.get("evidence"):
                    _display_evidence_section(message["evidence"], msg_idx)

        except Exception as e:
            logger.error(f"Error displaying message: {e}")
            # í‘œì‹œ ì˜¤ë¥˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ì§€ ì•Šê³  ë¡œê·¸ë§Œ ë‚¨ê¹€
            continue


def _generate_ai_response(
    query: str,
    rag_instance: RAGProtocol,
    message_placeholder: Any,
    selected_filename: Optional[str] = None
) -> Optional[dict]:
    """AI ì‘ë‹µ ìƒì„± (Evidence í¬í•¨)

    RAG Pipelineì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ê³¼ ê·¼ê±° ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì‘ë‹µ íƒ€ì…(ê°ì²´/dict/str)ì„ ì•ˆì „í•˜ê²Œ ì •ê·œí™”í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        query: í–¥ìƒëœ ì¿¼ë¦¬ ë¬¸ìì—´
        rag_instance: RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
        message_placeholder: Streamlit placeholder ê°ì²´
        selected_filename: ì„ íƒëœ ë¬¸ì„œ íŒŒì¼ëª… (ìš°ì„  ê²€ìƒ‰ìš©, ì„ íƒì‚¬í•­)

    Returns:
        Optional[dict]: {"text": str, "evidence": []} ë˜ëŠ” None (ì—ëŸ¬ ì‹œ)
    """
    try:
        # RAG ì¸ìŠ¤í„´ìŠ¤ ê²€ì¦
        if rag_instance is None:
            raise AttributeError("RAG instance is None")

        if not hasattr(rag_instance, 'answer'):
            raise AttributeError("RAG instance has no 'answer' method")

        # ì‘ë‹µ ìƒì„± (ë‹¤ì–‘í•œ íƒ€ì… ê°€ëŠ¥: RAGResponse ê°ì²´, dict, str ë“±)
        # ì„ íƒëœ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ìš°ì„  ê²€ìƒ‰ì„ ìœ„í•´ ì „ë‹¬
        raw_response = rag_instance.answer(query, selected_filename=selected_filename)

        # ì‘ë‹µ ì •ê·œí™”: ëª¨ë“  íƒ€ì…ì„ dictë¡œ í†µì¼
        response = _normalize_rag_response(raw_response)

        # ì •ê·œí™”ëœ ì‘ë‹µì˜ textê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not response["text"].strip():
            logger.warning("Empty response text received after normalization")
            return None

        return response

    except Exception as e:
        error_info = _handle_error(e)

        # ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
        message_placeholder.error(error_info["message"])

        # ìƒì„¸ ì •ë³´ëŠ” expanderë¡œ ì œê³µ
        with message_placeholder.container():
            with st.expander("ğŸ” ì˜¤ë¥˜ ìƒì„¸ ì •ë³´", expanded=False):
                st.caption(f"**ì˜¤ë¥˜ ìœ í˜•**: {error_info['error_type']}")
                st.caption(f"**ìƒì„¸ ì„¤ëª…**: {error_info['details']}")
                st.info("ğŸ’¡ **í•´ê²° ë°©ë²•**: ìœ„ ì„¤ëª…ì„ ì°¸ê³ í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")

        return {"text": error_info["message"], "evidence": []}  # ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜


def _add_message(role: str, content: str, evidence: Optional[List] = None) -> None:
    """ë©”ì‹œì§€ ì¶”ê°€

    ì„¸ì…˜ ìƒíƒœì— ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    íƒ€ì„ìŠ¤íƒ¬í”„ì™€ evidenceë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

    Args:
        role: ë©”ì‹œì§€ ì—­í•  (user ë˜ëŠ” assistant)
        content: ë©”ì‹œì§€ ë‚´ìš©
        evidence: ì¶œì²˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    """
    message: ChatMessage = {
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    }

    # Evidence ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
    if evidence:
        message["evidence"] = evidence

    st.session_state.messages.append(message)

    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    st.session_state.messages = _cleanup_old_messages(st.session_state.messages)


# ===== ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====

def render_chat_interface(unified_rag_instance: RAGProtocol) -> None:
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§

    ChatGPT ìŠ¤íƒ€ì¼ì˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    - ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
    - ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
    - ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    - AI ì‘ë‹µ ìƒì„±
    - ì—ëŸ¬ ì²˜ë¦¬
    - ë©”ëª¨ë¦¬ ê´€ë¦¬

    Args:
        unified_rag_instance: UnifiedRAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
    """
    # 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    _initialize_chat_state()

    # 1-1. ì„ íƒëœ ë¬¸ì„œ ì•Œë¦¼ (ì‚¬ì´ë“œë°”ì—ì„œ ë¬¸ì„œ ì„ íƒì‹œ)
    if 'selected_doc' in st.session_state and st.session_state.selected_doc is not None and st.session_state.get('show_doc_preview', False):
        selected_doc = st.session_state.selected_doc
        # pandas Seriesê°€ ì•„ë‹Œ dictì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
        if isinstance(selected_doc, dict):
            title = selected_doc.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')
            col1, col2 = st.columns([10, 1])
            with col1:
                st.info(f"ğŸ¯ **ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ**: {title} ë¬¸ì„œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤")
            with col2:
                if st.button("âŒ", key="clear_doc_context", help="ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ í•´ì œ"):
                    st.session_state.show_doc_preview = False
                    if 'selected_doc' in st.session_state:
                        del st.session_state.selected_doc
                    # Streamlit ìë™ ì¬ë Œë”ë§ìœ¼ë¡œ ì¶©ë¶„ (st.rerun() ì œê±°, 2025-11-07)

    # 2. ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
    _display_chat_history(st.session_state.messages)

    # 3. ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input(ChatConfig.INPUT_PLACEHOLDER):
        # 3-1. ì…ë ¥ ê²€ì¦
        is_valid, error_msg = _validate_input(prompt)
        if not is_valid:
            st.error(error_msg)
            return

        # 3-2. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        _add_message(ChatConfig.ROLE_USER, prompt)

        # 3-3. ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message(ChatConfig.ROLE_USER):
            st.markdown(prompt)

        # 3-4. AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with st.chat_message(ChatConfig.ROLE_ASSISTANT):
            message_placeholder = st.empty()

            # ëŒ€í™” ë§¥ë½ êµ¬ì„±
            context = _build_conversation_context(st.session_state.messages)

            # í–¥ìƒëœ ì¿¼ë¦¬ ìƒì„±
            enhanced_query = _create_enhanced_query(context, prompt)

            # ì„ íƒëœ ë¬¸ì„œ í™•ì¸ (ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•œ ë¬¸ì„œ ìš°ì„  ê²€ìƒ‰ìš©)
            selected_filename = None
            doc = st.session_state.get('selected_doc')
            if doc is not None:
                try:
                    # ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” pandas Seriesì—ì„œ filename ì¶”ì¶œ
                    selected_filename = doc.get('filename') if hasattr(doc, 'get') else doc['filename']
                    if selected_filename:
                        logger.info(f"ğŸ“Œ ì„ íƒëœ ë¬¸ì„œ ìš°ì„  ê²€ìƒ‰: {selected_filename}")
                except (KeyError, TypeError, AttributeError):
                    pass

            # AI ì‘ë‹µ ìƒì„±
            with st.spinner(ChatConfig.SPINNER_TEXT):
                response = _generate_ai_response(
                    enhanced_query,
                    unified_rag_instance,
                    message_placeholder,
                    selected_filename=selected_filename
                )

                # ì‘ë‹µì´ ìˆìœ¼ë©´ í‘œì‹œ ë° ì €ì¥
                if response:
                    # ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ì ì§„ì ìœ¼ë¡œ í‘œì‹œ (ChatGPT ìŠ¤íƒ€ì¼)
                    # ìºì‹œì—ì„œ ê°€ì ¸ì˜¨ ê²½ìš° ë¹ ë¥´ê²Œ, ìƒˆë¡œ ìƒì„±í•œ ê²½ìš° ì²œì²œíˆ
                    from_cache = response.get("status", {}).get("from_cache")

                    # ìºì‹œ í”¼ë“œë°± ë°°ì§€ í‘œì‹œ
                    if from_cache:
                        st.caption("âš¡ **Cached** - ì´ì „ ì‘ë‹µì„ ë¹ ë¥´ê²Œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤")

                    if from_cache:
                        # ìºì‹œëœ ì‘ë‹µì€ ì¦‰ì‹œ í‘œì‹œ (ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ ì—†ìŒ)
                        message_placeholder.markdown(response["text"])
                    else:
                        # ìƒˆë¡œ ìƒì„±ëœ ì‘ë‹µì€ ì ì§„ì ìœ¼ë¡œ í‘œì‹œ
                        streaming_speed = os.getenv("STREAMING_SPEED", "medium")  # slow, medium, fast
                        for partial_text in stream_text_smart(response["text"], speed=streaming_speed):
                            message_placeholder.markdown(partial_text + "â–Œ")  # ì»¤ì„œ íš¨ê³¼
                        # ìµœì¢… í…ìŠ¤íŠ¸ (ì»¤ì„œ ì œê±°)
                        message_placeholder.markdown(response["text"])

                    # Evidence í‘œì‹œ (session_state ê´€ë¦¬ë¡œ ë¯¸ë¦¬ë³´ê¸° í´ë¦­ ì‹œì—ë„ ìœ ì§€ë¨)
                    if response.get("evidence"):
                        # ìƒˆ ì‘ë‹µì˜ ì¸ë±ìŠ¤ëŠ” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ê°€ ë  ê²ƒì„
                        # í•˜ì§€ë§Œ ì•„ì§ ë©”ì‹œì§€ê°€ ì €ì¥ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ í˜„ì¬ ê¸¸ì´ë¥¼ ì‚¬ìš©
                        current_msg_idx = len(st.session_state.messages)
                        _display_evidence_section(response["evidence"], current_msg_idx)

                    # ì§„ë‹¨ íŒ¨ë„ (DIAG_RAG=trueì¼ ë•Œë§Œ í‘œì‹œ)
                    if DIAG_RAG and response.get("diagnostics"):
                        diag = response["diagnostics"]
                        with st.expander("ğŸ” ì§„ë‹¨ ì •ë³´ (Diagnostics)", expanded=False):
                            # ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
                            col1, col2, col3 = st.columns(3)

                            with col1:
                                st.metric("ëª¨ë“œ", diag.get("mode", "unknown"))
                                st.metric("ìƒì„± ê²½ë¡œ", diag.get("generate_path", "unknown"))
                                # ìºì‹œ íˆíŠ¸ ì—¬ë¶€
                                cache_hit = "âš¡ Hit" if diag.get("cache_hit") else "âŒ Miss"
                                st.metric("ìºì‹œ", cache_hit)

                            with col2:
                                st.metric("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", diag.get("retrieved_k", 0))
                                st.metric("ì••ì¶• í›„ ë¬¸ì„œ ìˆ˜", diag.get("after_compress_k", 0))
                                # ìŠ¤ë‹ˆí« ì´ ê¸€ììˆ˜
                                snippet_chars = diag.get("snippet_total_chars", 0)
                                st.metric("ìŠ¤ë‹ˆí« ì´ ê¸€ììˆ˜", f"{snippet_chars:,}")

                            with col3:
                                st.metric("Evidence ê°œìˆ˜", diag.get("evidence_count", 0))
                                # í† í° ì‚¬ìš©ëŸ‰
                                input_tokens = diag.get("input_tokens", 0)
                                output_tokens = diag.get("output_tokens", 0)
                                st.metric("ì…ë ¥ í† í°", f"{input_tokens:,}")
                                st.metric("ì¶œë ¥ í† í°", f"{output_tokens:,}")

                            # ìƒì„¸ ì •ë³´ (ì‘ì€ í…ìŠ¤íŠ¸ë¡œ)
                            st.caption(f"ì••ì¶• ë¹„ìœ¨: {diag.get('compression_ratio', 'N/A')}")
                            st.caption(f"ìµœì¢… ì‚¬ìš© ë¬¸ì„œ ìˆ˜: {diag.get('used_k', 0)}")
                            # ì‘ë‹µ ì‹œê°„
                            latency_ms = diag.get("latency_ms", 0)
                            st.caption(f"ì‘ë‹µ ì‹œê°„: {latency_ms:,}ms ({latency_ms/1000:.2f}s)")
                            # Evidence ê°•ì œ ì£¼ì… ì—¬ë¶€
                            injected = "Yes" if diag.get("evidence_injected") else "No"
                            st.caption(f"Evidence ê°•ì œ ì£¼ì…: {injected}")

                    # ë©”ì‹œì§€ ì €ì¥ (í…ìŠ¤íŠ¸ + evidence)
                    _add_message(ChatConfig.ROLE_ASSISTANT, response["text"], evidence=response.get("evidence"))
                else:
                    # ì‘ë‹µì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì—ëŸ¬ ë©”ì‹œì§€
                    error_msg = ChatConfig.ERROR_GENERIC
                    message_placeholder.markdown(error_msg)
                    _add_message(ChatConfig.ROLE_ASSISTANT, error_msg)

    # 4. UI êµ¬ë¶„ì„ 
    st.markdown(ChatConfig.DIVIDER)
