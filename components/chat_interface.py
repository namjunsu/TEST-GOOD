"""
Chat Interface Component
ChatGPT ìŠ¤íƒ€ì¼ì˜ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ UIë¥¼ ë Œë”ë§í•˜ëŠ” ì»´í¬ë„ŒíŠ¸

ê°œì„  ì‚¬í•­:
- ì™„ë²½í•œ íƒ€ì… ì‹œìŠ¤í…œ (TypedDict, Protocol)
- ìƒìˆ˜ ì •ì˜ë¡œ ë§¤ì§ ë„˜ë²„/ë¬¸ìì—´ ì œê±°
- í—¬í¼ í•¨ìˆ˜ ë¶„ë¦¬ (Single Responsibility Principle)
- ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬ (íƒ€ì…ë³„ ì²˜ë¦¬, ë¡œê¹…)
- ë©”ëª¨ë¦¬ ê´€ë¦¬ (ìë™ ë©”ì‹œì§€ ì •ë¦¬)
- ì…ë ¥ ê²€ì¦ ë° ë³´ì•ˆ ê°•í™”
- í¬ê´„ì ì¸ ë¬¸ì„œí™”
"""

import os
import streamlit as st
import requests
from typing import List, Dict, Optional, Protocol, Any
from typing_extensions import TypedDict, Literal
from datetime import datetime
from functools import lru_cache
from pathlib import Path

from app.core.logging import get_logger


# ===== ë¡œê¹… ì„¤ì • =====
logger = get_logger(__name__)

# ì§„ë‹¨ ëª¨ë“œ ì„¤ì •
DIAG_RAG = os.getenv('DIAG_RAG', 'false').lower() == 'true'


# ===== íƒ€ì… ì •ì˜ =====
class ChatMessage(TypedDict):
    """ì±„íŒ… ë©”ì‹œì§€ êµ¬ì¡°"""
    role: Literal["user", "assistant"]
    content: str
    timestamp: str


class RAGProtocol(Protocol):
    """RAG Pipeline ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (Evidence í¬í•¨)"""
    def answer(self, query: str, top_k: Optional[int] = None) -> dict:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±

        Returns:
            dict: {
                "text": ë‹µë³€ í…ìŠ¤íŠ¸,
                "evidence": [{"doc_id": str, "page": int, "snippet": str, "meta": dict}, ...]
            }
        """
        ...


# ===== ìƒìˆ˜ ì •ì˜ =====
class ChatConfig:
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ìƒìˆ˜"""
    # ì—­í•  ì •ì˜
    ROLE_USER = "user"
    ROLE_ASSISTANT = "assistant"

    # í•œê¸€ ì—­í• ëª…
    ROLE_DISPLAY_USER = "ì‚¬ìš©ì"
    ROLE_DISPLAY_ASSISTANT = "AI"

    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    MAX_MESSAGES = 100  # ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
    MAX_CONTEXT_TURNS = 3  # ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨í•  ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜
    MAX_MESSAGE_LENGTH = 10000  # ìµœëŒ€ ë©”ì‹œì§€ ê¸¸ì´

    # UI ë¬¸ìì—´
    INPUT_PLACEHOLDER = "ğŸ’¬ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    SPINNER_TEXT = "ğŸ¤” ìƒê° ì¤‘..."
    DIVIDER = "---"

    # ì—ëŸ¬ ë©”ì‹œì§€
    ERROR_GENERIC = "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    ERROR_TIMEOUT = "â±ï¸ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    ERROR_MEMORY = "ğŸ’¾ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€í™” ë‚´ì—­ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”."
    ERROR_NETWORK = "ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    ERROR_INITIALIZATION = "âš™ï¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    ERROR_INVALID_INPUT = "âš ï¸ ì…ë ¥ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë” ì§§ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    CONTEXT_PREFIX = "ì´ì „ ëŒ€í™” ë§¥ë½:"
    CURRENT_QUERY_PREFIX = "í˜„ì¬ ì§ˆë¬¸:"


# ===== í—¬í¼ í•¨ìˆ˜ =====

@lru_cache(maxsize=1)
def _get_api_base_url() -> str:
    """FastAPI ê¸°ì¤€ URLì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´ (ìºì‹œ ì ìš©)

    ìš°ì„ ìˆœìœ„:
    1. í™˜ê²½ë³€ìˆ˜ PUBLIC_API_BASE
    2. FastAPI /api/config ì—”ë“œí¬ì¸íŠ¸
    3. ê¸°ë³¸ê°’ (localhost:7860)

    Returns:
        str: API ê¸°ì¤€ URL
    """
    # 1. í™˜ê²½ë³€ìˆ˜ ìš°ì„ 
    env_base = os.getenv("PUBLIC_API_BASE")
    if env_base:
        logger.info(f"Using PUBLIC_API_BASE from env: {env_base}")
        return env_base.rstrip("/")

    # 2. FastAPIì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
    try:
        # Streamlitì´ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°, FastAPIëŠ” ê°™ì€ ë¨¸ì‹ ì˜ 7860 í¬íŠ¸
        api_url = "http://localhost:7860/api/config"
        response = requests.get(api_url, timeout=2)
        if response.status_code == 200:
            config = response.json()
            base_url = config.get("base_url", "http://localhost:7860")
            logger.info(f"Fetched API base URL from FastAPI: {base_url}")
            return base_url
    except Exception as e:
        logger.warning(f"Failed to fetch API config from FastAPI: {e}")

    # 3. ê¸°ë³¸ê°’
    default_url = "http://localhost:7860"
    logger.info(f"Using default API base URL: {default_url}")
    return default_url


def render_doc_card(
    index: int,
    filename: str,
    file_path: Optional[Path],
    doctype: Optional[str],
    display_date: Optional[str],
    drafter: Optional[str],
    summary: str,
    show_preview_inline: bool = False
) -> None:
    """ë¬¸ì„œ ì¹´ë“œ ë Œë”ë§ (ê³ ì • ë ˆì´ì•„ì›ƒ) - ì•ˆì „ê°€ë“œ + ìºì‹œ ì ìš©

    1í–‰: ğŸ“„ íŒŒì¼ëª…
    2í–‰: ë©”íƒ€ì¹© (doctype Â· date Â· drafter)
    3í–‰: LLM ìš”ì•½ (ìµœëŒ€ 2ì¤„, 160ì)
    4í–‰: ë²„íŠ¼ (ë¯¸ë¦¬ë³´ê¸° / ë‹¤ìš´ë¡œë“œ)
    5í–‰: PDF ë·°ì–´ (ì„ íƒì , ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)

    Args:
        index: ì¹´ë“œ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
        filename: íŒŒì¼ëª…
        file_path: ì‹¤ì œ íŒŒì¼ ê²½ë¡œ (Path ê°ì²´)
        doctype: ë¬¸ì„œ íƒ€ì…
        display_date: ë‚ ì§œ
        drafter: ê¸°ì•ˆì
        summary: LLM ìš”ì•½ (ì´ë¯¸ 160ìë¡œ ì œí•œëœ ìƒíƒœ)
        show_preview_inline: ì¸ë¼ì¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ ì—¬ë¶€
    """
    from utils.pdf_utils import download_pdf_button, render_pdf_preview

    # 1í–‰: íŒŒì¼ëª…
    st.markdown(f"**{index}. ğŸ“„ {filename}**")

    # 2í–‰: ë©”íƒ€ì¹© (ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ í‘œì‹œ)
    meta_chips = []
    if doctype:
        meta_chips.append(f"ğŸ· {doctype}")
    if display_date:
        meta_chips.append(f"ğŸ“… {display_date}")
    if drafter:
        meta_chips.append(f"âœ {drafter}")

    if meta_chips:
        st.caption(" Â· ".join(meta_chips))
    else:
        st.caption("â€”")  # ë©”íƒ€ ì •ë³´ ì—†ìŒ

    # 3í–‰: ìš”ì•½ (ìµœëŒ€ 2ì¤„, 160ì)
    summary_truncated = summary[:160].strip()
    if len(summary) > 160:
        summary_truncated += "..."
    st.markdown(f"{summary_truncated}")

    # 4í–‰: ë²„íŠ¼ (ì•ˆì „ê°€ë“œ + í‘œì¤€ í•¨ìˆ˜ ì‚¬ìš©)
    if file_path:
        col1, col2 = st.columns([1, 1])

        # ë¯¸ë¦¬ë³´ê¸° ë²„íŠ¼ (expander í† ê¸€)
        with col1:
            preview_key = f"preview_btn_{index}_{filename[:10]}"
            if st.button("ğŸ” ë¯¸ë¦¬ë³´ê¸°", key=preview_key, use_container_width=True):
                # ì„¸ì…˜ ìƒíƒœì— ë¯¸ë¦¬ë³´ê¸° ì •ë³´ ì €ì¥
                session_key = f"show_preview_{index}_{filename}"
                st.session_state[session_key] = not st.session_state.get(session_key, False)
                st.rerun()

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (í‘œì¤€ í•¨ìˆ˜ ì‚¬ìš©)
        with col2:
            download_pdf_button(
                file_path=str(file_path),
                key=f"download_{index}_{filename[:10]}",
                use_container_width=True
            )

        # 5í–‰: PDF ë·°ì–´ (ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”, ë‹¤ìš´ë¡œë“œ fallback)
        # ê¸°ë³¸ì€ ì ‘í˜ ìƒíƒœ, ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ í¼ì¹¨
        session_key = f"show_preview_{index}_{filename}"
        if st.session_state.get(session_key, False):
            with st.expander("ğŸ“„ PDF ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                render_pdf_preview(
                    file_path=str(file_path),
                    height=600,
                    show_download_fallback=True
                )
    else:
        st.warning("âš ï¸ íŒŒì¼ ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")


def _normalize_rag_response(resp: Any) -> dict:
    """RAG ì‘ë‹µì„ ì•ˆì „í•˜ê²Œ dictë¡œ ì •ê·œí™”

    RAG Pipelineì´ ë°˜í™˜í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ íƒ€ì…(ê°ì²´, dict, str)ì„
    í†µì¼ëœ dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        resp: RAG Pipelineì˜ ì‘ë‹µ (RAGResponse ê°ì²´, dict, str ë“±)

    Returns:
        dict: {"text": str, "evidence": list} í˜•ì‹ì˜ ì •ê·œí™”ëœ ì‘ë‹µ

    Examples:
        >>> _normalize_rag_response(RAGResponse(text="ë‹µë³€", evidence=[...]))
        {"text": "ë‹µë³€", "evidence": [...]}

        >>> _normalize_rag_response(RAGResponse(answer="ë‹µë³€", sources=[...]))
        {"text": "ë‹µë³€", "evidence": [...]}

        >>> _normalize_rag_response({"text": "ë‹µë³€", "evidence": [...]})
        {"text": "ë‹µë³€", "evidence": [...]}

        >>> _normalize_rag_response("ì§ì ‘ ë¬¸ìì—´ ë‹µë³€")
        {"text": "ì§ì ‘ ë¬¸ìì—´ ë‹µë³€", "evidence": []}
    """
    # None ì²´í¬
    if resp is None:
        logger.warning("Received None response from RAG")
        return {"text": "", "evidence": []}

    # ë¬¸ìì—´ì¸ ê²½ìš°
    if isinstance(resp, str):
        return {"text": resp, "evidence": []}

    # ê°ì²´ì¸ ê²½ìš° (RAGResponse ë“±)
    # text, answer í•„ë“œ ëª¨ë‘ ì§€ì›
    if hasattr(resp, "text") or hasattr(resp, "answer"):
        text = getattr(resp, "text", None) or getattr(resp, "answer", "")
        # evidence, evidences, sources, sources_cited ëª¨ë‘ ì‹œë„
        evidence = (
            getattr(resp, "evidence", None) or
            getattr(resp, "evidences", None) or
            getattr(resp, "sources", None) or
            getattr(resp, "sources_cited", None) or
            []
        )
        return {"text": str(text), "evidence": evidence}

    # dictì¸ ê²½ìš°
    if isinstance(resp, dict):
        text = resp.get("text") or resp.get("answer", "")
        evidence = (
            resp.get("evidence") or
            resp.get("evidences") or
            resp.get("sources") or
            resp.get("sources_cited") or
            []
        )
        return {"text": str(text), "evidence": evidence}

    # ê·¸ ì™¸ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…
    logger.warning(f"Unknown response type: {type(resp)}")
    return {"text": str(resp), "evidence": []}


def _initialize_chat_state() -> None:
    """ì±„íŒ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

    ì„¸ì…˜ ìƒíƒœì— messages ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        logger.info("Chat session initialized")


def _validate_message_structure(message: Any) -> bool:
    """ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦

    Args:
        message: ê²€ì¦í•  ë©”ì‹œì§€ ê°ì²´

    Returns:
        bool: ìœ íš¨í•œ ë©”ì‹œì§€ êµ¬ì¡°ë©´ True, ì•„ë‹ˆë©´ False
    """
    if not isinstance(message, dict):
        return False

    required_keys = {'role', 'content'}
    if not required_keys.issubset(message.keys()):
        return False

    if message['role'] not in [ChatConfig.ROLE_USER, ChatConfig.ROLE_ASSISTANT]:
        return False

    if not isinstance(message['content'], str):
        return False

    return True


def _validate_input(prompt: str) -> tuple[bool, Optional[str]]:
    """ì‚¬ìš©ì ì…ë ¥ ê²€ì¦

    Args:
        prompt: ì‚¬ìš©ì ì…ë ¥ ë¬¸ìì—´

    Returns:
        tuple[bool, Optional[str]]: (ìœ íš¨ì„±, ì—ëŸ¬ ë©”ì‹œì§€)
    """
    # ë¹ˆ ë¬¸ìì—´ ì²´í¬
    if not prompt or not prompt.strip():
        return False, "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."

    # ê¸¸ì´ ì²´í¬
    if len(prompt) > ChatConfig.MAX_MESSAGE_LENGTH:
        return False, ChatConfig.ERROR_INVALID_INPUT

    # ê¸°ë³¸ ìœ„í—˜ ë¬¸ì ì²´í¬ (ì„ íƒì , í•„ìš”ì‹œ í™•ì¥)
    # dangerous_patterns = ['<script>', 'javascript:', 'onerror=']
    # if any(pattern in prompt.lower() for pattern in dangerous_patterns):
    #     return False, "ë³´ì•ˆìƒ í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì…ë ¥ì…ë‹ˆë‹¤."

    return True, None


def _cleanup_old_messages(messages: List[ChatMessage]) -> List[ChatMessage]:
    """ì˜¤ë˜ëœ ë©”ì‹œì§€ ì •ë¦¬

    ë©”ì‹œì§€ ìˆ˜ê°€ MAX_MESSAGESë¥¼ ì´ˆê³¼í•˜ë©´ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¶€í„° ì‚­ì œí•©ë‹ˆë‹¤.
    ìµœê·¼ ë©”ì‹œì§€ë“¤ë§Œ ìœ ì§€í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

    Args:
        messages: ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸

    Returns:
        List[ChatMessage]: ì •ë¦¬ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    if len(messages) > ChatConfig.MAX_MESSAGES:
        removed_count = len(messages) - ChatConfig.MAX_MESSAGES
        logger.warning(f"Message limit exceeded. Removing {removed_count} old messages.")
        return messages[-ChatConfig.MAX_MESSAGES:]
    return messages


def _build_conversation_context(messages: List[Dict[str, str]], max_turns: int = ChatConfig.MAX_CONTEXT_TURNS) -> str:
    """ëŒ€í™” ë§¥ë½ êµ¬ì„±

    ìµœê·¼ Nê°œ í„´ì˜ ëŒ€í™”ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    íš¨ìœ¨ì ì¸ ë¬¸ìì—´ ì—°ê²°ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        messages: ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        max_turns: í¬í•¨í•  ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜ (ê¸°ë³¸ê°’: 3)

    Returns:
        str: êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    # ë©”ì‹œì§€ê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ
    if len(messages) < 2:
        return ""

    # ìµœê·¼ Ní„´ = N*2ê°œ ë©”ì‹œì§€ (user + assistant ìŒ)
    # í˜„ì¬ user ë©”ì‹œì§€ëŠ” ì´ë¯¸ ì¶”ê°€ëœ ìƒíƒœì´ë¯€ë¡œ, ê·¸ ì´ì „ ë©”ì‹œì§€ë“¤ë§Œ ê°€ì ¸ì˜´
    max_messages = max_turns * 2
    recent_messages = messages[-(max_messages + 1):-1]  # ë§ˆì§€ë§‰ ë©”ì‹œì§€(í˜„ì¬ ì§ˆë¬¸) ì œì™¸

    # íš¨ìœ¨ì ì¸ ë¬¸ìì—´ êµ¬ì„± (ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)
    context_parts = []

    for msg in recent_messages:
        # ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦
        if not _validate_message_structure(msg):
            logger.warning(f"Invalid message structure in context: {msg}")
            continue

        # ì—­í•  ë³€í™˜
        role = msg['role']
        display_role = ChatConfig.ROLE_DISPLAY_USER if role == ChatConfig.ROLE_USER else ChatConfig.ROLE_DISPLAY_ASSISTANT

        # ë©”ì‹œì§€ ì¶”ê°€
        context_parts.append(f"{display_role}: {msg['content']}")

    # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    if not context_parts:
        return ""

    # ì¡°ì¸í•˜ì—¬ ë°˜í™˜
    return "\n".join(context_parts)


def _create_enhanced_query(context: str, prompt: str) -> str:
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í–¥ìƒëœ ì¿¼ë¦¬ ìƒì„±

    Args:
        context: ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
        prompt: í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        str: í–¥ìƒëœ ì¿¼ë¦¬ ë¬¸ìì—´
    """
    if context:
        return f"{ChatConfig.CONTEXT_PREFIX}\n{context}\n\n{ChatConfig.CURRENT_QUERY_PREFIX} {prompt}"
    return prompt


def _handle_error(error: Exception) -> str:
    """ì˜ˆì™¸ íƒ€ì…ë³„ ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„±

    ì˜ˆì™¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ëª¨ë“  ì—ëŸ¬ëŠ” ë¡œê·¸ì— ê¸°ë¡ë©ë‹ˆë‹¤.

    Args:
        error: ë°œìƒí•œ ì˜ˆì™¸ ê°ì²´

    Returns:
        str: ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  ì—ëŸ¬ ë©”ì‹œì§€
    """
    error_type = type(error).__name__
    error_msg = str(error)

    # ë¡œê¹… (ë””ë²„ê¹…ìš©)
    logger.error(f"Chat error occurred: {error_type} - {error_msg}", exc_info=True)

    # íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, TimeoutError):
        return ChatConfig.ERROR_TIMEOUT
    elif isinstance(error, MemoryError):
        return ChatConfig.ERROR_MEMORY
    elif isinstance(error, ConnectionError):
        return ChatConfig.ERROR_NETWORK
    elif isinstance(error, AttributeError):
        # UnifiedRAG ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì œì¼ ê°€ëŠ¥ì„±
        return ChatConfig.ERROR_INITIALIZATION
    elif isinstance(error, KeyError):
        # ë©”ì‹œì§€ êµ¬ì¡° ë¬¸ì œ
        logger.error(f"Message structure error: {error_msg}")
        return ChatConfig.ERROR_GENERIC
    else:
        # ì¼ë°˜ ì—ëŸ¬ - ë¯¼ê°í•œ ì •ë³´ëŠ” ë…¸ì¶œí•˜ì§€ ì•ŠìŒ
        return ChatConfig.ERROR_GENERIC


def _display_chat_history(messages: List[Dict[str, str]]) -> None:
    """ì±„íŒ… ê¸°ë¡ í‘œì‹œ

    ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ Streamlit chat UIë¡œ í‘œì‹œí•©ë‹ˆë‹¤.

    Args:
        messages: í‘œì‹œí•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    for message in messages:
        # ë©”ì‹œì§€ êµ¬ì¡° ê²€ì¦
        if not _validate_message_structure(message):
            logger.warning(f"Skipping invalid message: {message}")
            continue

        try:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        except Exception as e:
            logger.error(f"Error displaying message: {e}")
            # í‘œì‹œ ì˜¤ë¥˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ì§€ ì•Šê³  ë¡œê·¸ë§Œ ë‚¨ê¹€
            continue


def _generate_ai_response(
    query: str,
    rag_instance: RAGProtocol,
    message_placeholder: Any
) -> Optional[dict]:
    """AI ì‘ë‹µ ìƒì„± (Evidence í¬í•¨)

    RAG Pipelineì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ê³¼ ê·¼ê±° ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì‘ë‹µ íƒ€ì…(ê°ì²´/dict/str)ì„ ì•ˆì „í•˜ê²Œ ì •ê·œí™”í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        query: í–¥ìƒëœ ì¿¼ë¦¬ ë¬¸ìì—´
        rag_instance: RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
        message_placeholder: Streamlit placeholder ê°ì²´

    Returns:
        Optional[dict]: {"text": str, "evidence": []} ë˜ëŠ” None (ì—ëŸ¬ ì‹œ)
    """
    try:
        # RAG ì¸ìŠ¤í„´ìŠ¤ ê²€ì¦
        if rag_instance is None:
            raise AttributeError("RAG instance is None")

        if not hasattr(rag_instance, 'answer'):
            raise AttributeError("RAG instance has no 'answer' method")

        # ì‘ë‹µ ìƒì„± (ë‹¤ì–‘í•œ íƒ€ì… ê°€ëŠ¥: RAGResponse ê°ì²´, dict, str ë“±)
        raw_response = rag_instance.answer(query)

        # ì‘ë‹µ ì •ê·œí™”: ëª¨ë“  íƒ€ì…ì„ dictë¡œ í†µì¼
        response = _normalize_rag_response(raw_response)

        # ì •ê·œí™”ëœ ì‘ë‹µì˜ textê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not response["text"].strip():
            logger.warning("Empty response text received after normalization")
            return None

        return response

    except Exception as e:
        error_msg = _handle_error(e)
        message_placeholder.markdown(error_msg)
        return {"text": error_msg, "evidence": []}  # ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜


def _add_message(role: str, content: str) -> None:
    """ë©”ì‹œì§€ ì¶”ê°€

    ì„¸ì…˜ ìƒíƒœì— ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

    Args:
        role: ë©”ì‹œì§€ ì—­í•  (user ë˜ëŠ” assistant)
        content: ë©”ì‹œì§€ ë‚´ìš©
    """
    message: ChatMessage = {
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    }

    st.session_state.messages.append(message)

    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    st.session_state.messages = _cleanup_old_messages(st.session_state.messages)


# ===== ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ =====

def render_chat_interface(unified_rag_instance: RAGProtocol) -> None:
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§

    ChatGPT ìŠ¤íƒ€ì¼ì˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    - ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
    - ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
    - ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    - AI ì‘ë‹µ ìƒì„±
    - ì—ëŸ¬ ì²˜ë¦¬
    - ë©”ëª¨ë¦¬ ê´€ë¦¬

    Args:
        unified_rag_instance: UnifiedRAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
    """
    # 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    _initialize_chat_state()

    # 2. ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
    _display_chat_history(st.session_state.messages)

    # 3. ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input(ChatConfig.INPUT_PLACEHOLDER):
        # 3-1. ì…ë ¥ ê²€ì¦
        is_valid, error_msg = _validate_input(prompt)
        if not is_valid:
            st.error(error_msg)
            return

        # 3-2. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        _add_message(ChatConfig.ROLE_USER, prompt)

        # 3-3. ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message(ChatConfig.ROLE_USER):
            st.markdown(prompt)

        # 3-4. AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with st.chat_message(ChatConfig.ROLE_ASSISTANT):
            message_placeholder = st.empty()

            # ëŒ€í™” ë§¥ë½ êµ¬ì„±
            context = _build_conversation_context(st.session_state.messages)

            # í–¥ìƒëœ ì¿¼ë¦¬ ìƒì„±
            enhanced_query = _create_enhanced_query(context, prompt)

            # AI ì‘ë‹µ ìƒì„±
            with st.spinner(ChatConfig.SPINNER_TEXT):
                response = _generate_ai_response(
                    enhanced_query,
                    unified_rag_instance,
                    message_placeholder
                )

                # ì‘ë‹µì´ ìˆìœ¼ë©´ í‘œì‹œ ë° ì €ì¥
                if response:
                    # ë‹µë³€ í…ìŠ¤íŠ¸ í‘œì‹œ
                    message_placeholder.markdown(response["text"])

                    # Evidence í‘œì‹œ (Top-K=5 ì œí•œ, ê³ ì • ì¹´ë“œ ë ˆì´ì•„ì›ƒ, ë¬¸ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í†µì¼)
                    if response.get("evidence"):
                        evidence_list = response["evidence"]

                        # Top-K=5 ì œí•œ
                        MAX_DISPLAY = 5
                        display_evidence = evidence_list[:MAX_DISPLAY]
                        has_more = len(evidence_list) > MAX_DISPLAY

                        # ê¸°ë³¸ì€ ì ‘í˜ ìƒíƒœ (ë²„íŠ¼ í´ë¦­ í•„ìš”)
                        auto_expand = False

                        with st.expander(f"ğŸ“š ì¶œì²˜ ë¬¸ì„œ ({len(display_evidence)}ê±´)", expanded=auto_expand):
                            for i, ev in enumerate(display_evidence, 1):
                                # Evidenceê°€ dict ë˜ëŠ” ê°ì²´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
                                if isinstance(ev, dict):
                                    doc_id = ev.get("doc_id") or ev.get("chunk_id", "unknown")
                                    filename = ev.get("filename", doc_id)
                                    snippet = ev.get("snippet") or ev.get("content", "") or ev.get("text", "")
                                    file_path_str = ev.get("file_path")  # â† ì‹¤ì œ íŒŒì¼ ê²½ë¡œ
                                    meta = ev.get("meta", {})
                                else:
                                    # ê°ì²´ì¸ ê²½ìš°
                                    doc_id = getattr(ev, "doc_id", None) or getattr(ev, "chunk_id", "unknown")
                                    filename = getattr(ev, "filename", doc_id)
                                    snippet = getattr(ev, "snippet", None) or getattr(ev, "content", "") or getattr(ev, "text", "")
                                    file_path_str = getattr(ev, "file_path", None)
                                    meta = getattr(ev, "meta", {})

                                # íŒŒì¼ ê²½ë¡œ ìƒì„± (year í´ë” ì§€ì›)
                                if file_path_str:
                                    file_path = Path(file_path_str)
                                else:
                                    # Fallback: _encode_file_ref ë¡œì§ê³¼ ë™ì¼
                                    import re
                                    year_match = re.search(r'(\d{4})-', filename)
                                    if year_match:
                                        year = year_match.group(1)
                                        file_path = Path(f"docs/year_{year}") / filename
                                    else:
                                        file_path = Path("docs") / filename

                                # ë©”íƒ€ ë°ì´í„° ì¶”ì¶œ
                                doctype = meta.get("doctype") if isinstance(meta, dict) else None
                                display_date = meta.get("date") or meta.get("display_date") if isinstance(meta, dict) else None
                                drafter = meta.get("drafter") if isinstance(meta, dict) else None

                                # ì¹´ë“œ ë Œë”ë§ (1ê±´ì¼ ë•Œë§Œ ì¸ë¼ì¸ ë¯¸ë¦¬ë³´ê¸° ìë™ í‘œì‹œ)
                                render_doc_card(
                                    index=i,
                                    filename=filename,
                                    file_path=file_path,
                                    doctype=doctype,
                                    display_date=display_date,
                                    drafter=drafter,
                                    summary=snippet,
                                    show_preview_inline=(auto_expand and i == 1)
                                )

                                # êµ¬ë¶„ì„  (ë§ˆì§€ë§‰ ì•„ì´í…œ ì œì™¸)
                                if i < len(display_evidence):
                                    st.markdown("---")

                            # ë” ë³´ê¸° ë²„íŠ¼ (5ê±´ ì´ˆê³¼ ì‹œ)
                            if has_more:
                                st.markdown("---")
                                remaining = len(evidence_list) - MAX_DISPLAY
                                st.info(f"ğŸ“„ {remaining}ê±´ì˜ ë¬¸ì„œê°€ ë” ìˆìŠµë‹ˆë‹¤. (í˜„ì¬ ìƒìœ„ {MAX_DISPLAY}ê±´ë§Œ í‘œì‹œ)")
                                # ì¶”í›„ "ë” ë³´ê¸°" ë²„íŠ¼ êµ¬í˜„ ê°€ëŠ¥

                    # ì§„ë‹¨ íŒ¨ë„ (DIAG_RAG=trueì¼ ë•Œë§Œ í‘œì‹œ)
                    if DIAG_RAG and response.get("diagnostics"):
                        diag = response["diagnostics"]
                        with st.expander("ğŸ” ì§„ë‹¨ ì •ë³´ (Diagnostics)", expanded=False):
                            # ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
                            col1, col2, col3 = st.columns(3)

                            with col1:
                                st.metric("ëª¨ë“œ", diag.get("mode", "unknown"))
                                st.metric("ìƒì„± ê²½ë¡œ", diag.get("generate_path", "unknown"))

                            with col2:
                                st.metric("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", diag.get("retrieved_k", 0))
                                st.metric("ì••ì¶• í›„ ë¬¸ì„œ ìˆ˜", diag.get("after_compress_k", 0))

                            with col3:
                                st.metric("Evidence ê°œìˆ˜", diag.get("evidence_count", 0))
                                injected = "Yes" if diag.get("evidence_injected") else "No"
                                st.metric("Evidence ê°•ì œ ì£¼ì…", injected)

                            # ìƒì„¸ ì •ë³´ (ì‘ì€ í…ìŠ¤íŠ¸ë¡œ)
                            st.caption(f"ì••ì¶• ë¹„ìœ¨: {diag.get('compression_ratio', 'N/A')}")
                            st.caption(f"ìµœì¢… ì‚¬ìš© ë¬¸ì„œ ìˆ˜: {diag.get('used_k', 0)}")

                    # ë©”ì‹œì§€ ì €ì¥ (í…ìŠ¤íŠ¸ë§Œ)
                    _add_message(ChatConfig.ROLE_ASSISTANT, response["text"])
                else:
                    # ì‘ë‹µì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì—ëŸ¬ ë©”ì‹œì§€
                    error_msg = ChatConfig.ERROR_GENERIC
                    message_placeholder.markdown(error_msg)
                    _add_message(ChatConfig.ROLE_ASSISTANT, error_msg)

    # 4. UI êµ¬ë¶„ì„ 
    st.markdown(ChatConfig.DIVIDER)
