"""
Sidebar Library Component
ì‚¬ì´ë“œë°”ì— ë¬¸ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ UIë¥¼ í‘œì‹œí•˜ëŠ” ì»´í¬ë„ŒíŠ¸
"""

import streamlit as st
import pandas as pd
from pathlib import Path
from typing import Optional
from utils.year_utils import safe_year_to_int, normalize_year_list, compare_year
from scripts.utils.lock import reindexing_lock, is_reindexing
from app.config.settings import RAG_MODEL


def display_document_list(
    filtered_df: pd.DataFrame,
    df: pd.DataFrame,
    prefix: str = "doc"
) -> Optional[pd.DataFrame]:
    """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜

    Args:
        filtered_df: í•„í„°ë§ëœ ë¬¸ì„œ DataFrame
        df: ì „ì²´ ë¬¸ì„œ DataFrame
        prefix: ë²„íŠ¼ í‚¤ prefix (ê³ ìœ ì„± ë³´ì¥)

    Returns:
        ë¹ˆ DataFrame ë˜ëŠ” None
    """
    if isinstance(filtered_df, pd.DataFrame) and not filtered_df.empty:
        doc_counter = 0  # ì „ì—­ ê³ ìœ  ì¹´ìš´í„°
        # year í•„ë“œë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ì •ë ¬ (year_utils ì‚¬ìš©)
        years = filtered_df['year'].unique()
        valid_years = normalize_year_list(years)

        for year in valid_years:
            # year_utilsì˜ compare_year í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë¹„êµ
            year_docs = filtered_df[
                filtered_df['year'].apply(lambda x: compare_year(x, year))
            ]

            # ì—°ë„ êµ¬ë¶„ì„ 
            st.markdown(f"### {year}ë…„ ({len(year_docs)}ê°œ)")

            # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ - ë‚ ì§œì™€ ë¬¸ì„œëª…
            for _, row in year_docs.iterrows():
                # ë‚ ì§œ ì²˜ë¦¬
                if row['date'] and len(row['date']) >= 10:
                    date_str = row['date'][5:10]  # MM-DD
                else:
                    date_str = "     "  # ë‚ ì§œ ì—†ìœ¼ë©´ ê³µë°±

                # ì œëª© ì²˜ë¦¬ (ê¸¸ë©´ ìë¥´ê¸°)
                title = row['title'][:30] + "..." if len(row['title']) > 30 else row['title']

                # ë‚ ì§œì™€ ì œëª©ì„ í•¨ê»˜ í‘œì‹œ
                button_text = f"[{date_str}] {title}"

                # ê³ ìœ í•œ í‚¤ ìƒì„± (prefix, ì¹´ìš´í„°, íŒŒì¼ëª… ì¡°í•©)
                unique_key = f"{prefix}_{doc_counter}_{row['filename'][:10]}"
                doc_counter += 1

                # ì‹¬í”Œí•œ ë²„íŠ¼ìœ¼ë¡œ ë¬¸ì„œ ì„ íƒ
                if st.button(button_text, key=unique_key, use_container_width=True):
                    st.session_state.selected_doc = row
                    st.session_state.show_doc_preview = True
                    # pdf_preview_shown ì´ˆê¸°í™” (ìƒˆ ë¬¸ì„œ ì„ íƒ ì‹œ)
                    st.session_state.pdf_preview_shown = False
                    # st.rerun() ì œê±° - Streamlit ìë™ ì¬ë Œë”ë§ (ë²„ê·¸ ìˆ˜ì • 2025-10-31)
    else:
        # ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì„ ë•Œ
        if not isinstance(filtered_df, pd.DataFrame):
            st.error("ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif filtered_df.empty:
            if df.empty:
                st.warning("ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. docs í´ë”ì— PDF íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            else:
                st.caption("í‘œì‹œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        return pd.DataFrame()


def render_sidebar_library(rag_instance) -> None:
    """ì‚¬ì´ë“œë°”ì— ë¬¸ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ UI ë Œë”ë§

    Args:
        rag_instance: RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ (st.session_state.rag)
    """
    from utils.document_loader import load_documents

    # ì‚¬ì´ë“œë°”ì—ë„ ë¡œê³  í‘œì‹œ (í°ìƒ‰ ë²„ì „, ì‘ê²Œ)
    if Path('logo_inverted.png').exists():
        st.image('logo_inverted.png', width=200)
    elif Path('logo.png').exists():
        st.image('logo.png', width=200)
    st.markdown("---")

    # ìë™ ì¸ë±ì‹± ìƒíƒœ í‘œì‹œ (ë¬¼ë¦¬ íŒŒì¼ ìˆ˜)
    st.markdown("### ğŸ“ íŒŒì¼ ìŠ¤ìº” (ë¬¼ë¦¬)")
    if 'auto_indexer' in st.session_state:
        stats = st.session_state.auto_indexer.get_statistics()
        col1, col2 = st.columns(2)
        with col1:
            st.metric("PDF", f"{stats['pdf_count']}ê°œ")
        with col2:
            st.metric("TXT", f"{stats['txt_count']}ê°œ")
        # ë¬¼ë¦¬ íŒŒì¼ ì´ ê°œìˆ˜ í‘œì‹œ
        physical_total = stats['pdf_count'] + stats['txt_count']
        st.caption(f"ë¬¼ë¦¬ íŒŒì¼ ì´ê³„: {physical_total}ê°œ")

        # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸
        if stats['last_update'] != 'Never':
            st.caption(f"ë§ˆì§€ë§‰ ì²´í¬: {stats['last_update'][:16]}")

    st.markdown("---")

    # ë¬¸ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìš”ì•½ (DB ê¸°ë°˜)
    st.markdown("### ğŸ“š ë¬¸ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬")
    try:
        from modules.metadata_db import MetadataDB
        from config.indexing import ALLOWED_EXTS

        db = MetadataDB()

        # í†µí•© ì¹´ìš´íŠ¸ API ì‚¬ìš© - ê³ ìœ  ë¬¸ì„œ ìˆ˜ (ì¤‘ë³µ ì œì™¸, í—ˆìš© í™•ì¥ìë§Œ)
        allowed_ext_list = [ext.replace(".", "") for ext in ALLOWED_EXTS]
        unique_count = db.count_unique_documents(allowed_ext=tuple(allowed_ext_list))
        st.metric("ì´ ë¬¸ì„œ", f"{unique_count}ê±´", help="MetadataDB ê¸°ì¤€")

        # í™•ì¥ìë³„ ì¹´ìš´íŠ¸ (ë¬¼ë¦¬ íŒŒì¼ ê¸°ì¤€)
        ext_counts = db.count_by_extension()

        # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¹´ìš´íŠ¸ (íŒ¨ì¹˜ 2025-10-31: MetadataDB ë‹¨ì¼ ì†ŒìŠ¤ ê°•ì œ)
        import os
        index_source = os.getenv("INDEX_SOURCE", "metadata")

        if index_source == "metadata":
            # MetadataDBë¥¼ ë‹¨ì¼ ì†ŒìŠ¤ë¡œ ì‚¬ìš© (ê¶Œì¥)
            search_count = db.count_unique_documents(allowed_ext=tuple(allowed_ext_list))
        else:
            # ë ˆê±°ì‹œ BM25 ì¸ë±ìŠ¤ ì°¸ì¡° (deprecated)
            search_count = db.count_search_index()

        # session_stateì— ì €ì¥í•˜ì—¬ ì•„ë˜ì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•¨
        st.session_state.search_count = search_count
        st.session_state.unique_count = unique_count

        # [PATCH 3] ì¹´ìš´íŠ¸ ë¶ˆì¼ì¹˜ ì²´í¬ ë° ê²½ê³  + stale ë©”íŠ¸ë¦­
        stale_entries = 0
        try:
            import requests
            # /metrics ì—”ë“œí¬ì¸íŠ¸ì—ì„œ stale_index_entries ê°€ì ¸ì˜¤ê¸°
            resp = requests.get("http://localhost:7860/metrics", timeout=2)
            if resp.status_code == 200:
                metrics_data = resp.json()
                stale_entries = metrics_data.get("stale_index_entries", 0)
        except:
            pass  # ë°±ì—”ë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ

        # ë¶ˆì¼ì¹˜ ë˜ëŠ” stale í•­ëª© ì¡´ì¬ ì‹œ ê²½ê³ 
        has_mismatch = (unique_count != search_count) or (stale_entries > 0)

        # [LOCK] ì¬ìƒ‰ì¸ ì§„í–‰ ì¤‘ ì²´í¬
        if is_reindexing():
            st.warning("âš™ï¸ ì¬ìƒ‰ì¸ ì§„í–‰ ì¤‘â€¦ ì ì‹œ í›„ ì¬ì‹œë„í•´ì£¼ì„¸ìš”")
            st.stop()

        if has_mismatch:
            warning_msg = f"âš ï¸ ì§€í‘œ ë¶ˆì¼ì¹˜: ë¼ì´ë¸ŒëŸ¬ë¦¬ {unique_count} / ê²€ìƒ‰ ì¸ë±ìŠ¤ {search_count}"
            if stale_entries > 0:
                warning_msg += f" (ì‚­ì œ í•„ìš”: {stale_entries}ê±´)"
            st.warning(warning_msg)

            # [PATCH 4] ì•ˆì „ ëª¨ë“œ ì¬ìƒ‰ì¸ ì˜µì…˜
            col1, col2 = st.columns([3, 1])
            with col1:
                drop_rebuild = st.checkbox("Drop & Rebuild (ì•ˆì „ ëª¨ë“œ)",
                    help="ì „ì²´ ì¸ë±ìŠ¤ë¥¼ ì‚­ì œ í›„ ì¬êµ¬ì¶• (ê°€ì¥ ê¹”ë”)",
                    key="drop_rebuild_checkbox")
            with col2:
                reindex_button = st.button("ğŸ”„ ì „ì²´ ì¬ìƒ‰ì¸", key="fix_mismatch")

            if reindex_button:
                if 'auto_indexer' in st.session_state:
                    try:
                        with reindexing_lock(timeout_sec=3.0):
                            with st.spinner("ì „ì²´ ì¬ì¸ë±ì‹± ì¤‘..." + (" (Drop & Rebuild)" if drop_rebuild else "")):
                                st.info("ğŸ”’ ë½ íšë“, ì•ˆì „ ì¬ìƒ‰ì¸ ì‹œì‘")

                                if drop_rebuild:
                                    # Drop & Rebuild ëª¨ë“œ: everything_index.db ì‚­ì œ í›„ ì¬ìƒì„±
                                    import os
                                    import sqlite3
                                    try:
                                        if os.path.exists("everything_index.db"):
                                            os.remove("everything_index.db")
                                        # ìƒˆ DB ìƒì„± (ìë™ ì¸ë±ì„œê°€ ë‹¤ì‹œ ë§Œë“¦)
                                        conn = sqlite3.connect("everything_index.db")
                                        conn.execute("""
                                            CREATE TABLE IF NOT EXISTS files (
                                                filename TEXT,
                                                path TEXT,
                                                PRIMARY KEY (filename)
                                            )
                                        """)
                                        conn.commit()
                                        conn.close()
                                        st.info("ğŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ")
                                    except Exception as e:
                                        st.error(f"Drop ì‹¤íŒ¨: {e}")

                                result = st.session_state.auto_indexer.force_reindex()
                                st.success(f"âœ… {result['total']}ê°œ íŒŒì¼ ì¬ì¸ë±ì‹± ì™„ë£Œ!")

                                # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë¡
                                from datetime import datetime
                                Path("var").mkdir(exist_ok=True)
                                Path("var/last_full_reindex.txt").write_text(datetime.now().isoformat())

                                if 'rag' in st.session_state:
                                    del st.session_state.rag
                                st.rerun()
                    except RuntimeError as e:
                        st.error(f"âŒ ë™ì‹œ ì‘ì—…ìœ¼ë¡œ ëŒ€ê¸° ì´ˆê³¼: {e}")

        # ìµœê·¼ ë¬¸ì„œ (expander)
        with st.expander("ìµœê·¼ 10ê±´", expanded=False):
            # ìµœê·¼ ë¬¸ì„œ ì¡°íšŒ
            import sqlite3
            conn = sqlite3.connect("metadata.db")
            cursor = conn.execute("""
                SELECT filename, title, page_count, created_at
                FROM documents
                ORDER BY created_at DESC
                LIMIT 10
            """)
            rows = cursor.fetchall()
            conn.close()

            if rows:
                for row in rows:
                    filename, title, page_count, created_at = row
                    title_short = title[:25] + "..." if len(title) > 25 else title
                    st.caption(f"ğŸ“„ {title_short}")
                    st.caption(f"   {page_count}p Â· {created_at[:10]}")
            else:
                st.caption("ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")

    except Exception as e:
        st.error(f"DB ì ‘ê·¼ ì‹¤íŒ¨: {e}")

    st.markdown("---")

    # ìˆ˜ë™ ì¬ì¸ë±ì‹± ë²„íŠ¼
    if 'auto_indexer' in st.session_state:
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ìƒˆë¡œê³ ì¹¨", key="refresh_index", width="stretch"):
                with st.spinner("ì¸ë±ì‹± ì¤‘..."):
                    result = st.session_state.auto_indexer.check_new_files()
                    if result['new']:
                        st.success(f"âœ… {len(result['new'])}ê°œ ìƒˆ íŒŒì¼ ì¸ë±ì‹± ì™„ë£Œ!")
                        # RAG ì‹œìŠ¤í…œ ë¦¬ë¡œë“œ
                        if 'rag' in st.session_state:
                            del st.session_state.rag
                        st.rerun()
                    else:
                        st.info("ë³€ê²½ì‚¬í•­ ì—†ìŒ")

        with col2:
            if st.button("â™»ï¸ ì „ì²´ì¬ì¸ë±ì‹±", key="force_reindex", width="stretch"):
                try:
                    with reindexing_lock(timeout_sec=3.0):
                        with st.spinner("ì „ì²´ ì¬ì¸ë±ì‹± ì¤‘..."):
                            result = st.session_state.auto_indexer.force_reindex()
                            st.success(f"âœ… {result['total']}ê°œ íŒŒì¼ ì¬ì¸ë±ì‹± ì™„ë£Œ!")
                            # RAG ì‹œìŠ¤í…œ ë¦¬ë¡œë“œ
                            if 'rag' in st.session_state:
                                del st.session_state.rag
                            st.rerun()
                except RuntimeError as e:
                    st.error(f"âŒ ë™ì‹œ ì‘ì—…ìœ¼ë¡œ ëŒ€ê¸° ì´ˆê³¼: {e}")

    st.markdown("---")
    st.markdown("### ğŸ“‚ ë¬¸ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬")

    # ë¹ ë¥¸ ë¬¸ì„œ ê°œìˆ˜ë§Œ ë¨¼ì € í‘œì‹œ
    if hasattr(rag_instance, 'metadata_cache'):
        doc_count = len(rag_instance.metadata_cache)
        st.caption(f"ğŸ“š {doc_count}ê°œ ë¬¸ì„œ")

    # ë¬¸ì„œ ë¡œë“œ (ìºì‹œë¨ - @st.cache_data ë•ë¶„ì— ë¹ ë¦„)
    with st.spinner("ë¬¸ì„œ ëª©ë¡ ë¡œë“œ ì¤‘..."):
        df = load_documents(rag_instance)
        st.session_state.documents_df = df

    # ë¬¸ì„œ ëª©ë¡ì´ ë¡œë“œëœ ê²½ìš° íƒ­ í‘œì‹œ
    if not df.empty:
        # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¹´ìš´íŠ¸ë¥¼ session_stateì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if 'search_count' in st.session_state:
            search_count = st.session_state.search_count
        else:
            # session_stateì— ì—†ìœ¼ë©´ DBì—ì„œ ì¡°íšŒ
            try:
                from modules.metadata_db import MetadataDB
                temp_db = MetadataDB()
                search_count = temp_db.count_search_index()
                st.session_state.search_count = search_count
                temp_db.close()
            except:
                search_count = df['filename'].nunique() if 'filename' in df.columns else len(df)

        col1, col2 = st.columns([3, 1])
        with col1:
            st.caption(f"ê²€ìƒ‰ ê°€ëŠ¥: {search_count}ê°œ ë¬¸ì„œ")

        # íƒ­ êµ¬ì„±
        tab1, tab2 = st.tabs(["ğŸ“ ë¬¸ì„œ ê²€ìƒ‰", "ğŸ“… ì—°ë„ë³„"])

        with tab1:
            # ê²€ìƒ‰ì°½
            search_query = st.text_input(
                "ë¬¸ì„œ ê²€ìƒ‰",
                placeholder="ì œëª©, íŒŒì¼ëª…, ê¸°ì•ˆì ì…ë ¥...",
                label_visibility="collapsed",
                key="doc_search_input"
            )

            # ê²€ìƒ‰ ì²˜ë¦¬
            if search_query:
                # ê²€ìƒ‰ ê²°ê³¼
                mask = (df['title'].str.contains(search_query, case=False, na=False) |
                       df['filename'].str.contains(search_query, case=False, na=False) |
                       df['drafter'].str.contains(search_query, case=False, na=False))
                filtered_df = df[mask]

                if len(filtered_df) > 0:
                    st.success(f"ê²€ìƒ‰ ê²°ê³¼: {len(filtered_df)}ê°œ")
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                    filtered_df = pd.DataFrame()
            else:
                # ê²€ìƒ‰ì–´ê°€ ì—†ìœ¼ë©´ ì „ì²´ ë¬¸ì„œ í‘œì‹œ
                filtered_df = df if not df.empty else pd.DataFrame()

            # ê²€ìƒ‰ íƒ­ì—ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
            display_document_list(filtered_df, df, "search")

        with tab2:
            # ì—°ë„ ì„ íƒ
            if not df.empty and 'year' in df.columns:
                # year_utilsë¥¼ ì‚¬ìš©í•˜ì—¬ year í•„ë“œ ì •ê·œí™”
                years_raw = df['year'].unique()
                years = normalize_year_list(years_raw)

                # ì—°ë„ë³„ ë¬¸ì„œ ê°œìˆ˜ í¬í•¨í•˜ì—¬ í‘œì‹œ
                year_counts = {}
                for year in years:
                    # compare_yearë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ì¹´ìš´íŠ¸
                    count = len(df[df['year'].apply(lambda x: compare_year(x, year))])
                    year_counts[year] = count

                year_options = [f"{year}ë…„ ({year_counts[year]}ê°œ)" for year in years]

                selected_year_str = st.selectbox(
                    "ì—°ë„ ì„ íƒ",
                    year_options,
                    label_visibility="collapsed",
                    key="year_select"
                )

                # ì„ íƒëœ ì—°ë„ ì¶”ì¶œ
                if selected_year_str:
                    selected_year = int(selected_year_str.split("ë…„")[0])
                    # compare_yearë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ í•„í„°ë§
                    filtered_df = df[df['year'].apply(lambda x: compare_year(x, selected_year))]
                else:
                    filtered_df = pd.DataFrame()

                # ì„ íƒëœ ì—°ë„ ì •ë³´
                if selected_year == 0:
                    st.info(f"ì—°ë„ ì •ë³´ ì—†ëŠ” ë¬¸ì„œ {len(filtered_df)}ê°œ")
                else:
                    st.info(f"{selected_year}ë…„ ë¬¸ì„œ {len(filtered_df)}ê°œ")

                # ì—°ë„ë³„ íƒ­ì—ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
                display_document_list(filtered_df, df, "year")
            else:
                st.info("ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")

    # CSS ìŠ¤íƒ€ì¼ì€ í˜ì´ì§€ ì‹œì‘ ì‹œ ë¡œë“œë¨ (load_all_css)

    # ì‹œìŠ¤í…œ ì •ë³´
    st.markdown("---")
    st.markdown("### ì‹œìŠ¤í…œ ì •ë³´")
    if not df.empty and 'year' in df.columns:
        # year_utilsë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ min/max ê³„ì‚°
        years = normalize_year_list(df['year'].unique())
        if years:
            year_range = f"{min(years)}ë…„ ~ {max(years)}ë…„"
        else:
            year_range = "ë°ì´í„° ì—†ìŒ"
    else:
        year_range = "ë°ì´í„° ì—†ìŒ"

    st.info(f"""
    **ëª¨ë¸**: {RAG_MODEL}
    **ë¬¸ì„œ**: {len(df)}ê°œ
    **ê¸°ê°„**: {year_range}
    """)
