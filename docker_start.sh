#!/bin/bash
#
# Docker ì»¨í…Œì´ë„ˆ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
# ëª¨ë“  ì„œë¹„ìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œì‘
#

echo "ğŸ³ AI-CHAT RAG System Starting in Docker..."
echo "==========================================="

# í™˜ê²½ í™•ì¸
echo "ğŸ” í™˜ê²½ í™•ì¸ ì¤‘..."
echo "  - Python: $(python3 --version)"
echo "  - GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null || echo 'CPU mode')"
echo "  - Memory: $(free -h | grep Mem | awk '{print $2}')"

# ë””ë ‰í† ë¦¬ í™•ì¸
echo "ğŸ“ ë””ë ‰í† ë¦¬ í™•ì¸ ì¤‘..."
mkdir -p logs cache indexes models

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸
if [ ! -f "models/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf" ]; then
    echo "ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”..."
    echo "  ëª¨ë¸ì„ ë¨¼ì € ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:"
    echo "  python3 download_models.py"
fi

# ìë™ ì¸ë±ì„œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
echo "ğŸ“š ìë™ ì¸ë±ì„œ ì‹œì‘..."
nohup python3 auto_indexer.py > logs/auto_indexer.log 2>&1 &
INDEXER_PID=$!

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ì„ íƒì‚¬í•­)
if [ "$ENABLE_MONITORING" = "true" ]; then
    echo "ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘..."
    nohup streamlit run performance_dashboard.py \
        --server.port 8502 \
        --server.address 0.0.0.0 \
        > logs/monitoring.log 2>&1 &
    MONITOR_PID=$!
fi

# ë©”ì¸ ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
echo "ğŸš€ ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹œì‘..."
echo "==========================================="
echo "âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!"
echo ""
echo "ğŸ“Œ ì ‘ì† ì£¼ì†Œ:"
echo "   - ë©”ì¸: http://localhost:8501"
if [ "$ENABLE_MONITORING" = "true" ]; then
    echo "   - ëª¨ë‹ˆí„°ë§: http://localhost:8502"
fi
echo ""
echo "ğŸ“Œ ë¡œê·¸ í™•ì¸:"
echo "   docker logs -f ai-chat-rag"
echo ""

# ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (í¬ê·¸ë¼ìš´ë“œ)
exec streamlit run web_interface.py \
    --server.port 8501 \
    --server.address 0.0.0.0 \
    --server.headless true