#!/usr/bin/env python3
"""
í•˜ì´ë¸Œë¦¬ë“œ ì±„íŒ… RAG - QuickFixRAG + Qwen LLM
ê²€ìƒ‰ì€ ì´ˆê³ ì†, ëŒ€í™”ëŠ” ë¡œì»¬ LLM ì‚¬ìš©
"""

import time
from typing import List, Dict, Any, Optional
from quick_fix_rag import QuickFixRAG

try:
    from rag_system.qwen_llm import QwenLLM
    from rag_system.llm_singleton import LLMSingleton
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("âš ï¸ LLM ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

class HybridChatRAG:
    """í•˜ì´ë¸Œë¦¬ë“œ ì±„íŒ… RAG - ê²€ìƒ‰ + LLM ëŒ€í™”"""

    def __init__(self):
        # ì´ˆê³ ì† ê²€ìƒ‰ ì—”ì§„
        self.search_rag = QuickFixRAG()

        # LLM ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
        self.llm = None
        self.llm_loaded = False

        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
        self.conversation_history = []
        self.selected_documents = []

    def _ensure_llm_loaded(self):
        """LLMì´ í•„ìš”í•  ë•Œë§Œ ë¡œë“œ"""
        if not LLM_AVAILABLE:
            return False

        if not self.llm_loaded:
            try:
                print("ğŸ¤– Qwen LLM ë¡œë”© ì¤‘...")
                start_time = time.time()

                # ì§ì ‘ ëª¨ë¸ ê²½ë¡œ ì§€ì •í•˜ì—¬ ë¡œë“œ
                from rag_system.qwen_llm import QwenLLM
                from config import QWEN_MODEL_PATH

                self.llm = QwenLLM(model_path=QWEN_MODEL_PATH)

                load_time = time.time() - start_time
                print(f"âœ… LLM ë¡œë“œ ì™„ë£Œ ({load_time:.1f}ì´ˆ)")
                self.llm_loaded = True
                return True

            except Exception as e:
                print(f"âŒ LLM ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False
        return True

    def search_only(self, query: str) -> str:
        """ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (ê¸°ì¡´ QuickFixRAGì™€ ë™ì¼)"""
        return self.search_rag.answer(query)

    def chat_with_documents(self, query: str, use_context: bool = True) -> str:
        """ë¬¸ì„œ ê¸°ë°˜ LLM ëŒ€í™”"""
        if not self._ensure_llm_loaded():
            return "âŒ LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê¸°ëŠ¥ë§Œ ì´ìš©í•´ì£¼ì„¸ìš”."

        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self._get_relevant_documents(query)

        # 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_chat_prompt(query, search_results, use_context)

        # 3. LLM ì‘ë‹µ ìƒì„±
        try:
            start_time = time.time()
            # QwenLLMì€ generate_response ë©”ì„œë“œ ì‚¬ìš©
            response = self.llm.generate_response(prompt, [])
            if hasattr(response, 'content'):
                response_text = response.content
            else:
                response_text = str(response)
            response_time = time.time() - start_time

            # 4. ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.conversation_history.append({
                'query': query,
                'response': response_text,
                'documents': search_results,
                'timestamp': time.time()
            })

            return f"{response_text}\n\n*ì‘ë‹µ ì‹œê°„: {response_time:.1f}ì´ˆ*"

        except Exception as e:
            return f"âŒ LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}"

    def _get_relevant_documents(self, query: str) -> List[Dict]:
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        # ê¸°ì¡´ QuickFixRAGì˜ search_module í™œìš©
        try:
            # ê¸°ì•ˆì ê²€ìƒ‰
            import re
            drafter_match = re.search(r'ê¸°ì•ˆì\s*([ê°€-í£]+)', query)
            if drafter_match:
                drafter_name = drafter_match.group(1)
                return self.search_rag.rag.search_module.search_by_drafter(drafter_name, top_k=5)

            # ì¼ë°˜ ê²€ìƒ‰
            return self.search_rag.rag.search_module.search_by_content(query, top_k=5)

        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _build_chat_prompt(self, query: str, documents: List[Dict], use_context: bool) -> str:
        """ëŒ€í™”ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        prompt = """ë‹¹ì‹ ì€ ë°©ì†¡êµ­ ë¬¸ì„œ ê´€ë¦¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ê²€ìƒ‰ëœ ë¬¸ì„œ:
"""

        # ë¬¸ì„œ ì •ë³´ ì¶”ê°€
        for i, doc in enumerate(documents[:3], 1):  # ìµœëŒ€ 3ê°œë§Œ
            prompt += f"\n{i}. {doc.get('filename', 'ì œëª©ì—†ìŒ')}"
            if doc.get('date'):
                prompt += f" ({doc['date']})"
            if doc.get('department'):
                prompt += f" - ê¸°ì•ˆì: {doc['department']}"

        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if use_context and self.conversation_history:
            prompt += "\n\nì´ì „ ëŒ€í™”:"
            for hist in self.conversation_history[-2:]:  # ìµœê·¼ 2ê°œë§Œ
                prompt += f"\nQ: {hist['query']}"
                prompt += f"\nA: {hist['response'][:100]}..."  # 100ìë§Œ

        prompt += f"\n\nì‚¬ìš©ì ì§ˆë¬¸: {query}"
        prompt += "\n\në‹µë³€ (í•œêµ­ì–´ë¡œ, ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ):"

        return prompt

    def get_conversation_history(self) -> List[Dict]:
        """ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.conversation_history

    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []
        self.selected_documents = []

def main():
    """í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì±„íŒ… RAG í…ŒìŠ¤íŠ¸")

    rag = HybridChatRAG()

    # 1. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    search_result = rag.search_only("ê¸°ì•ˆì ë‚¨ì¤€ìˆ˜")
    print(search_result[:200] + "...")

    # 2. ì±„íŒ… í…ŒìŠ¤íŠ¸
    if LLM_AVAILABLE:
        print("\n2ï¸âƒ£ ì±„íŒ… í…ŒìŠ¤íŠ¸:")
        chat_result = rag.chat_with_documents("ë‚¨ì¤€ìˆ˜ê°€ ì‘ì„±í•œ ë¬¸ì„œë“¤ì˜ íŠ¹ì§•ì„ ë¶„ì„í•´ì¤˜")
        print(chat_result)
    else:
        print("\nâŒ LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì±„íŒ… í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

if __name__ == "__main__":
    main()