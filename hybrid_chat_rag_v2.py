#!/usr/bin/env python3
"""
í†µí•© RAG ì‹œìŠ¤í…œ - ìë™ìœ¼ë¡œ ìµœì  ëª¨ë“œ ì„ íƒ
ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ ë¹ ë¥¸ ê²€ìƒ‰
ë³µì¡í•œ ì§ˆë¬¸ â†’ AI ë¶„ì„
"""

import time
import re
from typing import List, Dict, Any, Optional
from quick_fix_rag import QuickFixRAG

try:
    from rag_system.qwen_llm import QwenLLM
    from config import QWEN_MODEL_PATH
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("âš ï¸ LLM ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

class UnifiedRAG:
    """í†µí•© RAG - ìë™ìœ¼ë¡œ ê²€ìƒ‰/AI ì„ íƒ"""

    def __init__(self):
        # ê²€ìƒ‰ ì—”ì§„
        self.search_rag = QuickFixRAG()

        # LLM (ì§€ì—° ë¡œë”©)
        self.llm = None
        self.llm_loaded = False

        # ëŒ€í™” ê¸°ë¡
        self.conversation_history = []

    def answer(self, query: str) -> str:
        """
        í†µí•© ë‹µë³€ - ìë™ìœ¼ë¡œ ëª¨ë“œ ì„ íƒ
        ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ ë¹ ë¥¸ ê²€ìƒ‰
        ë³µì¡í•œ ì§ˆë¬¸ â†’ AI ë¶„ì„
        """
        # ì§ˆë¬¸ ë¶„ì„
        needs_ai = self._needs_ai_analysis(query)

        # ë””ë²„ê¹… ì •ë³´
        print(f"\nğŸ” ì§ˆë¬¸: {query}")
        print(f"ğŸ“Š AI ë¶„ì„ í•„ìš”: {needs_ai}")
        print(f"ğŸ¤– LLM ì‚¬ìš© ê°€ëŠ¥: {LLM_AVAILABLE}")

        if needs_ai and LLM_AVAILABLE:
            # AI ë¶„ì„ í•„ìš”
            print("âœ… AI ë¶„ì„ ëª¨ë“œ ì„ íƒ")
            return self._ai_answer(query)
        else:
            # ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ ì¶©ë¶„
            print("âš¡ ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ")
            return self._quick_answer(query)

    def _needs_ai_analysis(self, query: str) -> bool:
        """AI ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""

        # AIê°€ í•„ìš”í•œ í‚¤ì›Œë“œ
        ai_keywords = [
            # ë¶„ì„/ì„¤ëª…
            'ìš”ì•½', 'ë¶„ì„', 'ë¹„êµ', 'ì„¤ëª…', 'ì™œ', 'ì–´ë–»ê²Œ',
            'íŠ¹ì§•', 'ì°¨ì´', 'ê³µí†µì ', 'íŒ¨í„´', 'ì¶”ì²œ',
            'ì´ìœ ', 'ì›ì¸', 'ê²°ê³¼', 'ì˜í–¥', 'ê´€ê³„',
            # ë‚´ìš© ìš”ì²­
            'ë‚´ìš©', 'ì•Œë ¤', 'ë§í•´', 'ì •ë¦¬', 'ìƒì„¸', 'ìì„¸',
            'êµ¬ì²´ì ', 'ì „ì²´', 'ëª¨ë“ ', 'ë‹¤', 'ì „ë¶€'
        ]

        # ê°„ë‹¨í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        simple_keywords = [
            'ì°¾ì•„', 'ë³´ì—¬', 'ê²€ìƒ‰', 'ìˆì–´', 'ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸',
            'ëª‡ ê°œ', 'ê°œìˆ˜', 'ì–¸ì œ', 'ëˆ„ê°€', 'ì–´ë””', 'ì–´ëŠ'
        ]

        query_lower = query.lower()

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¹ ë¥¸ ê²€ìƒ‰ (ìš°ì„ )
        for keyword in simple_keywords:
            if keyword in query_lower:
                return False

        # AI í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ AI ë¶„ì„
        for keyword in ai_keywords:
            if keyword in query_lower:
                return True

        # ì• ë§¤í•˜ë©´ ì§ˆë¬¸ ê¸¸ì´ë¡œ íŒë‹¨ (25ì ì´ìƒ = AI)
        return len(query) > 25

    def _quick_answer(self, query: str) -> str:
        """ë¹ ë¥¸ ê²€ìƒ‰ ë‹µë³€"""
        start_time = time.time()
        result = self.search_rag.answer(query)
        elapsed = time.time() - start_time

        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.conversation_history.append({
            'query': query,
            'response': result,
            'mode': 'quick',
            'timestamp': time.time()
        })

        return f"{result}\n\n*ğŸ” ë¹ ë¥¸ ê²€ìƒ‰ ({elapsed:.2f}ì´ˆ)*"

    def _ai_answer(self, query: str) -> str:
        """AI ë¶„ì„ ë‹µë³€"""
        if not self._ensure_llm_loaded():
            # LLM ëª» ì“°ë©´ ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            return self._quick_answer(query)

        start_time = time.time()

        # 1. ë¬¸ì„œ ê²€ìƒ‰
        documents = self._search_documents(query)

        if not documents:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(query, documents)

        # 3. LLM ì‘ë‹µ
        try:
            response = self.llm.generate_response(prompt, [])

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if hasattr(response, 'answer'):
                answer = response.answer
            elif hasattr(response, 'content'):
                answer = response.content
            else:
                answer = str(response)

            elapsed = time.time() - start_time

            # ëŒ€í™” ê¸°ë¡
            self.conversation_history.append({
                'query': query,
                'response': answer,
                'mode': 'ai',
                'timestamp': time.time()
            })

            return f"{answer}\n\n*ğŸ¤– AI ë¶„ì„ ({elapsed:.1f}ì´ˆ)*"

        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            return self._quick_answer(query)

    def _ensure_llm_loaded(self) -> bool:
        """LLM ë¡œë”©"""
        if not LLM_AVAILABLE:
            return False

        if not self.llm_loaded:
            try:
                print("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.llm = QwenLLM(model_path=QWEN_MODEL_PATH)
                self.llm_loaded = True
                print("âœ… AI ì¤€ë¹„ ì™„ë£Œ")
                return True
            except Exception as e:
                print(f"âŒ AI ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False
        return True

    def _search_documents(self, query: str) -> List[Dict]:
        """ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # ê¸°ì•ˆì ê²€ìƒ‰
            drafter_match = re.search(r'ê¸°ì•ˆì\s*([ê°€-í£]+)', query)
            if drafter_match:
                drafter = drafter_match.group(1)
                return self.search_rag.rag.search_module.search_by_drafter(drafter, top_k=5)

            # ì¼ë°˜ ê²€ìƒ‰
            return self.search_rag.rag.search_module.search_by_content(query, top_k=5)

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _build_prompt(self, query: str, documents: List[Dict]) -> str:
        """AIìš© í”„ë¡¬í”„íŠ¸ ìƒì„± (Chain-of-Thought ë°©ì‹ìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ)"""
        prompt = """ë‹¹ì‹ ì€ ë°©ì†¡êµ­ ê¸°ìˆ ê´€ë¦¬íŒ€ì˜ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ AIì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê¼¼ê¼¼íˆ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš” ì›ì¹™:
- ë¬¸ì„œì˜ ì‹¤ì œ ë‚´ìš©ë§Œ ì‚¬ìš© (ì¶”ì¸¡/ìƒìƒ ì ˆëŒ€ ê¸ˆì§€)
- ëª¨ë“  ì •ë³´ëŠ” ë°˜ë“œì‹œ [íŒŒì¼ëª….pdf] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ ëª…ì‹œ
- í‘œ, ê¸ˆì•¡, ë‚ ì§œ, ì¥ë¹„ëª… ë“± ì„¸ë¶€ì‚¬í•­ì„ ì •í™•íˆ ì „ë‹¬
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•ŠìŒ"ìœ¼ë¡œ í‘œì‹œ

ê²€ìƒ‰ëœ ë¬¸ì„œ:
"""

        # ë¬¸ì„œ ë‚´ìš© ì¶”ê°€ (ì „ì²´ ë‚´ìš© ì‚¬ìš© - í’ˆì§ˆ ìš°ì„ )
        for i, doc in enumerate(documents[:1], 1):
            filename = doc.get('filename', 'ì•Œìˆ˜ì—†ìŒ')
            prompt += f"\n[ë¬¸ì„œ {i}: {filename}]\n"

            if doc.get('date'):
                prompt += f"ë‚ ì§œ: {doc['date']}\n"
            if doc.get('drafter'):
                prompt += f"ê¸°ì•ˆì: {doc['drafter']}\n"

            # ì ì‘í˜• ì»¨í…ìŠ¤íŠ¸: ì§ˆë¬¸ê³¼ ë¬¸ì„œ íŠ¹ì„±ì— ë”°ë¼ ê¸¸ì´ ìë™ ì¡°ì ˆ
            if doc.get('content'):
                full_content = doc['content']

                # ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„
                detail_keywords = ['ìƒì„¸', 'ìì„¸íˆ', 'ì „ì²´', 'ëª¨ë‘', 'ì „ë¶€', 'ë‚´ìš©', 'í‘œ', 'ëª©ë¡']
                simple_keywords = ['ì–¸ì œ', 'ëˆ„ê°€', 'ì–´ë””', 'ê¸ˆì•¡', 'ê°€ê²©', 'ë‚ ì§œ']

                is_detail_query = any(kw in query for kw in detail_keywords)
                is_simple_query = any(kw in query for kw in simple_keywords) and not is_detail_query

                # ì ì‘í˜• ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê²°ì •
                if is_simple_query and len(full_content) > 5000:
                    # ê°„ë‹¨í•œ ì§ˆë¬¸: í•µì‹¬ë§Œ ì¶”ì¶œ (5000ì)
                    content = full_content[:5000]
                    prompt += f"\nì‹¤ì œ ë‚´ìš© (ìš”ì•½):\n{content}\n"
                elif len(full_content) < 5000:
                    # ì§§ì€ ë¬¸ì„œ: ì „ì²´ ì‚¬ìš©
                    prompt += f"\nì‹¤ì œ ë‚´ìš©:\n{full_content}\n"
                else:
                    # ìƒì„¸ ì§ˆë¬¸ ë˜ëŠ” ì¤‘ê°„ ê¸¸ì´: ìµœëŒ€ 12000ì
                    content = full_content[:12000]
                    prompt += f"\nì‹¤ì œ ë‚´ìš©:\n{content}\n"

            prompt += "\n---\n"

        prompt += f"\nì‚¬ìš©ì ì§ˆë¬¸: {query}\n\n"
        prompt += """ë‹µë³€ ì‘ì„± ë‹¨ê³„ (Chain-of-Thought):
1. **ë¬¸ì„œ ë¶„ì„**: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ì •ë³´ íŒŒì•…
2. **ì •ë³´ ì¶”ì¶œ**: ë‚ ì§œ, ê¸ˆì•¡, ì¥ë¹„ëª…, ì—…ì²´ëª… ë“± êµ¬ì²´ì  ë°ì´í„° ìˆ˜ì§‘
3. **êµ¬ì¡°í™”**: í‘œê°€ ìˆë‹¤ë©´ í‘œ í˜•ì‹ìœ¼ë¡œ, ëª©ë¡ì´ë©´ ëª©ë¡ìœ¼ë¡œ ì •ë¦¬
4. **ê²€ì¦**: ëª¨ë“  ì •ë³´ê°€ ë¬¸ì„œì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
5. **ì‘ì„±**: ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ë©° ëª…í™•í•˜ê³  ì™„ì „í•œ ë‹µë³€ ì‘ì„±

ë‹µë³€ í˜•ì‹:
[íŒŒì¼ëª….pdf]ì— ë”°ë¥´ë©´...
- í•µì‹¬ ì •ë³´ 1
- í•µì‹¬ ì •ë³´ 2
- ì„¸ë¶€ ì‚¬í•­ (í‘œ/ê¸ˆì•¡/ë‚ ì§œ í¬í•¨)

ë‹µë³€ ì˜ˆì‹œ:
[2025-07-17_ë¯¸ëŸ¬í´ë©_ì¹´ë©”ë¼_ì‚¼ê°ëŒ€_ê¸°ìˆ ê²€í† ì„œ.pdf]ì— ë”°ë¥´ë©´...
- ì¥ë¹„: Leofoto LVC-253C (820,000ì›)
- ëª©ì : Miller DS20 ì‚¼ê°ëŒ€ íŒŒì†ìœ¼ë¡œ ëŒ€ì²´í’ˆ ê²€í† 

ë‹µë³€:"""

        return prompt

    def get_conversation_history(self) -> List[Dict]:
        """ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.conversation_history

    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []

def main():
    """í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ í†µí•© RAG í…ŒìŠ¤íŠ¸\n")

    rag = UnifiedRAG()

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "DVR ê´€ë ¨ ë¬¸ì„œ ì°¾ì•„ì¤˜",  # â†’ ë¹ ë¥¸ ê²€ìƒ‰
        "ì¤‘ê³„ì°¨ ë³´ìˆ˜ê±´ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜",  # â†’ AI ë¶„ì„
        "ê¸°ì•ˆì ë‚¨ì¤€ìˆ˜",  # â†’ ë¹ ë¥¸ ê²€ìƒ‰
        "2024ë…„ê³¼ 2025ë…„ êµ¬ë§¤ ë¬¸ì„œë¥¼ ë¹„êµ ë¶„ì„í•´ì¤˜"  # â†’ AI ë¶„ì„
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*50}")
        print(f"ì§ˆë¬¸ {i}: {query}")
        print(f"{'='*50}")

        answer = rag.answer(query)
        print(answer)
        print()

if __name__ == "__main__":
    main()
