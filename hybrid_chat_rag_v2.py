#!/usr/bin/env python3
"""
í†µí•© RAG ì‹œìŠ¤í…œ - ìë™ìœ¼ë¡œ ìµœì  ëª¨ë“œ ì„ íƒ
ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ ë¹ ë¥¸ ê²€ìƒ‰
ë³µì¡í•œ ì§ˆë¬¸ â†’ AI ë¶„ì„
"""

import time
import re
from typing import List, Dict, Any, Optional
from quick_fix_rag import QuickFixRAG

try:
    from rag_system.qwen_llm import QwenLLM
    from config import QWEN_MODEL_PATH
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("âš ï¸ LLM ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

class UnifiedRAG:
    """í†µí•© RAG - ìë™ìœ¼ë¡œ ê²€ìƒ‰/AI ì„ íƒ"""

    def __init__(self):
        # ê²€ìƒ‰ ì—”ì§„
        self.search_rag = QuickFixRAG()

        # LLM (ì§€ì—° ë¡œë”©)
        self.llm = None
        self.llm_loaded = False

        # ëŒ€í™” ê¸°ë¡
        self.conversation_history = []

    def answer(self, query: str) -> str:
        """
        í†µí•© ë‹µë³€ - ìë™ìœ¼ë¡œ ëª¨ë“œ ì„ íƒ
        ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ ë¹ ë¥¸ ê²€ìƒ‰
        ë³µì¡í•œ ì§ˆë¬¸ â†’ AI ë¶„ì„
        """
        # ì§ˆë¬¸ ë¶„ì„
        needs_ai = self._needs_ai_analysis(query)

        # ë””ë²„ê¹… ì •ë³´
        print(f"\nğŸ” ì§ˆë¬¸: {query}")
        print(f"ğŸ“Š AI ë¶„ì„ í•„ìš”: {needs_ai}")
        print(f"ğŸ¤– LLM ì‚¬ìš© ê°€ëŠ¥: {LLM_AVAILABLE}")

        if needs_ai and LLM_AVAILABLE:
            # AI ë¶„ì„ í•„ìš”
            print("âœ… AI ë¶„ì„ ëª¨ë“œ ì„ íƒ")
            return self._ai_answer(query)
        else:
            # ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ ì¶©ë¶„
            print("âš¡ ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ ì„ íƒ")
            return self._quick_answer(query)

    def _needs_ai_analysis(self, query: str) -> bool:
        """AI ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""

        # AIê°€ í•„ìš”í•œ í‚¤ì›Œë“œ
        ai_keywords = [
            # ë¶„ì„/ì„¤ëª…
            'ìš”ì•½', 'ë¶„ì„', 'ë¹„êµ', 'ì„¤ëª…', 'ì™œ', 'ì–´ë–»ê²Œ',
            'íŠ¹ì§•', 'ì°¨ì´', 'ê³µí†µì ', 'íŒ¨í„´', 'ì¶”ì²œ',
            'ì´ìœ ', 'ì›ì¸', 'ê²°ê³¼', 'ì˜í–¥', 'ê´€ê³„',
            # ë‚´ìš© ìš”ì²­
            'ë‚´ìš©', 'ì•Œë ¤', 'ë§í•´', 'ì •ë¦¬', 'ìƒì„¸', 'ìì„¸',
            'êµ¬ì²´ì ', 'ì „ì²´', 'ëª¨ë“ ', 'ë‹¤', 'ì „ë¶€'
        ]

        # ê°„ë‹¨í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        simple_keywords = [
            'ì°¾ì•„', 'ë³´ì—¬', 'ê²€ìƒ‰', 'ìˆì–´', 'ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸',
            'ëª‡ ê°œ', 'ê°œìˆ˜', 'ì–¸ì œ', 'ëˆ„ê°€', 'ì–´ë””', 'ì–´ëŠ'
        ]

        query_lower = query.lower()

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¹ ë¥¸ ê²€ìƒ‰ (ìš°ì„ )
        for keyword in simple_keywords:
            if keyword in query_lower:
                return False

        # AI í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ AI ë¶„ì„
        for keyword in ai_keywords:
            if keyword in query_lower:
                return True

        # ì• ë§¤í•˜ë©´ ì§ˆë¬¸ ê¸¸ì´ë¡œ íŒë‹¨ (25ì ì´ìƒ = AI)
        return len(query) > 25

    def _quick_answer(self, query: str) -> str:
        """ë¹ ë¥¸ ê²€ìƒ‰ ë‹µë³€"""
        start_time = time.time()
        result = self.search_rag.answer(query)
        elapsed = time.time() - start_time

        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.conversation_history.append({
            'query': query,
            'response': result,
            'mode': 'quick',
            'timestamp': time.time()
        })

        return f"{result}\n\n*ğŸ” ë¹ ë¥¸ ê²€ìƒ‰ ({elapsed:.2f}ì´ˆ)*"

    def _ai_answer(self, query: str) -> str:
        """AI ë¶„ì„ ë‹µë³€"""
        if not self._ensure_llm_loaded():
            # LLM ëª» ì“°ë©´ ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            return self._quick_answer(query)

        start_time = time.time()

        # 1. ë¬¸ì„œ ê²€ìƒ‰
        documents = self._search_documents(query)

        if not documents:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(query, documents)

        # 3. LLM ì‘ë‹µ
        try:
            response = self.llm.generate_response(prompt, [])

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if hasattr(response, 'answer'):
                answer = response.answer
            elif hasattr(response, 'content'):
                answer = response.content
            else:
                answer = str(response)

            elapsed = time.time() - start_time

            # ëŒ€í™” ê¸°ë¡
            self.conversation_history.append({
                'query': query,
                'response': answer,
                'mode': 'ai',
                'timestamp': time.time()
            })

            return f"{answer}\n\n*ğŸ¤– AI ë¶„ì„ ({elapsed:.1f}ì´ˆ)*"

        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ë¹ ë¥¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            return self._quick_answer(query)

    def _ensure_llm_loaded(self) -> bool:
        """LLM ë¡œë”©"""
        if not LLM_AVAILABLE:
            return False

        if not self.llm_loaded:
            try:
                print("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
                self.llm = QwenLLM(model_path=QWEN_MODEL_PATH)
                self.llm_loaded = True
                print("âœ… AI ì¤€ë¹„ ì™„ë£Œ")
                return True
            except Exception as e:
                print(f"âŒ AI ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False
        return True

    def _search_documents(self, query: str) -> List[Dict]:
        """ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # ê¸°ì•ˆì ê²€ìƒ‰
            drafter_match = re.search(r'ê¸°ì•ˆì\s*([ê°€-í£]+)', query)
            if drafter_match:
                drafter = drafter_match.group(1)
                return self.search_rag.rag.search_module.search_by_drafter(drafter, top_k=5)

            # ì¼ë°˜ ê²€ìƒ‰
            return self.search_rag.rag.search_module.search_by_content(query, top_k=5)

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _build_prompt(self, query: str, documents: List[Dict]) -> str:
        """AIìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = """ë‹¹ì‹ ì€ ë°©ì†¡êµ­ ê¸°ìˆ ê´€ë¦¬íŒ€ì˜ ë¬¸ì„œ ë¶„ì„ AIì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ë¬´ì— ë„ì›€ì´ ë˜ëŠ” êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ê²€ìƒ‰ëœ ë¬¸ì„œ:
"""

        # ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
        for i, doc in enumerate(documents[:3], 1):
            prompt += f"\n[ë¬¸ì„œ {i}]\n"
            prompt += f"íŒŒì¼: {doc.get('filename', 'ì•Œìˆ˜ì—†ìŒ')}\n"

            if doc.get('date'):
                prompt += f"ë‚ ì§œ: {doc['date']}\n"
            if doc.get('drafter'):
                prompt += f"ê¸°ì•ˆì: {doc['drafter']}\n"

            # ë¬¸ì„œ ë‚´ìš©
            if doc.get('content'):
                content = doc['content'][:2000]  # ìµœëŒ€ 2000ì
                prompt += f"ë‚´ìš©:\n{content}\n"

            prompt += "\n---\n"

        # ì´ì „ ëŒ€í™”
        if self.conversation_history:
            prompt += "\nì´ì „ ëŒ€í™”:\n"
            for hist in self.conversation_history[-2:]:
                prompt += f"Q: {hist['query']}\n"
                prompt += f"A: {hist['response'][:100]}...\n"

        prompt += f"\nì§ˆë¬¸: {query}\n\n"
        prompt += """ë‹µë³€ ìš”êµ¬ì‚¬í•­:
- ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì  ë‹µë³€
- ê¸ˆì•¡, ì—…ì²´ëª…, ì¥ë¹„ëª… ë“± ì‹¤ë¬´ ì •ë³´ í¬í•¨
- í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬ (í•„ìš”ì‹œ)
- ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ

ë‹µë³€:"""

        return prompt

    def get_conversation_history(self) -> List[Dict]:
        """ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.conversation_history

    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []

def main():
    """í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ í†µí•© RAG í…ŒìŠ¤íŠ¸\n")

    rag = UnifiedRAG()

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "DVR ê´€ë ¨ ë¬¸ì„œ ì°¾ì•„ì¤˜",  # â†’ ë¹ ë¥¸ ê²€ìƒ‰
        "ì¤‘ê³„ì°¨ ë³´ìˆ˜ê±´ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜",  # â†’ AI ë¶„ì„
        "ê¸°ì•ˆì ë‚¨ì¤€ìˆ˜",  # â†’ ë¹ ë¥¸ ê²€ìƒ‰
        "2024ë…„ê³¼ 2025ë…„ êµ¬ë§¤ ë¬¸ì„œë¥¼ ë¹„êµ ë¶„ì„í•´ì¤˜"  # â†’ AI ë¶„ì„
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*50}")
        print(f"ì§ˆë¬¸ {i}: {query}")
        print(f"{'='*50}")

        answer = rag.answer(query)
        print(answer)
        print()

if __name__ == "__main__":
    main()
