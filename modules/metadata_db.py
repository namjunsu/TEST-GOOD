#!/usr/bin/env python3
"""
Phase 1.2: ë©”íƒ€ë°ì´í„° DB êµ¬ì¶•
SQLiteë¥¼ ì‚¬ìš©í•œ PDF ë©”íƒ€ë°ì´í„° ê´€ë¦¬
"""

from app.core.logging import get_logger
import sqlite3
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import re
from functools import lru_cache

logger = get_logger(__name__)


class MetadataDB:
    """PDF ë©”íƒ€ë°ì´í„° SQLite DB ê´€ë¦¬"""

    def __init__(self, db_path: str = "metadata.db"):
        self.db_path = db_path
        self.conn = None
        self.init_database()
        logger.info(f"MetadataDB ì´ˆê¸°í™”: {db_path}")

    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
        self.conn = sqlite3.connect(self.db_path, timeout=5.0)
        self.conn.row_factory = sqlite3.Row  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜

        # WAL ëª¨ë“œ ì„¤ì • (ë™ì‹œ ì½ê¸° ì§€ì›)
        self.conn.execute("PRAGMA journal_mode=WAL;")
        self.conn.execute("PRAGMA busy_timeout=5000;")
        self.conn.execute("PRAGMA synchronous=NORMAL;")
        logger.info(f"DB WAL mode enabled: {self.db_path}")

        # ë©”íƒ€ë°ì´í„° í…Œì´ë¸” ìƒì„±
        self.conn.execute(
            """
            CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                path TEXT UNIQUE NOT NULL,
                filename TEXT NOT NULL,
                title TEXT,
                date TEXT,
                year TEXT,
                month TEXT,
                category TEXT,
                drafter TEXT,
                amount INTEGER,
                file_size INTEGER,
                page_count INTEGER,
                text_preview TEXT,
                keywords TEXT,  -- JSON array
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        # ì¸ë±ìŠ¤ ìƒì„± (ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ)
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_year ON documents(year)")
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_category ON documents(category)"
        )
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_date ON documents(date)")
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_filename ON documents(filename)"
        )

        # ì „ë¬¸ ê²€ìƒ‰ì„ ìœ„í•œ FTS í…Œì´ë¸” (Full-Text Search)
        self.conn.execute(
            """
            CREATE VIRTUAL TABLE IF NOT EXISTS documents_fts
            USING fts5(
                path UNINDEXED,
                title,
                text_preview,
                keywords,
                content=documents,
                content_rowid=id
            )
        """
        )

        # FTS íŠ¸ë¦¬ê±° ì„¤ì • (ìë™ ë™ê¸°í™”)
        self.conn.execute(
            """
            CREATE TRIGGER IF NOT EXISTS documents_ai
            AFTER INSERT ON documents
            BEGIN
                INSERT INTO documents_fts(rowid, path, title, text_preview, keywords)
                VALUES (new.id, new.path, new.title, new.text_preview, new.keywords);
            END
        """
        )

        self.conn.execute(
            """
            CREATE TRIGGER IF NOT EXISTS documents_au
            AFTER UPDATE ON documents
            BEGIN
                UPDATE documents_fts
                SET title = new.title,
                    text_preview = new.text_preview,
                    keywords = new.keywords
                WHERE rowid = new.id;
            END
        """
        )

        self.conn.execute(
            """
            CREATE TRIGGER IF NOT EXISTS documents_ad
            AFTER DELETE ON documents
            BEGIN
                DELETE FROM documents_fts WHERE rowid = old.id;
            END
        """
        )

        self.conn.commit()

        # ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜: doctype, display_date, claimed_total, sum_match ì»¬ëŸ¼ ì¶”ê°€
        self._migrate_schema()

    def _migrate_schema(self):
        """ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜: ì‹ ê·œ ì»¬ëŸ¼ ì¶”ê°€"""
        try:
            # ë°±ì—… ìƒì„±
            backup_path = f"{self.db_path}.bak"
            import shutil

            if Path(self.db_path).exists() and not Path(backup_path).exists():
                shutil.copy2(self.db_path, backup_path)
                logger.info(f"DB ë°±ì—… ìƒì„±: {backup_path}")

            # doctype ì»¬ëŸ¼ ì¶”ê°€ (ì¡´ì¬ í™•ì¸ í›„ ì¶”ê°€)
            cursor = self.conn.execute("PRAGMA table_info(documents)")
            columns = [col[1] for col in cursor.fetchall()]

            if "doctype" not in columns:
                self.conn.execute(
                    'ALTER TABLE documents ADD COLUMN doctype TEXT DEFAULT "proposal"'
                )
                logger.info("âœ“ doctype ì»¬ëŸ¼ ì¶”ê°€")

            if "display_date" not in columns:
                self.conn.execute("ALTER TABLE documents ADD COLUMN display_date TEXT")
                logger.info("âœ“ display_date ì»¬ëŸ¼ ì¶”ê°€")

            if "claimed_total" not in columns:
                self.conn.execute(
                    "ALTER TABLE documents ADD COLUMN claimed_total INTEGER"
                )
                logger.info("âœ“ claimed_total ì»¬ëŸ¼ ì¶”ê°€")

            if "sum_match" not in columns:
                self.conn.execute("ALTER TABLE documents ADD COLUMN sum_match BOOLEAN")
                logger.info("âœ“ sum_match ì»¬ëŸ¼ ì¶”ê°€")

            self.conn.commit()

        except Exception as e:
            logger.error(f"ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            self.conn.rollback()

    def add_document(self, metadata: Dict[str, Any]) -> int:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        try:
            # í‚¤ì›Œë“œë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            keywords = metadata.get("keywords", [])
            if isinstance(keywords, list):
                keywords = json.dumps(keywords, ensure_ascii=False)

            cursor = self.conn.execute(
                """
                INSERT OR REPLACE INTO documents (
                    path, filename, title, date, year, month, category,
                    drafter, amount, file_size, page_count, text_preview, keywords,
                    doctype, display_date, claimed_total, sum_match
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    str(metadata.get("path", "")),
                    metadata.get("filename", ""),
                    metadata.get("title", ""),
                    metadata.get("date", ""),
                    metadata.get("year", ""),
                    metadata.get("month", ""),
                    metadata.get("category", ""),
                    metadata.get("drafter", ""),
                    metadata.get("amount", 0),
                    metadata.get("file_size", 0),
                    metadata.get("page_count", 0),
                    metadata.get("text_preview", ""),
                    keywords,
                    metadata.get("doctype", "proposal"),
                    metadata.get("display_date", ""),
                    metadata.get("claimed_total", None),
                    metadata.get("sum_match", None),
                ),
            )

            self.conn.commit()
            return cursor.lastrowid

        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            self.conn.rollback()
            return -1

    def search_by_year(self, year: str) -> List[Dict[str, Any]]:
        """ì—°ë„ë³„ ê²€ìƒ‰"""
        cursor = self.conn.execute(
            "SELECT * FROM documents WHERE year = ? ORDER BY date DESC", (year,)
        )
        return [dict(row) for row in cursor.fetchall()]

    def search_documents(
        self, drafter: Optional[str] = None, year: Optional[str] = None, limit: int = 20
    ) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ í•„í„° ê²€ìƒ‰ (drafter, year ì¡°í•© ì§€ì›)

        Args:
            drafter: ê¸°ì•ˆìëª… (ë¶€ë¶„ ì¼ì¹˜)
            year: ì—°ë„ (display_date ê¸°ì¤€, ì˜ˆ: "2024")
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ)
        """
        query = "SELECT * FROM documents WHERE 1=1"
        params = []

        if drafter:
            query += " AND drafter LIKE ?"
            params.append(f"%{drafter}%")

        if year:
            # display_date ë˜ëŠ” date í•„ë“œì—ì„œ ì—°ë„ ì¶”ì¶œ
            query += " AND (display_date LIKE ? OR date LIKE ?)"
            params.append(f"{year}%")
            params.append(f"{year}%")

        query += " ORDER BY date DESC"
        if limit is not None:
            query += " LIMIT ?"
            params.append(limit)

        cursor = self.conn.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]

    def count_documents(
        self, drafter: Optional[str] = None, year: Optional[str] = None
    ) -> int:
        """ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ (í•„í„° ì ìš©)

        Args:
            drafter: ê¸°ì•ˆìëª… (ë¶€ë¶„ ì¼ì¹˜)
            year: ì—°ë„ (display_date ê¸°ì¤€, ì˜ˆ: "2024")

        Returns:
            ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œ ê°œìˆ˜
        """
        query = "SELECT COUNT(*) as count FROM documents WHERE 1=1"
        params = []

        if drafter:
            query += " AND drafter LIKE ?"
            params.append(f"%{drafter}%")

        if year:
            # display_date ë˜ëŠ” date í•„ë“œì—ì„œ ì—°ë„ ì¶”ì¶œ
            query += " AND (display_date LIKE ? OR date LIKE ?)"
            params.append(f"{year}%")
            params.append(f"{year}%")

        cursor = self.conn.execute(query, params)
        result = cursor.fetchone()
        return result["count"] if result else 0

    def search_by_category(self, category: str) -> List[Dict[str, Any]]:
        """ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰"""
        cursor = self.conn.execute(
            "SELECT * FROM documents WHERE category LIKE ? ORDER BY date DESC",
            (f"%{category}%",),
        )
        return [dict(row) for row in cursor.fetchall()]

    def search_by_keyword(self, keyword: str) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê²€ìƒ‰ (FTS ì‚¬ìš©)"""
        cursor = self.conn.execute(
            """
            SELECT d.* FROM documents d
            JOIN documents_fts f ON d.id = f.rowid
            WHERE documents_fts MATCH ?
            ORDER BY rank
            LIMIT 20
        """,
            (keyword,),
        )
        return [dict(row) for row in cursor.fetchall()]

    def search_by_date_range(
        self, start_date: str, end_date: str
    ) -> List[Dict[str, Any]]:
        """ë‚ ì§œ ë²”ìœ„ ê²€ìƒ‰"""
        cursor = self.conn.execute(
            "SELECT * FROM documents WHERE date BETWEEN ? AND ? ORDER BY date DESC",
            (start_date, end_date),
        )
        return [dict(row) for row in cursor.fetchall()]

    def get_document_by_path(self, path: str) -> Optional[Dict[str, Any]]:
        """ê²½ë¡œë¡œ ë¬¸ì„œ ì¡°íšŒ"""
        cursor = self.conn.execute(
            "SELECT * FROM documents WHERE path = ?", (str(path),)
        )
        row = cursor.fetchone()
        return dict(row) if row else None

    def get_document(self, filename: str) -> Optional[Dict[str, Any]]:
        """íŒŒì¼ëª…ìœ¼ë¡œ ë¬¸ì„œ ì¡°íšŒ (perfect_rag.py í˜¸í™˜ìš©)"""
        # íŒŒì¼ëª…ë§Œìœ¼ë¡œ ê²€ìƒ‰
        cursor = self.conn.execute(
            "SELECT * FROM documents WHERE filename = ? LIMIT 1", (filename,)
        )
        row = cursor.fetchone()
        return dict(row) if row else None

    def get_by_filename(self, filename: str) -> Optional[Dict[str, Any]]:
        """íŒŒì¼ëª…ìœ¼ë¡œ ë¬¸ì„œ ì¡°íšŒ (claimed_total í¬í•¨, ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)

        Args:
            filename: íŒŒì¼ëª… (í™•ì¥ì í¬í•¨ ê°€ëŠ¥)

        Returns:
            ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬ (claimed_total í¬í•¨) ë˜ëŠ” None
        """
        cursor = self.conn.execute(
            "SELECT * FROM documents WHERE filename = ? COLLATE NOCASE LIMIT 1",
            (filename,)
        )
        row = cursor.fetchone()
        return dict(row) if row else None

    def get_by_filename_fuzzy(self, name: str) -> Optional[Dict[str, Any]]:
        """í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ íŒŒì¼ëª… ê²€ìƒ‰ (ì–¸ë”ìŠ¤ì½”ì–´/ê³µë°±/íŠ¹ìˆ˜ê¸°í˜¸ ë¬´ì‹œ)

        Args:
            name: ê²€ìƒ‰í•  íŒŒì¼ëª… (ì¼ë¶€ë§Œ ì…ë ¥ ê°€ëŠ¥)

        Returns:
            ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        # ì´ëª¨ì§€ì™€ ë©”íƒ€ë°ì´í„° ì œê±° (ğŸ·, ğŸ“…, âœ ë“±)
        # "ë‰´ìŠ¤ ìŠ¤íŠœë””ì˜¤ ì§€ë¯¸ì§‘ Control Box ìˆ˜ë¦¬ ê±´ ğŸ· proposal Â· ğŸ“… 2024-11-25 Â· âœ ë‚¨ì¤€ìˆ˜"
        # -> "ë‰´ìŠ¤ ìŠ¤íŠœë””ì˜¤ ì§€ë¯¸ì§‘ Control Box ìˆ˜ë¦¬ ê±´"
        clean_name = re.sub(r'[ğŸ·ğŸ“…âœÂ·].*$', '', name).strip()

        def slug(s):
            """ë¬¸ìì—´ ì •ê·œí™”: ì†Œë¬¸ì + íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°"""
            s = s.lower().replace("&", "and")
            # ê³µë°±ê³¼ ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ ëª¨ë‘ ì œê±°í•˜ì—¬ ë¹„êµ
            return re.sub(r"[^0-9a-zê°€-í£]", "", s)

        s = slug(clean_name)

        # ë¹ˆ ë¬¸ìì—´ì´ë©´ None ë°˜í™˜
        if not s:
            return None

        cur = self.conn.cursor()
        # SQLì—ì„œë„ ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ì—¬ ë¹„êµ
        cur.execute(
            """
            SELECT *,
              ABS(LENGTH(filename) - ?) AS len_diff
            FROM documents
            WHERE LOWER(REPLACE(REPLACE(REPLACE(REPLACE(filename, '_',''), ' ',''), '.pdf',''), '-','')) LIKE ?
            ORDER BY len_diff ASC
            LIMIT 1
            """,
            (len(clean_name), f"%{s}%"),
        )
        row = cur.fetchone()
        return dict(row) if row else None

    def get_text_preview(self, filename: str) -> Optional[str]:
        """íŒŒì¼ëª…ìœ¼ë¡œ text_preview ì¡°íšŒ (snippet ë³´ê°•ìš©)

        Args:
            filename: íŒŒì¼ëª… (í™•ì¥ì í¬í•¨ ê°€ëŠ¥)

        Returns:
            text_preview ë¬¸ìì—´ ë˜ëŠ” None
        """
        cursor = self.conn.execute(
            "SELECT text_preview FROM documents WHERE filename = ? COLLATE NOCASE LIMIT 1",
            (filename,)
        )
        row = cursor.fetchone()
        return row["text_preview"] if row and row["text_preview"] else None

    def get_page_text(self, doc_id: str, page: int) -> Optional[str]:
        """íŠ¹ì • ë¬¸ì„œì˜ íŠ¹ì • í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìºì‹œ ì§€ì›)

        Args:
            doc_id: ë¬¸ì„œ ID (filename ë˜ëŠ” path)
            page: í˜ì´ì§€ ë²ˆí˜¸ (1-based)

        Returns:
            í˜ì´ì§€ í…ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        try:
            # ë¬¸ì„œ ê²½ë¡œ ì¡°íšŒ
            cursor = self.conn.execute(
                "SELECT path FROM documents WHERE filename = ? OR path = ? LIMIT 1",
                (doc_id, doc_id)
            )
            row = cursor.fetchone()

            if not row:
                logger.debug(f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {doc_id}")
                return None

            pdf_path = Path(row["path"])

            if not pdf_path.exists():
                logger.debug(f"PDF íŒŒì¼ ì—†ìŒ: {pdf_path}")
                return None

            # PDFì—ì„œ í˜ì´ì§€ ì¶”ì¶œ (pdfplumber ì‚¬ìš©)
            try:
                import pdfplumber

                with pdfplumber.open(pdf_path) as pdf:
                    if page < 1 or page > len(pdf.pages):
                        logger.debug(f"í˜ì´ì§€ ë²”ìœ„ ì´ˆê³¼: {page} (ì´ {len(pdf.pages)}ìª½)")
                        return None

                    page_obj = pdf.pages[page - 1]  # 0-based index
                    text = page_obj.extract_text() or ""

                    logger.debug(f"í˜ì´ì§€ ì¶”ì¶œ ì„±ê³µ: {doc_id} page={page}, len={len(text)}")
                    return text.strip()

            except Exception as e:
                logger.error(f"PDF í˜ì´ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_path} page={page}, error={e}")
                return None

        except Exception as e:
            logger.error(f"get_page_text ì‹¤íŒ¨: doc_id={doc_id}, page={page}, error={e}")
            return None

    def update_document(self, filename: str, **kwargs):
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ê°„í¸ ì—…ë°ì´íŠ¸ (perfect_rag.py í˜¸í™˜ìš©)"""
        # ë¨¼ì € ë¬¸ì„œ ì°¾ê¸°
        doc = self.get_document(filename)

        if not doc:
            # ìƒˆ ë¬¸ì„œë©´ ì¶”ê°€
            metadata = {"filename": filename}
            metadata.update(kwargs)
            return self.add_document(metadata)

        # ê¸°ì¡´ ë¬¸ì„œ ì—…ë°ì´íŠ¸
        fields = []
        values = []
        for key, value in kwargs.items():
            if key in [
                "title",
                "date",
                "year",
                "month",
                "category",
                "drafter",
                "amount",
                "file_size",
                "page_count",
                "text_preview",
                "keywords",
                "doctype",
                "display_date",
                "claimed_total",
                "sum_match",
            ]:
                fields.append(f"{key} = ?")
                if key == "keywords" and isinstance(value, list):
                    value = json.dumps(value, ensure_ascii=False)
                values.append(value)

        if fields:
            values.append(doc["id"])
            query = f"UPDATE documents SET {', '.join(fields)}, updated_at = CURRENT_TIMESTAMP WHERE id = ?"
            self.conn.execute(query, values)
            self.conn.commit()

    def update_text_preview(self, path: str, text_preview: str):
        """í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ì—…ë°ì´íŠ¸"""
        self.conn.execute(
            "UPDATE documents SET text_preview = ?, updated_at = CURRENT_TIMESTAMP WHERE path = ?",
            (text_preview[:1000], str(path)),  # ìµœëŒ€ 1000ì
        )
        self.conn.commit()

    def get_statistics(self) -> Dict[str, Any]:
        """DB í†µê³„ ì •ë³´"""
        cursor = self.conn.execute("SELECT COUNT(*) as total FROM documents")
        total = cursor.fetchone()["total"]

        cursor = self.conn.execute(
            """
            SELECT year, COUNT(*) as count
            FROM documents
            GROUP BY year
            ORDER BY year DESC
        """
        )
        by_year = {row["year"]: row["count"] for row in cursor.fetchall()}

        cursor = self.conn.execute(
            """
            SELECT category, COUNT(*) as count
            FROM documents
            GROUP BY category
            ORDER BY count DESC
        """
        )
        by_category = {row["category"]: row["count"] for row in cursor.fetchall()}

        return {
            "total_documents": total,
            "by_year": by_year,
            "by_category": by_category,
        }

    def rebuild_fts_index(self):
        """FTS ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        self.conn.execute('INSERT INTO documents_fts(documents_fts) VALUES("rebuild")')
        self.conn.commit()
        logger.info("FTS ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ")

    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


def extract_metadata_from_filename(filename: str) -> Dict[str, Any]:
    """íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    metadata = {
        "filename": filename,
        "title": "",
        "date": "",
        "year": "",
        "month": "",
        "category": "",
        "drafter": "",
    }

    # ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD or YYYY-MM or YYYY)
    date_match = re.search(r"(\d{4})[-_]?(\d{2})?[-_]?(\d{2})?", filename)
    if date_match:
        year = date_match.group(1)
        month = date_match.group(2) or ""
        day = date_match.group(3) or ""

        metadata["year"] = year
        metadata["month"] = month

        if day:
            metadata["date"] = f"{year}-{month}-{day}"
        elif month:
            metadata["date"] = f"{year}-{month}"
        else:
            metadata["date"] = year

    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    categories = ["êµ¬ë§¤", "ìˆ˜ë¦¬", "ë³´ìˆ˜", "êµì²´", "íê¸°", "ê²€í† ", "ê¸°ìˆ ", "ì†Œëª¨í’ˆ"]
    for cat in categories:
        if cat in filename:
            metadata["category"] = cat
            break

    # ì œëª© ì¶”ì¶œ (ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ ê³µë°±ìœ¼ë¡œ)
    title_part = filename.replace(".pdf", "").replace(".PDF", "")
    # ë‚ ì§œ ë¶€ë¶„ ì œê±°
    title_part = re.sub(r"\d{4}[-_]?\d{2}[-_]?\d{2}[-_]?", "", title_part)
    title_part = title_part.replace("_", " ").strip()
    metadata["title"] = title_part

    return metadata
