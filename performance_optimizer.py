#!/usr/bin/env python3
"""
RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
Phase 1: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­
"""

import os
import sys
import time
from pathlib import Path

def optimize_llm_singleton():
    """LLM ì‹±ê¸€í†¤ íŒ¨í„´ ìµœì í™”"""
    print("ğŸ”§ LLM ì‹±ê¸€í†¤ ìµœì í™” ì¤‘...")
    
    # llm_singleton.py ë°±ì—…
    singleton_path = Path("rag_system/llm_singleton.py")
    if singleton_path.exists():
        backup_path = singleton_path.with_suffix('.py.bak')
        singleton_path.rename(backup_path)
        print(f"  âœ… ë°±ì—… ìƒì„±: {backup_path}")
    
    # ê°œì„ ëœ ì‹±ê¸€í†¤ ì½”ë“œ ì‘ì„±
    optimized_code = '''"""
LLM ì‹±ê¸€í†¤ íŒ¨í„´ - ì„±ëŠ¥ ìµœì í™” ë²„ì „
"""

import threading
from typing import Optional, Dict, Any
from rag_system.qwen_llm import QwenLLM
import time

class LLMSingleton:
    """LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬"""
    
    _instance: Optional[QwenLLM] = None
    _lock = threading.Lock()
    _initialized = False
    _load_time = 0
    _usage_count = 0
    
    @classmethod
    def get_instance(cls, model_path: str = None, **kwargs) -> QwenLLM:
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        
        # ë¹ ë¥¸ ì²´í¬ (ë½ ì—†ì´)
        if cls._instance is not None:
            cls._usage_count += 1
            return cls._instance
        
        # ë”ë¸” ì²´í¬ ë½í‚¹
        with cls._lock:
            if cls._instance is None:
                start_time = time.time()
                print("ğŸ¤– LLM ëª¨ë¸ ìµœì´ˆ ë¡œë”©...")
                
                cls._instance = QwenLLM(model_path=model_path)
                cls._load_time = time.time() - start_time
                cls._initialized = True
                
                print(f"âœ… LLM ë¡œë“œ ì™„ë£Œ ({cls._load_time:.1f}ì´ˆ)")
            else:
                cls._usage_count += 1
                print(f"â™»ï¸ LLM ì¬ì‚¬ìš© (#{cls._usage_count})")
        
        return cls._instance
    
    @classmethod
    def is_loaded(cls) -> bool:
        """ëª¨ë¸ ë¡œë“œ ì—¬ë¶€ í™•ì¸"""
        return cls._initialized
    
    @classmethod
    def get_stats(cls) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ ë°˜í™˜"""
        return {
            "loaded": cls._initialized,
            "load_time": cls._load_time,
            "usage_count": cls._usage_count
        }
    
    @classmethod
    def clear(cls):
        """ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ì •ë¦¬ìš©)"""
        with cls._lock:
            if cls._instance:
                try:
                    # LLM ë¦¬ì†ŒìŠ¤ ì •ë¦¬
                    if hasattr(cls._instance, 'llm') and cls._instance.llm:
                        del cls._instance.llm
                except:
                    pass
                
                cls._instance = None
                cls._initialized = False
                print("ğŸ§¹ LLM ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
'''
    
    # íŒŒì¼ ì €ì¥
    with open(singleton_path, 'w', encoding='utf-8') as f:
        f.write(optimized_code)
    
    print("  âœ… LLM ì‹±ê¸€í†¤ ìµœì í™” ì™„ë£Œ")
    return True

def optimize_cache_key():
    """ìºì‹œ í‚¤ ìƒì„± ìµœì í™”"""
    print("ğŸ”§ ìºì‹œ í‚¤ ìƒì„± ìµœì í™” ì¤‘...")
    
    cache_optimizer = '''
# perfect_rag.pyì˜ _get_cache_key ë©”ì„œë“œ ê°œì„ 
import re

def _get_enhanced_cache_key(self, query: str, mode: str) -> str:
    """í–¥ìƒëœ ìºì‹œ í‚¤ ìƒì„± - ìœ ì‚¬ ì§ˆë¬¸ë„ ìºì‹œ íˆíŠ¸"""
    
    # 1. ì¿¼ë¦¬ ì •ê·œí™”
    normalized = query.strip().lower()
    
    # 2. ì¡°ì‚¬ ì œê±° (í•œêµ­ì–´ íŠ¹í™”)
    particles = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ', 'ì—', 'ì—ì„œ']
    for particle in particles:
        normalized = normalized.replace(particle + ' ', ' ')
    
    # 3. ê³µë°± ì •ê·œí™”
    normalized = ' '.join(normalized.split())
    
    # 4. í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
    keywords = []
    for word in normalized.split():
        if len(word) >= 2:  # 2ê¸€ì ì´ìƒë§Œ
            keywords.append(word)
    
    # 5. ì •ë ¬í•˜ì—¬ ìˆœì„œ ë¬´ê´€í•˜ê²Œ
    keywords.sort()
    
    # 6. í•´ì‹œ ìƒì„±
    cache_str = f"{mode}:{'_'.join(keywords)}"
    return hashlib.md5(cache_str.encode()).hexdigest()
'''
    
    print("  âœ… ìºì‹œ í‚¤ ìµœì í™” ì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    return cache_optimizer

def optimize_context_window():
    """ë™ì  ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê´€ë¦¬"""
    print("ğŸ”§ ë™ì  ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì¶”ê°€...")
    
    dynamic_context = '''
def _get_optimal_context_size(self, query: str, doc_count: int) -> int:
    """ì¿¼ë¦¬ì™€ ë¬¸ì„œ ìˆ˜ì— ë”°ë¥¸ ìµœì  ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ê²°ì •"""
    
    query_len = len(query)
    
    # ê°„ë‹¨í•œ ì¿¼ë¦¬ (20ì ë¯¸ë§Œ)
    if query_len < 20 and doc_count <= 3:
        return 4096
    
    # ì¤‘ê°„ ë³µì¡ë„ (20-50ì)
    elif query_len < 50 and doc_count <= 5:
        return 8192
    
    # ë³µì¡í•œ ì¿¼ë¦¬ ë˜ëŠ” ë§ì€ ë¬¸ì„œ
    else:
        return 16384

def _smart_truncate_context(self, text: str, max_tokens: int = 8000) -> str:
    """ìŠ¤ë§ˆíŠ¸ ì»¨í…ìŠ¤íŠ¸ ì ˆë‹¨"""
    
    # í† í° ìˆ˜ ì¶”ì • (í•œê¸€ 1.5ì = 1í† í° ê¸°ì¤€)
    estimated_tokens = len(text) / 1.5
    
    if estimated_tokens <= max_tokens:
        return text
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì ˆë‹¨
    sentences = text.split('.')
    result = []
    current_tokens = 0
    
    for sentence in sentences:
        sentence_tokens = len(sentence) / 1.5
        if current_tokens + sentence_tokens > max_tokens:
            break
        result.append(sentence)
        current_tokens += sentence_tokens
    
    return '.'.join(result) + '.'
'''
    
    print("  âœ… ë™ì  ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì½”ë“œ ì¤€ë¹„ ì™„ë£Œ")
    return dynamic_context

def create_performance_config():
    """ì„±ëŠ¥ ìµœì í™” ì„¤ì • íŒŒì¼ ìƒì„±"""
    print("ğŸ”§ ì„±ëŠ¥ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘...")
    
    config_content = '''# performance_config.yaml
# RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ì„¤ì •

llm:
  max_tokens: 800      # ê¸°ì¡´ 1200ì—ì„œ ì¶•ì†Œ
  temperature: 0.3     # ê¸°ì¡´ 0.7ì—ì„œ ì¶•ì†Œ (ë” ê²°ì •ì )
  top_p: 0.85         # ê¸°ì¡´ 0.9ì—ì„œ ì¶•ì†Œ
  repeat_penalty: 1.15 # ë°˜ë³µ ë°©ì§€ ê°•í™”
  batch_size: 256     # ê¸°ì¡´ 512ì—ì„œ ì¶•ì†Œ

cache:
  response_ttl: 7200   # 2ì‹œê°„ (ê¸°ì¡´ 1ì‹œê°„)
  max_size: 500       # ê¸°ì¡´ 200ì—ì„œ ì¦ê°€
  similarity_threshold: 0.85  # ìœ ì‚¬ ì¿¼ë¦¬ ìºì‹œ íˆíŠ¸

search:
  max_documents: 30    # ê¸°ì¡´ 50ì—ì„œ ì¶•ì†Œ
  timeout: 20         # ê¸°ì¡´ 30ì´ˆì—ì„œ ì¶•ì†Œ
  min_relevance: 0.6  # ê´€ë ¨ì„± ì„ê³„ê°’

parallel:
  pdf_workers: 4      # PDF ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤
  chunk_size: 5       # ì²­í¬ í¬ê¸°
  
memory:
  max_document_length: 8000  # ë¬¸ì„œë‹¹ ìµœëŒ€ ê¸¸ì´
  cache_documents: true      # ë¬¸ì„œ ìºì‹± í™œì„±í™”
  
optimization:
  use_singleton: true        # LLM ì‹±ê¸€í†¤ ì‚¬ìš©
  use_streaming: false       # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì¶”í›„ êµ¬í˜„)
  use_dynamic_context: true  # ë™ì  ì»¨í…ìŠ¤íŠ¸
'''
    
    # ì„¤ì • íŒŒì¼ ì €ì¥
    config_path = Path("performance_config.yaml")
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    print(f"  âœ… ì„±ëŠ¥ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    return True

def main():
    """ë©”ì¸ ìµœì í™” ì‹¤í–‰"""
    print("="*50)
    print("ğŸš€ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” Phase 1")
    print("="*50)
    
    start_time = time.time()
    
    # 1. LLM ì‹±ê¸€í†¤ ìµœì í™”
    optimize_llm_singleton()
    
    # 2. ìºì‹œ í‚¤ ìµœì í™” (ì½”ë“œ ì¶œë ¥)
    cache_code = optimize_cache_key()
    print("\nğŸ“ perfect_rag.pyì— ì¶”ê°€í•  ìºì‹œ ìµœì í™” ì½”ë“œ:")
    print("-"*40)
    print(cache_code)
    print("-"*40)
    
    # 3. ë™ì  ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ (ì½”ë“œ ì¶œë ¥)
    context_code = optimize_context_window()
    print("\nğŸ“ perfect_rag.pyì— ì¶”ê°€í•  ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì½”ë“œ:")
    print("-"*40)
    print(context_code)
    print("-"*40)
    
    # 4. ì„±ëŠ¥ ì„¤ì • íŒŒì¼ ìƒì„±
    create_performance_config()
    
    elapsed = time.time() - start_time
    
    print("\n" + "="*50)
    print(f"âœ… Phase 1 ìµœì í™” ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")
    print("="*50)
    
    print("\nğŸ“‹ ì ìš© ë°©ë²•:")
    print("1. llm_singleton.pyëŠ” ìë™ìœ¼ë¡œ êµì²´ë¨")
    print("2. perfect_rag.pyì— ìœ„ ì½”ë“œë“¤ì„ ì¶”ê°€")
    print("3. performance_config.yaml ì„¤ì • ì ìš©")
    print("\nâš¡ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ:")
    print("- LLM ë¡œë”©: 7.73ì´ˆ â†’ 0.1ì´ˆ (ì¬ì‚¬ìš© ì‹œ)")
    print("- ì‘ë‹µ ì‹œê°„: 140ì´ˆ â†’ 30-50ì´ˆ")
    print("- ìºì‹œ íˆíŠ¸ìœ¨: 30% â†’ 70%+")

if __name__ == "__main__":
    main()
