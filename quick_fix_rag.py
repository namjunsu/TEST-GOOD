#!/usr/bin/env python3
"""
ê°œì„ ëœ ë¹ ë¥¸ ê²€ìƒ‰ RAG - LLM ìš”ì•½ + ì¶œì²˜ ì¸ìš© ê°•ì œ + L2 ë¦¬ë­í‚¹
"""

from modules.search_module_hybrid import SearchModuleHybrid
from modules.reranker import RuleBasedReranker
import time
import re
import sqlite3

from app.core.logging import get_logger

logger = get_logger(__name__)

class QuickFixRAG:
    """ë¹ ë¥¸ ê²€ìƒ‰ + LLM ìš”ì•½ - í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ"""

    def __init__(self, use_hybrid: bool = True):
        """
        Args:
            use_hybrid: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë“ˆ ì‚¬ìš© ì‹œë„
            self.search_module = SearchModuleHybrid(use_hybrid=use_hybrid)
            logger.info(f"âœ… SearchModuleHybrid ì´ˆê¸°í™” ì„±ê³µ (hybrid={use_hybrid})")
        except Exception as e:
            logger.warning(f"âš ï¸ SearchModuleHybrid ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ SearchModule ì‚¬ìš©: {e}")
            from modules.search_module import SearchModule
            self.search_module = SearchModule()

        # L2 ë¦¬ë­ì»¤ ì´ˆê¸°í™”
        try:
            self.reranker = RuleBasedReranker()
            logger.info("âœ… RuleBasedReranker ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ RuleBasedReranker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.reranker = None

        # LLM (ì§€ì—° ë¡œë”©)
        self.llm = None
        self.llm_loaded = False

    def answer(self, query: str, use_llm_summary: bool = True) -> str:
        """
        ê²€ìƒ‰ + LLM ìš”ì•½ ë°˜í™˜

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            use_llm_summary: LLM ìš”ì•½ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)
        """

        # ë©”íŠ¸ë¦­ ì¸¡ì • ì‹œì‘
        start_time = time.time()
        metrics = {
            'retrieval_ms': 0,
            'rerank_ms': 0,
            'llm_ms': 0,
            'total_ms': 0,
            'retrieved_k': 0,
            'reranked_k': 0,
            'context_tokens': 0,
            'fallback_reason': None
        }

        try:
            # ğŸ”¥ P0: íŒŒì¼ëª… ì§ì ‘ ë§¤ì¹­ (ìµœìš°ì„  ìˆœìœ„)
            filename_pattern = r'(\S+\.pdf)'
            filename_match = re.search(filename_pattern, query, re.IGNORECASE)

            if filename_match:
                filename = filename_match.group(1).strip()
                logger.info(f"ğŸ¯ P0: íŒŒì¼ëª… ì§ì ‘ ë§¤ì¹­ ì‹œë„ - {filename}")

                # DBì—ì„œ íŒŒì¼ ì§ì ‘ ì¡°íšŒ
                file_result = self._search_by_exact_filename(filename)
                if file_result:
                    logger.info(f"âœ… íŒŒì¼ëª… ë§¤ì¹­ ì„±ê³µ: {filename}")
                    metrics['retrieval_ms'] = int((time.time() - start_time) * 1000)
                    metrics['retrieved_k'] = 1
                    metrics['total_ms'] = int((time.time() - start_time) * 1000)
                    self._log_metrics(metrics)
                    return self._format_file_result(filename, file_result)

            # 1. ê¸°ì•ˆì ë° ì—°ë„ íŒ¨í„´ ì¶”ì¶œ
            drafter_name = self._extract_author_name(query)
            year_match = re.search(r'(\d{4})\s*ë…„', query)
            year = year_match.group(1) if year_match else None

            # 2. ì¡°í•© ê²€ìƒ‰: ì—°ë„ + ê¸°ì•ˆì (ìš°ì„ ìˆœìœ„ ìµœìƒìœ„)
            if year and drafter_name:
                retrieval_start = time.time()
                logger.info(f"âœ… ì¡°í•© ê²€ìƒ‰ ëª¨ë“œ: {year}ë…„ + ê¸°ì•ˆì={drafter_name}")
                search_results = self._search_by_year_and_drafter(year, drafter_name)
                metrics['retrieval_ms'] = int((time.time() - retrieval_start) * 1000)
                metrics['retrieved_k'] = len(search_results)

                # L2 ë¦¬ë­í‚¹ ì ìš©
                if search_results and self.reranker:
                    rerank_start = time.time()
                    search_results = self.reranker.rerank(query, search_results, top_k=20)
                    metrics['rerank_ms'] = int((time.time() - rerank_start) * 1000)
                    metrics['reranked_k'] = len(search_results)
                    logger.info(f"ğŸ”„ ë¦¬ë­í‚¹ ì™„ë£Œ: {len(search_results)}ê±´")

                metrics['total_ms'] = int((time.time() - start_time) * 1000)
                self._log_metrics(metrics)

                if search_results:
                    logger.info(f"âœ… {year}ë…„ {drafter_name} ë¬¸ì„œ {len(search_results)}ê°œ ë°œê²¬")
                    return self._format_drafter_results(query, f"{year}ë…„ {drafter_name}", search_results)
                else:
                    metrics['fallback_reason'] = 'no_results'
                    logger.warning(f"âš ï¸  {year}ë…„ {drafter_name} ë¬¸ì„œ ì—†ìŒ")
                    return f"âŒ {year}ë…„ì— {drafter_name}ì´(ê°€) ì‘ì„±í•œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # 3. ê¸°ì•ˆìë§Œ ê²€ìƒ‰
            if drafter_name:
                retrieval_start = time.time()
                logger.info(f"âœ… ê¸°ì•ˆì ê²€ìƒ‰ ëª¨ë“œ: {drafter_name}")
                search_results = self.search_module.search_by_drafter(drafter_name, top_k=200)
                metrics['retrieval_ms'] = int((time.time() - retrieval_start) * 1000)
                metrics['retrieved_k'] = len(search_results)

                # L2 ë¦¬ë­í‚¹ ì ìš©
                if search_results and self.reranker:
                    rerank_start = time.time()
                    search_results = self.reranker.rerank(query, search_results, top_k=20)
                    metrics['rerank_ms'] = int((time.time() - rerank_start) * 1000)
                    metrics['reranked_k'] = len(search_results)
                    logger.info(f"ğŸ”„ ë¦¬ë­í‚¹ ì™„ë£Œ: {len(search_results)}ê±´")

                metrics['total_ms'] = int((time.time() - start_time) * 1000)
                self._log_metrics(metrics)

                if search_results:
                    logger.info(f"âœ… ê¸°ì•ˆì '{drafter_name}' ë¬¸ì„œ {len(search_results)}ê°œ ë°œê²¬")
                    return self._format_drafter_results(query, drafter_name, search_results)
                else:
                    logger.warning(f"âš ï¸  ê¸°ì•ˆì '{drafter_name}' ë¬¸ì„œ ì—†ìŒ")

            # 4. ì—°ë„ë§Œ ê²€ìƒ‰
            if year:
                retrieval_start = time.time()
                logger.info(f"âœ… ì—°ë„ ê²€ìƒ‰ ëª¨ë“œ: {year}ë…„")
                search_results = self._search_by_year(year)
                metrics['retrieval_ms'] = int((time.time() - retrieval_start) * 1000)
                metrics['retrieved_k'] = len(search_results)

                # L2 ë¦¬ë­í‚¹ ì ìš©
                if search_results and self.reranker:
                    rerank_start = time.time()
                    search_results = self.reranker.rerank(query, search_results, top_k=20)
                    metrics['rerank_ms'] = int((time.time() - rerank_start) * 1000)
                    metrics['reranked_k'] = len(search_results)
                    logger.info(f"ğŸ”„ ë¦¬ë­í‚¹ ì™„ë£Œ: {len(search_results)}ê±´")

                metrics['total_ms'] = int((time.time() - start_time) * 1000)
                self._log_metrics(metrics)

                if search_results:
                    logger.info(f"âœ… {year}ë…„ ë¬¸ì„œ {len(search_results)}ê°œ ë°œê²¬")
                    return self._format_search_results(f"{year}ë…„ ë¬¸ì„œ", search_results)

            # 5. ì¼ë°˜ ê²€ìƒ‰
            retrieval_start = time.time()
            search_results = self.search_module.search_by_content(query, top_k=20)
            metrics['retrieval_ms'] = int((time.time() - retrieval_start) * 1000)
            metrics['retrieved_k'] = len(search_results)

            # L2 ë¦¬ë­í‚¹ ì ìš©
            if search_results and self.reranker:
                rerank_start = time.time()
                search_results = self.reranker.rerank(query, search_results, top_k=5)
                metrics['rerank_ms'] = int((time.time() - rerank_start) * 1000)
                metrics['reranked_k'] = len(search_results)
                logger.info(f"ğŸ”„ ë¦¬ë­í‚¹ ì™„ë£Œ: {len(search_results)}ê±´")

            if not search_results:
                metrics['fallback_reason'] = 'no_results'
                metrics['total_ms'] = int((time.time() - start_time) * 1000)
                self._log_metrics(metrics)
                return self._format_no_results_message(query)

            # 6. LLM ìš”ì•½ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
            if use_llm_summary and self._ensure_llm_loaded():
                llm_start = time.time()
                result = self._answer_with_llm_summary(query, search_results)
                metrics['llm_ms'] = int((time.time() - llm_start) * 1000)
                metrics['context_tokens'] = sum(len(str(doc.get('content', '')).split()) for doc in search_results[:3])
                metrics['total_ms'] = int((time.time() - start_time) * 1000)
                self._log_metrics(metrics)
                return result
            else:
                # LLM ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜ (ì¶œì²˜ í¬í•¨)
                metrics['fallback_reason'] = 'llm_disabled'
                metrics['total_ms'] = int((time.time() - start_time) * 1000)
                self._log_metrics(metrics)
                fallback_msg = "ğŸ’¡ **LLM ë¹„í™œì„±**: ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤ (ìš”ì•½ ë¯¸ì œê³µ)\n\n"
                return fallback_msg + self._format_search_results(query, search_results)

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return f"âŒ ì˜¤ë¥˜: {str(e)}"

    def _answer_with_llm_summary(self, query: str, search_results: list) -> str:
        """LLMìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (í•µì‹¬ë§Œ ì¶”ì¶œ)"""

        try:
            # ìƒìœ„ 3ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
            top_docs = search_results[:3]

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸ˆì•¡/í’ˆëª© ì •ë³´ í¬í•¨í•˜ë„ë¡ ì¶©ë¶„í•œ ê¸¸ì´)
            context_chunks = []
            for doc in top_docs:
                context_chunks.append({
                    'source': doc['filename'],
                    'content': doc.get('content', '')[:3000],  # 3000ìë¡œ í™•ì¥ (ê¸ˆì•¡/í’ˆëª© ì •ë³´ í¬í•¨)
                    'score': doc.get('score', 0.8),
                    'metadata': {
                        'ë‚ ì§œ': doc.get('date', ''),
                        'ì¹´í…Œê³ ë¦¬': doc.get('category', ''),
                        'ê¸°ì•ˆì': doc.get('department', '')
                    }
                })

            # LLMì—ê²Œ í•µì‹¬ë§Œ ìš”ì•½ ìš”ì²­
            response = self.llm.generate_response(query, context_chunks, max_retries=1)

            # ë‹µë³€ ì¶”ì¶œ
            if hasattr(response, 'answer'):
                summary = response.answer
            else:
                summary = str(response)

            # ì¶œì²˜ ê°•ì œ ì¶”ê°€ (LLMì´ ì¸ìš© ì•ˆí–ˆì„ ê²½ìš°)
            if '[' not in summary or '.pdf]' not in summary:
                # LLMì´ ì¶œì²˜ë¥¼ ì•ˆ ë‹¬ì•˜ìœ¼ë©´ ê°•ì œë¡œ ì¶”ê°€
                sources = [f"[{doc['filename']}]" for doc in top_docs[:2]]
                summary += f"\n\nì¶œì²˜: {', '.join(sources)}"

            return summary

        except Exception as e:
            logger.error(f"âŒ LLM ìš”ì•½ ì‹¤íŒ¨: {e}, ê²€ìƒ‰ ê²°ê³¼ë¡œ ëŒ€ì²´")
            fallback_msg = "âš ï¸ **LLM ìš”ì•½ ì‹¤íŒ¨**: ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤\n\n"
            return fallback_msg + self._format_search_results(query, search_results)

    def _format_no_results_message(self, query: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ ë©”ì‹œì§€ (ì‚¬ìš©ì ì¹œí™”ì )

        Args:
            query: ê²€ìƒ‰ ì§ˆì˜

        Returns:
            ì‚¬ìš©ì ì¹œí™”ì  ì•ˆë‚´ ë©”ì‹œì§€
        """
        return f"""ğŸ” **ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ**

**ì§ˆì˜:** {query}

**ì•ˆë‚´:**
- ì…ë ¥í•˜ì‹  ì§ˆì˜ì™€ ì¼ì¹˜í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤
- ë‹¤ìŒ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”:
  1. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (ì˜ˆ: "2025ë…„ ë¬¸ì„œ", "ë°©ì†¡ ì¥ë¹„")
  2. íŒŒì¼ëª… ì§ì ‘ ì§€ì • (ì˜ˆ: "2025-03-04_ë°©ì†¡_ì˜ìƒ_ë³´ì¡´ìš©_DVR_êµì²´_ê²€í† ì˜_ê±´.pdf")
  3. ê¸°ì•ˆì ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (ì˜ˆ: "ë‚¨ì¤€ìˆ˜ ë¬¸ì„œ", "ìµœìƒˆë¦„ì´ ì‘ì„±í•œ ë¬¸ì„œ")
  4. ì—°ë„ë¡œ ê²€ìƒ‰ (ì˜ˆ: "2024ë…„ ë¬¸ì„œ")

ğŸ’¡ **ê²€ìƒ‰ íŒ:**
- êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš©
- ì—¬ëŸ¬ í‚¤ì›Œë“œ ì¡°í•© (ì˜ˆ: "2025ë…„ ì¹´ë©”ë¼ êµ¬ë§¤")
- íŒŒì¼ëª…ì´ë‚˜ ê¸°ì•ˆìëª… ì •í™•íˆ ì§€ì •
"""

    def _is_valid_drafter_name(self, drafter: str) -> bool:
        """ê¸°ì•ˆì ì´ë¦„ ìœ íš¨ì„± ê²€ì¦ (ì˜ëª»ëœ í‚¤ì›Œë“œ í•„í„°ë§)

        Args:
            drafter: ê¸°ì•ˆì ì´ë¦„

        Returns:
            ìœ íš¨í•œ ì´ë¦„ì´ë©´ True, ì˜ëª»ëœ í‚¤ì›Œë“œë©´ False
        """
        if not drafter or drafter == 'ë¯¸ìƒ':
            return False

        # ğŸ”¥ ì˜ëª»ëœ í‚¤ì›Œë“œ í•„í„° (íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œëœ ë‹¨ì–´ë“¤)
        invalid_keywords = [
            'DVR', 'dvr', 'CAMERA', 'camera', 'ì¹´ë©”ë¼', 'TV', 'tv',
            'ìŠ¤íŠœë””ì˜¤', 'studio', 'STUDIO', 'ë°©ì†¡', 'ì¥ë¹„', 'ëª¨ë‹ˆí„°',
            'ì›Œí¬ìŠ¤í…Œì´ì…˜', 'ì»´í“¨í„°', 'PC', 'pc', 'ìˆ˜ë¦¬', 'êµ¬ë§¤', 'êµì²´'
        ]

        return drafter not in invalid_keywords

    def _format_search_results(self, query: str, search_results: list) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§¤íŒ… (ì¶œì²˜ ê°•ì œ í¬í•¨)"""
        total_count = len(search_results)

        answer = f"**{query}** ê²€ìƒ‰ ê²°ê³¼\n\n"
        answer += f"ğŸ“Š **ì´ {total_count}ê°œ ë¬¸ì„œ** ë°œê²¬\n\n"

        for i, doc in enumerate(search_results, 1):
            answer += f"**{i}. {doc['filename']}**\n"
            if doc.get('date'):
                answer += f"   - ë‚ ì§œ: {doc['date']}\n"
            if doc.get('category'):
                answer += f"   - ì¹´í…Œê³ ë¦¬: {doc['category']}\n"

            # ê¸°ì•ˆì ì •ë³´ ìš°ì„  í‘œì‹œ (ìœ íš¨í•œ ì´ë¦„ë§Œ)
            drafter = doc.get('department', '')
            if self._is_valid_drafter_name(drafter):
                answer += f"   - ê¸°ì•ˆì: {drafter}\n"

            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì§§ê²Œ)
            content_preview = (doc.get('content', '')[:150] + "..."
                               if len(doc.get('content', '')) > 150
                               else doc.get('content', ''))
            answer += f"   - ë‚´ìš©: {content_preview}\n"

            # âœ… ì¶œì²˜ ê°•ì œ ì¶”ê°€
            answer += f"   - ğŸ“ ì¶œì²˜: [{doc['filename']}]\n\n"

        return answer

    def _format_drafter_results(self, query: str, drafter_name: str, search_results: list) -> str:
        """ê¸°ì•ˆì ê²€ìƒ‰ ê²°ê³¼ í¬ë§¤íŒ… (ì¶œì²˜ í¬í•¨)"""
        total_count = len(search_results)
        display_count = min(100, total_count)  # ìµœëŒ€ 100ê°œ í‘œì‹œ

        answer = f"**ê¸°ì•ˆì: {drafter_name}** ê²€ìƒ‰ ê²°ê³¼\n\n"
        answer += f"ğŸ“Š **ì´ {total_count}ê°œ ë¬¸ì„œ** ë°œê²¬ ({display_count}ê°œ í‘œì‹œ)\n\n"

        # ë‚ ì§œë³„ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        sorted_results = sorted(search_results,
                                key=lambda x: x.get('date', ''),
                                reverse=True)

        for i, doc in enumerate(sorted_results[:display_count], 1):
            answer += f"**{i}. {doc['filename']}**\n"
            if doc.get('date'):
                answer += f"   - ë‚ ì§œ: {doc['date']}\n"
            if doc.get('category'):
                answer += f"   - ì¹´í…Œê³ ë¦¬: {doc['category']}\n"

            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            content_preview = (doc.get('content', '')[:150] + "..."
                               if len(doc.get('content', '')) > 150
                               else doc.get('content', ''))
            answer += f"   - ë‚´ìš©: {content_preview}\n"

            # âœ… ì¶œì²˜ ê°•ì œ ì¶”ê°€
            answer += f"   - ğŸ“ ì¶œì²˜: [{doc['filename']}]\n\n"

        # ë‚¨ì€ ë¬¸ì„œ ì•ˆë‚´
        remaining = total_count - display_count
        if remaining > 0:
            answer += f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            answer += f"ğŸ“Œ **{remaining}ê°œ ë¬¸ì„œ ë” ìˆìŠµë‹ˆë‹¤**\n"
            answer += f"ğŸ’¡ ì¹´í…Œê³ ë¦¬ë‚˜ ê¸°ê°„ìœ¼ë¡œ ì¢í˜€ë³´ì„¸ìš”\n"

        return answer

    def _search_by_year_and_drafter(self, year: str, drafter: str) -> list:
        """ì—°ë„ + ê¸°ì•ˆì ì¡°í•© ê²€ìƒ‰ (metadata.db ì‚¬ìš©, ì¤‘ë³µ ì œê±°)

        Args:
            year: ì—°ë„ (ì˜ˆ: "2025")
            drafter: ê¸°ì•ˆì ì´ë¦„ (ì˜ˆ: "ìµœìƒˆë¦„")

        Returns:
            í•´ë‹¹ ì—°ë„ + ê¸°ì•ˆìì˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°ë¨)
        """
        try:
            import sqlite3
            import pdfplumber
            from pathlib import Path

            conn = sqlite3.connect('metadata.db')
            cursor = conn.cursor()

            # year í•„ë“œì™€ drafter í•„ë“œë¡œ í•„í„° (metadata.db)
            cursor.execute("""
                SELECT path, filename, date, category, drafter, text_preview
                FROM documents
                WHERE year = ? AND drafter LIKE ?
                ORDER BY date DESC
                LIMIT 200
            """, (year, f'%{drafter}%'))

            results = []
            seen_filenames = set()  # ì¤‘ë³µ ì œê±°ìš©

            for path, filename, date, category, drafter_val, text_preview in cursor.fetchall():
                # ì¤‘ë³µ ì œê±°: íŒŒì¼ëª… ê¸°ì¤€
                if filename in seen_filenames:
                    continue
                seen_filenames.add(filename)

                result = {
                    'filename': filename,
                    'path': path,
                    'date': date or '',
                    'category': category or '',
                    'department': drafter_val or '',
                    'content': text_preview or '',
                    'score': 1.5
                }

                # PDF ì „ì²´ í…ìŠ¤íŠ¸ ë¡œë“œ (ì²˜ìŒ 5ê°œë§Œ)
                if len(results) < 5 and path:
                    try:
                        pdf_path = Path(path)
                        if pdf_path.exists() and pdf_path.suffix.lower() == '.pdf':
                            with pdfplumber.open(pdf_path) as pdf:
                                full_text = ""
                                for page in pdf.pages[:3]:  # ìµœëŒ€ 3í˜ì´ì§€
                                    page_text = page.extract_text() or ""
                                    full_text += page_text + "\n\n"
                                    if len(full_text) > 5000:
                                        break
                                result['content'] = full_text
                    except Exception as e:
                        logger.warning(f"PDF ì½ê¸° ì‹¤íŒ¨ ({filename}): {e}")

                results.append(result)

            conn.close()
            logger.info(f"âœ… ì¡°í•© ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê±´ (ì¤‘ë³µ ì œê±° í›„)")
            return results

        except Exception as e:
            logger.error(f"âŒ ì¡°í•© ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _search_by_year(self, year: str) -> list:
        """ì—°ë„ë³„ ë¬¸ì„œ ê²€ìƒ‰ (metadata.db ì‚¬ìš©)

        Args:
            year: ì—°ë„ (ì˜ˆ: "2025")

        Returns:
            í•´ë‹¹ ì—°ë„ì˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            import sqlite3
            import pdfplumber
            from pathlib import Path

            conn = sqlite3.connect('metadata.db')
            cursor = conn.cursor()

            # year í•„ë“œì—ì„œ ê²€ìƒ‰ (metadata.db)
            cursor.execute("""
                SELECT path, filename, date, category, drafter, text_preview
                FROM documents
                WHERE year = ?
                ORDER BY date DESC
                LIMIT 200
            """, (year,))

            results = []
            for path, filename, date, category, drafter, text_preview in cursor.fetchall():
                result = {
                    'filename': filename,
                    'path': path,
                    'date': date or '',
                    'category': category or '',
                    'department': drafter or '',
                    'content': text_preview or '',
                    'score': 1.5
                }

                # PDF ì „ì²´ í…ìŠ¤íŠ¸ ë¡œë“œ (ì²˜ìŒ 5ê°œë§Œ)
                if len(results) < 5 and path:
                    try:
                        pdf_path = Path(path)
                        if pdf_path.exists() and pdf_path.suffix.lower() == '.pdf':
                            with pdfplumber.open(pdf_path) as pdf:
                                full_text = ""
                                for page in pdf.pages[:3]:  # ìµœëŒ€ 3í˜ì´ì§€
                                    page_text = page.extract_text() or ""
                                    full_text += page_text + "\n\n"
                                    if len(full_text) > 5000:
                                        break
                                result['content'] = full_text
                    except Exception as e:
                        logger.warning(f"PDF ì½ê¸° ì‹¤íŒ¨ ({filename}): {e}")

                results.append(result)

            conn.close()
            return results

        except Exception as e:
            logger.error(f"âŒ ì—°ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _extract_author_name(self, query: str) -> str:
        """ì§ˆë¬¸ì—ì„œ ê¸°ì•ˆì/ì‘ì„±ì ì´ë¦„ ì¶”ì¶œ (ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›)

        ì§€ì› íŒ¨í„´:
        - "ë‚¨ì¤€ìˆ˜ ë¬¸ì„œ"
        - "ë‚¨ì¤€ìˆ˜ê°€ ì‘ì„±í•œ"
        - "ë‚¨ì¤€ìˆ˜ê°€ ì‘ì„±ì•ˆ" (ì˜¤íƒ€)
        - "ê¸°ì•ˆì ë‚¨ì¤€ìˆ˜"
        - "ì‘ì„±ì: ë‚¨ì¤€ìˆ˜"
        - "ë‚¨ì¤€ìˆ˜ ê¸°ì•ˆì„œ"
        """
        # íŒ¨í„´ 1: "ê¸°ì•ˆì XXX", "ì‘ì„±ì XXX"
        match = re.search(r'(ê¸°ì•ˆì|ì‘ì„±ì|ì œì•ˆì)[:\s]+([ê°€-í£]{2,4})', query)
        if match:
            return match.group(2)

        # íŒ¨í„´ 2: "XXXê°€ ì‘ì„±í•œ", "XXXê°€ ì‘ì„±ì•ˆ"
        match = re.search(r'([ê°€-í£]{2,4})ê°€?\s*(ì‘ì„±í•œ|ì‘ì„±ì•ˆ|ê¸°ì•ˆí•œ|ì“´|ë§Œë“ )', query)
        if match:
            return match.group(1)

        # íŒ¨í„´ 3: "XXX ë¬¸ì„œ", "XXX ê¸°ì•ˆì„œ" (2-4ê¸€ì í•œê¸€ ì´ë¦„)
        match = re.search(r'([ê°€-í£]{2,4})\s*(ë¬¸ì„œ|ê¸°ì•ˆì„œ|ê¸°ì•ˆ|ê²€í† ì„œ)', query)
        if match:
            name = match.group(1)
            # ì¼ë°˜ ëª…ì‚¬ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ (ì˜ˆ: "êµ¬ë§¤ ë¬¸ì„œ"ëŠ” ì œì™¸)
            if name not in ['êµ¬ë§¤', 'ìˆ˜ë¦¬', 'ì¥ë¹„', 'ì¹´ë©”ë¼', 'ìµœê·¼', 'ìµœì‹ ', 'ì „ì²´']:
                return name

        return None

    def _log_metrics(self, metrics: dict) -> None:
        """ë‹¨ê³„ë³„ ë©”íŠ¸ë¦­ ë¡œê¹… (1í–‰ ìš”ì•½)

        Args:
            metrics: ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        """
        # 1í–‰ ìš”ì•½ ë¡œê·¸
        log_parts = []
        log_parts.append(f"total={metrics['total_ms']}ms")

        if metrics['retrieval_ms'] > 0:
            log_parts.append(f"retrieval={metrics['retrieval_ms']}ms")

        if metrics['rerank_ms'] > 0:
            log_parts.append(f"rerank={metrics['rerank_ms']}ms")

        if metrics['llm_ms'] > 0:
            log_parts.append(f"llm={metrics['llm_ms']}ms")

        log_parts.append(f"retrieved={metrics['retrieved_k']}")

        if metrics['reranked_k'] > 0:
            log_parts.append(f"reranked={metrics['reranked_k']}")

        if metrics['context_tokens'] > 0:
            log_parts.append(f"tokens={metrics['context_tokens']}")

        if metrics['fallback_reason']:
            log_parts.append(f"fallback={metrics['fallback_reason']}")

        logger.info(f"ğŸ“Š ë©”íŠ¸ë¦­: {' | '.join(log_parts)}")

    def _ensure_llm_loaded(self) -> bool:
        """LLM ë¡œë”© (ì§€ì—° ë¡œë”©)"""
        if self.llm_loaded:
            return True

        try:
            from rag_system.qwen_llm import QwenLLM
            from config import QWEN_MODEL_PATH

            logger.info("ğŸ¤– LLM ë¡œë”© ì¤‘ (ë¹ ë¥¸ ê²€ìƒ‰ ìš”ì•½ìš©)...")
            self.llm = QwenLLM(model_path=QWEN_MODEL_PATH)
            self.llm_loaded = True
            logger.info("âœ… LLM ë¡œë“œ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.warning(f"âš ï¸ LLM ë¡œë“œ ì‹¤íŒ¨ (ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜): {e}")
            return False

    def _search_by_exact_filename(self, filename: str) -> dict:
        """íŒŒì¼ëª…ìœ¼ë¡œ ì •í™•íˆ ê²€ìƒ‰

        Args:
            filename: íŒŒì¼ëª… (ì˜ˆ: "2025-03-20_ì±„ë„ì—ì´_ì¤‘ê³„ì°¨_ì¹´ë©”ë¼_ë…¸í›„í™”_ì¥ì• _ê¸´ê¸‰_ë³´ìˆ˜ê±´.pdf")

        Returns:
            íŒŒì¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì—†ìœ¼ë©´ None)
        """
        try:
            conn = sqlite3.connect('metadata.db')
            cursor = conn.cursor()

            # LIKEë¡œ ë¶€ë¶„ ë§¤ì¹­ (íŒŒì¼ëª…ì´ í¬í•¨ë˜ë©´ OK)
            cursor.execute("""
                SELECT path, filename, drafter, date, category, text_preview
                FROM documents
                WHERE filename LIKE ?
                LIMIT 1
            """, (f'%{filename}%',))

            result = cursor.fetchone()
            conn.close()

            if result:
                path, fname, drafter, date, category, text_preview = result
                return {
                    'path': path,
                    'filename': fname,
                    'drafter': drafter or 'ì •ë³´ ì—†ìŒ',
                    'date': date or 'ì •ë³´ ì—†ìŒ',
                    'category': category or 'ë¯¸ë¶„ë¥˜',
                    'content': text_preview or ''
                }
            else:
                return None

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ëª… ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    def _format_file_result(self, filename: str, file_result: dict) -> str:
        """íŒŒì¼ ê²€ìƒ‰ ê²°ê³¼ í¬ë§¤íŒ…

        Args:
            filename: ìš”ì²­í•œ íŒŒì¼ëª…
            file_result: íŒŒì¼ ì •ë³´

        Returns:
            í¬ë§¤íŒ…ëœ ë¬¸ìì—´
        """
        answer = f"**ğŸ“„ ë¬¸ì„œ:** {file_result['filename']}\n\n"

        # ë©”íƒ€ë°ì´í„°
        answer += "**ğŸ“‹ ë¬¸ì„œ ì •ë³´**\n"
        answer += f"- **ê¸°ì•ˆì:** {file_result['drafter']}\n"
        answer += f"- **ë‚ ì§œ:** {file_result['date']}\n"
        answer += f"- **ì¹´í…Œê³ ë¦¬:** {file_result['category']}\n\n"

        # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 1000ì)
        content = file_result.get('content', '')
        if content:
            answer += "**ğŸ“ ì£¼ìš” ë‚´ìš©**\n"
            content_preview = content[:1000].strip()
            answer += content_preview

            if len(content) > 1000:
                answer += "...\n\n*(ì „ì²´ ë¬¸ì„œëŠ” ë” ê¸´ ë‚´ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤)*"
        else:
            answer += "*(ë¬¸ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤)*"

        answer += f"\n\n**ğŸ“ ì¶œì²˜:** [{file_result['filename']}]"

        return answer


if __name__ == "__main__":
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    print("ğŸš€ QuickFixRAG v3 (LLM ìš”ì•½ + ì¶œì²˜ ê°•ì œ)")
    print("=" * 60)

    start = time.time()
    rag = QuickFixRAG()
    init_time = time.time() - start

    print(f"â±ï¸  ì´ˆê¸°í™” ì‹œê°„: {init_time:.4f}ì´ˆ")
    print()

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ì¹´ë©”ë¼ ìˆ˜ë¦¬",
        "HP Z8 ì›Œí¬ìŠ¤í…Œì´ì…˜ ì–¼ë§ˆ"
    ]

    for query in test_queries:
        print(f"\nğŸ“ ì§ˆë¬¸: {query}")
        print("-" * 60)

        start = time.time()
        answer = rag.answer(query)
        elapsed = time.time() - start

        print(answer[:500])
        if len(answer) > 500:
            print(f"... (ì´ {len(answer)}ì)")
        print(f"\nâ±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed:.4f}ì´ˆ")
        print("=" * 60)
