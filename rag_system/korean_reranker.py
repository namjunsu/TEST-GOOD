"""
í•œêµ­ì–´ Reranker ëª¨ë“ˆ
Dongjin-kr/ko-reranker ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì„œ ì¬ì •ë ¬
"""

from app.core.logging import get_logger
import torch
import time
import re
import hashlib
from collections import Counter
from typing import List, Dict, Any, Tuple, Optional
from functools import lru_cache
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np

try:
    from sentence_transformers import SentenceTransformer, util
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

# Reranker ì„¤ì • ìƒìˆ˜
DEFAULT_MODEL_NAME = "Dongjin-kr/ko-reranker"
MAX_TOKEN_LENGTH = 512  # í† í° ìµœëŒ€ ê¸¸ì´
JACCARD_WEIGHT = 0.7  # Jaccard ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
TF_WEIGHT = 0.3  # Term Frequency ê°€ì¤‘ì¹˜
CACHE_SIZE = 1024  # ìºì‹œ í¬ê¸°
BATCH_SIZE = 32  # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°

class KoreanReranker:
    """í•œêµ­ì–´ ë¬¸ì„œ ì¬ì •ë ¬ ëª¨ë¸"""
    
    def __init__(self, model_name: str = DEFAULT_MODEL_NAME,
                 fallback_mode: bool = True,
                 device: Optional[str] = None,
                 batch_size: int = BATCH_SIZE):
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.batch_size = batch_size
        self.logger = get_logger(__name__)
        self.fallback_mode = fallback_mode
        
        # ì˜¤í”„ë¼ì¸ í™˜ê²½ì´ë¯€ë¡œ ë°”ë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ ì‚¬ìš©
        self.use_keyword_scoring = True
        self.logger.info("ì˜¤í”„ë¼ì¸ ëª¨ë“œ: í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ ì‚¬ìš©")

        # ì„±ëŠ¥ í†µê³„
        self.rerank_count = 0
        self.total_rerank_time = 0.0
        self.cache_hits = 0
        self.cache_misses = 0
    
    def load_model(self):
        """Reranker ëª¨ë¸ ë¡œë“œ"""
        try:
            self.logger.info(f"Reranker ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = AutoModelForSequenceClassification.from_pretrained(
                self.model_name,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                device_map="auto" if self.device == "cuda" else None
            )
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
            
            self.model.eval()
            self.logger.info(f"Reranker ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {self.device})")
            
        except Exception as e:
            self.logger.error(f"Reranker ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def load_fallback_model(self):
        """ëŒ€ì•ˆ ëª¨ë¸ ë¡œë“œ (ë¡œì»¬ sentence-transformer ê¸°ë°˜)"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            self.logger.error("sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            self.use_keyword_scoring = True
            self.logger.info("í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ìœ¼ë¡œ í´ë°±")
            return
        
        try:
            self.logger.info("ëŒ€ì•ˆ Reranker ëª¨ë¸ ë¡œë”© ì¤‘: sentence-transformers ê¸°ë°˜")
            
            # ë‹¤êµ­ì–´ ëª¨ë¸ ì‚¬ìš© (í•œêµ­ì–´ ì§€ì›)
            self.sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            self.use_sentence_transformer = True
            
            self.logger.info("ëŒ€ì•ˆ Reranker ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ëŒ€ì•ˆ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§
            self.use_keyword_scoring = True
            self.logger.info("í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ìœ¼ë¡œ í´ë°±")
    
    def _get_cache_key(self, query: str, document: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        combined = f"{query}::{document[:200]}"  # ë¬¸ì„œëŠ” ì²˜ìŒ 200ìë§Œ
        return hashlib.md5(combined.encode()).hexdigest()

    @lru_cache(maxsize=CACHE_SIZE)
    def _cached_score(self, cache_key: str, query: str, document: str) -> float:
        """ìºì‹œëœ ì ìˆ˜ ê³„ì‚°"""
        return self._compute_score_internal(query, document)

    def compute_score(self, query: str, document: str) -> float:
        """ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚° (ìºì‹œ ì ìš©)"""
        cache_key = self._get_cache_key(query, document)

        # ìºì‹œ í†µê³„ ì—…ë°ì´íŠ¸
        if cache_key in self._cached_score.__wrapped__.__dict__.get('cache', {}):
            self.cache_hits += 1
        else:
            self.cache_misses += 1

        return self._cached_score(cache_key, query, document)

    def _compute_score_internal(self, query: str, document: str) -> float:
        """ì‹¤ì œ ì ìˆ˜ ê³„ì‚° ë¡œì§"""
        try:
            # ì›ë³¸ cross-encoder ëª¨ë¸ ì‚¬ìš©
            if hasattr(self, 'model') and self.model is not None:
                return self._compute_cross_encoder_score(query, document)
            
            # ëŒ€ì•ˆ sentence transformer ëª¨ë¸ ì‚¬ìš©
            elif hasattr(self, 'use_sentence_transformer'):
                return self._compute_sentence_transformer_score(query, document)
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ ì‚¬ìš©
            elif hasattr(self, 'use_keyword_scoring'):
                return self._compute_keyword_score(query, document)
            
            else:
                return 0.0
                
        except Exception as e:
            self.logger.error(f"ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _compute_cross_encoder_score(self, query: str, document: str) -> float:
        """Cross-encoder ëª¨ë¸ë¡œ ì ìˆ˜ ê³„ì‚°"""
        # ì…ë ¥ í…ìŠ¤íŠ¸ ì¤€ë¹„
        pair = [query, document]
        
        # í† í¬ë‚˜ì´ì§•
        inputs = self.tokenizer(
            pair,
            padding=True,
            truncation=True,
            max_length=MAX_TOKEN_LENGTH,
            return_tensors="pt"
        ).to(self.device)
        
        # ì ìˆ˜ ê³„ì‚°
        with torch.no_grad():
            outputs = self.model(**inputs)
            score = torch.sigmoid(outputs.logits).cpu().numpy()[0][0]
        
        return float(score)
    
    def _compute_sentence_transformer_score(self, query: str, document: str) -> float:
        """Sentence Transformerë¡œ ì ìˆ˜ ê³„ì‚° (cosine similarity)"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            return self._compute_keyword_score(query, document)
        
        # ì„ë² ë”© ìƒì„±
        query_embedding = self.sentence_model.encode([query])
        doc_embedding = self.sentence_model.encode([document])
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = util.pytorch_cos_sim(query_embedding, doc_embedding)
        score = float(similarity[0][0])
        
        # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        return (score + 1.0) / 2.0
    
    def _compute_keyword_score(self, query: str, document: str) -> float:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        # í•œê¸€ê³¼ ì˜ì–´, ìˆ«ìë§Œ ì¶”ì¶œ
        query_words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', query.lower())
        doc_words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', document.lower())
        
        if not query_words:
            return 0.0
        
        # êµì§‘í•© ë‹¨ì–´ ê°œìˆ˜
        query_set = set(query_words)
        doc_set = set(doc_words)
        intersection = len(query_set.intersection(doc_set))
        
        # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
        union = len(query_set.union(doc_set))
        jaccard_score = intersection / union if union > 0 else 0.0
        
        # TF ê°€ì¤‘ì¹˜ ì¶”ê°€
        doc_counter = Counter(doc_words)
        tf_score = sum(doc_counter.get(word, 0) for word in query_words)
        if len(doc_words) > 0:
            tf_score = tf_score / len(doc_words)
        else:
            tf_score = 0.0
        
        # ìµœì¢… ì ìˆ˜ (Jaccard + TF)
        final_score = JACCARD_WEIGHT * jaccard_score + TF_WEIGHT * tf_score
        
        return min(max(final_score, 0.0), 1.0)
    
    def compute_batch_scores(self, query: str, documents: List[str]) -> List[float]:
        """ë°°ì¹˜ë¡œ ì—¬ëŸ¬ ë¬¸ì„œì˜ ì ìˆ˜ë¥¼ ê³„ì‚°"""
        try:
            # ê° ë¬¸ì„œì— ëŒ€í•´ ê°œë³„ ì ìˆ˜ ê³„ì‚°
            all_scores = []
            for doc in documents:
                score = self.compute_score(query, doc)
                all_scores.append(score)
            
            return all_scores
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return [0.0] * len(documents)
    
    def rerank(
        self,
        query: str,
        search_results: List[Dict[str, Any]],
        top_k: int = None
    ) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬ì •ë ¬ (rerank_documentsì˜ ë³„ì¹­)"""
        return self.rerank_documents(query, search_results, top_k)
    
    def rerank_documents(
        self, 
        query: str, 
        search_results: List[Dict[str, Any]], 
        top_k: int = None
    ) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬ì •ë ¬"""
        if not search_results:
            return search_results
        
        start_time = time.time()
        
        try:
            # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            documents = [result.get('content', '') for result in search_results]
            
            # ë°°ì¹˜ ì ìˆ˜ ê³„ì‚°
            rerank_scores = self.compute_batch_scores(query, documents)
            
            # ì›ë³¸ ê²°ê³¼ì— rerank ì ìˆ˜ ì¶”ê°€
            for i, result in enumerate(search_results):
                result['rerank_score'] = rerank_scores[i]
                result['original_rank'] = i + 1
            
            # rerank ì ìˆ˜ë¡œ ì¬ì •ë ¬
            reranked_results = sorted(
                search_results, 
                key=lambda x: x['rerank_score'], 
                reverse=True
            )
            
            # ìƒˆë¡œìš´ ìˆœìœ„ ë¶€ì—¬
            for i, result in enumerate(reranked_results):
                result['rerank_rank'] = i + 1
            
            # ìƒìœ„ Kê°œë§Œ ë°˜í™˜
            if top_k is not None:
                reranked_results = reranked_results[:top_k]
            
            rerank_time = time.time() - start_time

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.rerank_count += 1
            self.total_rerank_time += rerank_time

            self.logger.info(
                f"ë¬¸ì„œ ì¬ì •ë ¬ ì™„ë£Œ: {len(search_results)}ê°œ â†’ {len(reranked_results)}ê°œ "
                f"(ì‹œê°„: {rerank_time:.3f}ì´ˆ, ìºì‹œ íˆíŠ¸ìœ¨: {self.cache_hits/(self.cache_hits+self.cache_misses)*100:.1f}%)"
            )
            
            return reranked_results
            
        except Exception as e:
            self.logger.error(f"ë¬¸ì„œ ì¬ì •ë ¬ ì‹¤íŒ¨: {e}")
            return search_results

    def get_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = {
            'rerank_count': self.rerank_count,
            'total_rerank_time': self.total_rerank_time,
            'avg_rerank_time': self.total_rerank_time / self.rerank_count if self.rerank_count > 0 else 0.0,
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'cache_hit_rate': self.cache_hits / (self.cache_hits + self.cache_misses) * 100 if (self.cache_hits + self.cache_misses) > 0 else 0.0,
            'cached_score_info': self._cached_score.cache_info() if hasattr(self._cached_score, 'cache_info') else None
        }
        return stats

    def get_reranking_analysis(self, reranked_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì¬ì •ë ¬ ë¶„ì„ ì •ë³´ ì œê³µ"""
        if not reranked_results:
            return {}
        
        # ìˆœìœ„ ë³€ë™ ë¶„ì„
        rank_changes = []
        for result in reranked_results:
            original_rank = result.get('original_rank', 0)
            rerank_rank = result.get('rerank_rank', 0)
            change = original_rank - rerank_rank  # ì–‘ìˆ˜ë©´ ìˆœìœ„ ìƒìŠ¹
            rank_changes.append(change)
        
        # ì ìˆ˜ í†µê³„
        rerank_scores = [r.get('rerank_score', 0.0) for r in reranked_results]
        
        analysis = {
            'total_documents': len(reranked_results),
            'rank_changes': {
                'improved': len([c for c in rank_changes if c > 0]),
                'degraded': len([c for c in rank_changes if c < 0]),
                'unchanged': len([c for c in rank_changes if c == 0]),
                'max_improvement': max(rank_changes) if rank_changes else 0,
                'max_degradation': min(rank_changes) if rank_changes else 0
            },
            'score_stats': {
                'mean_score': np.mean(rerank_scores) if rerank_scores else 0.0,
                'max_score': max(rerank_scores) if rerank_scores else 0.0,
                'min_score': min(rerank_scores) if rerank_scores else 0.0,
                'std_score': np.std(rerank_scores) if rerank_scores else 0.0
            }
        }
        
        return analysis

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_korean_reranker():
    """í•œêµ­ì–´ Reranker í…ŒìŠ¤íŠ¸"""
    print("ğŸ”„ í•œêµ­ì–´ Reranker í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Reranker ì´ˆê¸°í™”
        reranker = KoreanReranker()
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì™€ ë¬¸ì„œë“¤
        test_query = "HP Z8 ì›Œí¬ìŠ¤í…Œì´ì…˜ ê°€ê²©"
        test_documents = [
            {
                'content': 'ê´‘í™”ë¬¸ ìŠ¤íŠœë””ì˜¤ ëª¨ë‹ˆí„° êµì²´ ì´ì•¡ì€ 9,760,000ì›ì…ë‹ˆë‹¤.',
                'filename': '2025-01-09_ê´‘í™”ë¬¸ìŠ¤íŠœë””ì˜¤ëª¨ë‹ˆí„°êµì²´.pdf',
                'score': 5.2
            },
            {
                'content': 'HP Z8 ì›Œí¬ìŠ¤í…Œì´ì…˜ ì´ ê¸ˆì•¡ì€ 179,300,000ì›ì…ë‹ˆë‹¤. ì˜ìƒí¸ì§‘ìš©ì…ë‹ˆë‹¤.',
                'filename': '2022-02-03_HPì›Œí¬ìŠ¤í…Œì´ì…˜êµì²´.pdf', 
                'score': 4.8
            },
            {
                'content': 'í•€ë§ˆì´í¬ ëª¨ë¸ ECM-77BC ê°€ê²©ì€ 336,000ì›ì…ë‹ˆë‹¤.',
                'filename': '2021-05-13_í•€ë§ˆì´í¬êµ¬ë§¤.pdf',
                'score': 3.1
            }
        ]
        
        print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
        print(f"ğŸ“„ ë¬¸ì„œ ìˆ˜: {len(test_documents)}")
        
        # ì¬ì •ë ¬ ìˆ˜í–‰
        reranked = reranker.rerank_documents(test_query, test_documents.copy())
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ì¬ì •ë ¬ ê²°ê³¼:")
        for i, result in enumerate(reranked):
            print(f"  {i+1}ìœ„: {result['filename']}")
            print(f"      ì›ë³¸ ìˆœìœ„: {result['original_rank']} â†’ ì¬ì •ë ¬: {result['rerank_rank']}")
            print(f"      ì›ë³¸ ì ìˆ˜: {result['score']:.2f} â†’ Rerank ì ìˆ˜: {result['rerank_score']:.4f}")
            print(f"      ë‚´ìš©: {result['content'][:50]}...")
            print()
        
        # ë¶„ì„ ì •ë³´
        analysis = reranker.get_reranking_analysis(reranked)
        print("ğŸ“ˆ ì¬ì •ë ¬ ë¶„ì„:")
        print(f"  ìˆœìœ„ ê°œì„ : {analysis['rank_changes']['improved']}ê°œ")
        print(f"  ìˆœìœ„ í•˜ë½: {analysis['rank_changes']['degraded']}ê°œ") 
        print(f"  í‰ê·  ì ìˆ˜: {analysis['score_stats']['mean_score']:.4f}")
        print(f"  ìµœê³  ì ìˆ˜: {analysis['score_stats']['max_score']:.4f}")
        
        print("âœ… í•œêµ­ì–´ Reranker í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ í•œêµ­ì–´ Reranker í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    test_korean_reranker()