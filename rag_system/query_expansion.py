"""
ì¿¼ë¦¬ í™•ì¥ (Query Expansion) ëª¨ë“ˆ
Advanced RAG ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ, ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í™•ì¥í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ

YAML ê¸°ë°˜ ì„¤ì •ìœ¼ë¡œ í•˜ë“œì½”ë”© ì œê±°
"""

from app.core.logging import get_logger
import time
import hashlib
import yaml
import os
from pathlib import Path
from functools import lru_cache
from typing import List, Dict, Any, Set, Tuple, Optional
import re
from collections import defaultdict


class QueryExpansion:
    """ì¿¼ë¦¬ í™•ì¥ ëª¨ë“ˆ (YAML ê¸°ë°˜)"""

    # ìƒìˆ˜ ì •ì˜
    MAX_SYNONYMS_EXPANSIONS = 3
    MAX_PATTERN_EXPANSIONS = 2
    MAX_MORPHOLOGY_EXPANSIONS = 2
    DEFAULT_METHODS = ['synonyms', 'abbreviations', 'patterns', 'morphology']
    WORD_PATTERN = r'[ê°€-í£a-zA-Z0-9]+'
    CONFIG_FILE = "config/query_expansion.yaml"

    def __init__(self, config_path: Optional[str] = None):
        self.logger = get_logger(__name__)

        # ì„¤ì • íŒŒì¼ ê²½ë¡œ
        if config_path is None:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
            project_root = Path(__file__).parent.parent
            self.config_path = project_root / self.CONFIG_FILE
        else:
            self.config_path = Path(config_path)

        # ì„¤ì • ë¡œë“œ
        self.config = {}
        self.synonyms = {}
        self.abbreviations = {}
        self.expansion_patterns = {}
        self.rules = []
        self.performance_config = {}

        # íŒŒì¼ ë³€ê²½ ê°ì§€ìš©
        self.config_mtime = 0
        self.last_check_time = 0

        # ì´ˆê¸° ì„¤ì • ë¡œë“œ
        self._load_config()

        # ì„±ëŠ¥ í†µê³„
        self.expansion_count = 0
        self.total_expansion_time = 0.0
        self.method_usage = defaultdict(int)
        self.cache_hits = 0
        self.cache_misses = 0

        # í˜•íƒœì†Œ íŒ¨í„´ ì´ˆê¸°í™”
        self._init_morphology_patterns()
        self._compile_patterns()

    def _load_config(self) -> bool:
        """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            if not self.config_path.exists():
                self.logger.warning(f"ì„¤ì • íŒŒì¼ ì—†ìŒ: {self.config_path}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                self._use_default_config()
                return False

            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f) or {}

            # ë™ì˜ì–´ ë¡œë“œ
            self.synonyms = {}
            if 'synonyms' in self.config:
                for key, values in self.config['synonyms'].items():
                    if isinstance(values, list):
                        self.synonyms[key] = values
                    else:
                        self.logger.warning(f"ì˜ëª»ëœ ë™ì˜ì–´ í˜•ì‹: {key}")

            # ê·œì¹™ ë¡œë“œ
            self.rules = self.config.get('rules', [])

            # ì„±ëŠ¥ ì„¤ì • ë¡œë“œ
            self.performance_config = self.config.get('performance', {
                'cache_ttl': 3600,
                'hot_reload_interval': 60,
                'max_expansions': 10
            })

            # í˜•íƒœì†Œ íŒ¨í„´ ì„¤ì • ë¡œë“œ
            morpheme_config = self.config.get('morpheme_patterns', {})
            self.morpheme_enabled = morpheme_config.get('noun_verb', {}).get('enabled', True)

            # íŒŒì¼ mtime ê°±ì‹ 
            self.config_mtime = self.config_path.stat().st_mtime

            self.logger.info(
                f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {len(self.synonyms)}ê°œ ë™ì˜ì–´ ê·¸ë£¹, "
                f"{len(self.rules)}ê°œ ê·œì¹™"
            )
            return True

        except Exception as e:
            self.logger.error(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            self._use_default_config()
            return False

    def _use_default_config(self):
        """ê¸°ë³¸ ì„¤ì • ì‚¬ìš© (YAML ë¡œë“œ ì‹¤íŒ¨ ì‹œ fallback)"""
        self.synonyms = {
            'êµ¬ë§¤': ['êµ¬ë§¤', 'êµ¬ì…', 'ë°œì£¼', 'ë§¤ì…'],
            'ìˆ˜ë¦¬': ['ìˆ˜ë¦¬', 'ì •ë¹„', 'ë³´ìˆ˜', 'ìˆ˜ì„ '],
            'ì¹´ë©”ë¼': ['ì¹´ë©”ë¼', 'ìº ', 'ì´¬ì˜ê¸°'],
        }
        self.abbreviations = {
            'ENG': 'ë‰´ìŠ¤ì·¨ì¬',
            'LED': 'ë°œê´‘ë‹¤ì´ì˜¤ë“œ'
        }
        self.expansion_patterns = {
            'ìµœê·¼': ['ìµœê·¼', 'ìµœì‹ ', 'ì‹ ê·œ']
        }
        self.rules = []
        self.performance_config = {
            'cache_ttl': 3600,
            'hot_reload_interval': 60,
            'max_expansions': 10
        }
        self.logger.warning("ê¸°ë³¸ ì„¤ì • ì‚¬ìš© ì¤‘ (ì œí•œëœ ë™ì˜ì–´)")

    def _check_and_reload(self) -> bool:
        """ì„¤ì • íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ì¬ë¡œë“œ (hot reload)"""
        try:
            # hot_reload_interval í™•ì¸
            reload_interval = self.performance_config.get('hot_reload_interval', 60)
            current_time = time.time()

            if current_time - self.last_check_time < reload_interval:
                return False

            self.last_check_time = current_time

            # íŒŒì¼ mtime í™•ì¸
            if not self.config_path.exists():
                return False

            current_mtime = self.config_path.stat().st_mtime
            if current_mtime > self.config_mtime:
                self.logger.info("ì„¤ì • íŒŒì¼ ë³€ê²½ ê°ì§€, ì¬ë¡œë“œ ì¤‘...")
                # ìºì‹œ í´ë¦¬ì–´
                if hasattr(self._expand_query_cached, 'cache_clear'):
                    self._expand_query_cached.cache_clear()
                # ì„¤ì • ì¬ë¡œë“œ
                success = self._load_config()
                if success:
                    # íŒ¨í„´ ì¬ì»´íŒŒì¼
                    self._compile_patterns()
                    self.logger.info("ì„¤ì • ì¬ë¡œë“œ ì™„ë£Œ")
                return success

            return False

        except Exception as e:
            self.logger.error(f"ì¬ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _init_morphology_patterns(self):
        """í˜•íƒœì†Œ ë³€í˜• íŒ¨í„´ ì´ˆê¸°í™”"""
        self.morphology_patterns = [
            (r'(\w+)ì„', r'\1ë¥¼'),
            (r'(\w+)ë¥¼', r'\1ì„'),
            (r'(\w+)ì´', r'\1ê°€'),
            (r'(\w+)ê°€', r'\1ì´'),
            (r'(\w+)ì€', r'\1ëŠ”'),
            (r'(\w+)ëŠ”', r'\1ì€'),
            (r'(\w+)ì—ì„œ', r'\1ì˜'),
            (r'(\w+)ì˜', r'\1ì—ì„œ')
        ]

    def _compile_patterns(self):
        """ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼"""
        # ë‹¨ì–´ ì¶”ì¶œ íŒ¨í„´ ì»´íŒŒì¼
        self.compiled_word_pattern = re.compile(self.WORD_PATTERN)

        # í˜•íƒœì†Œ íŒ¨í„´ ì»´íŒŒì¼
        self.compiled_morphology = [(re.compile(p), r) for p, r in self.morphology_patterns]

        # ë™ì˜ì–´ ì—­ ì¸ë±ìŠ¤ êµ¬ì¶• (ë¹ ë¥¸ ê²€ìƒ‰ìš©)
        self.synonym_index = {}
        for key, synonyms in self.synonyms.items():
            for synonym in synonyms:
                synonym_lower = synonym.lower()
                if synonym_lower not in self.synonym_index:
                    self.synonym_index[synonym_lower] = []
                self.synonym_index[synonym_lower].append(key)

        self.logger.info(
            f"íŒ¨í„´ ì»´íŒŒì¼ ì™„ë£Œ: {len(self.compiled_morphology)}ê°œ í˜•íƒœì†Œ íŒ¨í„´, "
            f"{len(self.synonym_index)}ê°œ ë™ì˜ì–´ ì¸ë±ìŠ¤"
        )

    def expand_query(self, query: str, methods: List[str] = None) -> Dict[str, Any]:
        """ì¿¼ë¦¬ë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í™•ì¥ (ìºì‹±ë¨)"""
        # hot reload ì²´í¬
        self._check_and_reload()

        if methods is None:
            methods = self.DEFAULT_METHODS

        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = hashlib.md5(f"{query}:{':'.join(sorted(methods))}".encode()).hexdigest()
        return self._expand_query_cached(cache_key, query, tuple(methods))

    @lru_cache(maxsize=512)
    def _expand_query_cached(self, cache_key: str, query: str, methods: Tuple[str]) -> Dict[str, Any]:
        """ì‹¤ì œ ì¿¼ë¦¬ í™•ì¥ (ìºì‹±ë¨)"""
        start_time = time.time()
        methods = list(methods)  # íŠœí”Œì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

        expansion_result = {
            'original_query': query,
            'expanded_queries': [],
            'expansion_methods': {},  # ë©”ì„œë“œë³„ë¡œ í™•ì¥ ê²°ê³¼ ì €ì¥
            'methods_used': methods,
            'processing_time': 0.0
        }

        try:
            # í™•ì¥ ë©”ì„œë“œ ë§¤í•‘
            expansion_methods = {
                'synonyms': self._expand_with_synonyms,
                'abbreviations': self._expand_abbreviations,
                'patterns': self._expand_with_patterns,
                'morphology': self._expand_morphology
            }

            # ê° ë©”ì„œë“œ ì‹¤í–‰
            for method in methods:
                if method in expansion_methods:
                    method_expansions = expansion_methods[method](query)
                    expansion_result['expansion_methods'][method] = method_expansions
                    expansion_result['expanded_queries'].extend(method_expansions)

            # ì¤‘ë³µ ì œê±°
            unique_queries = []
            seen = set()
            for q in [query] + expansion_result['expanded_queries']:
                if q not in seen:
                    unique_queries.append(q)
                    seen.add(q)

            expansion_result['expanded_queries'] = unique_queries[1:]  # ì›ë³¸ ì œì™¸
            expansion_result['total_queries'] = len(unique_queries)
            expansion_result['processing_time'] = time.time() - start_time

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.expansion_count += 1
            self.total_expansion_time += expansion_result['processing_time']
            for method in methods:
                self.method_usage[method] += 1

            self.logger.info(
                f"ì¿¼ë¦¬ í™•ì¥ ì™„ë£Œ: '{query}' â†’ {len(unique_queries)}ê°œ ì¿¼ë¦¬ "
                f"(ì‹œê°„: {expansion_result['processing_time']:.3f}ì´ˆ)"
            )

            return expansion_result

        except Exception as e:
            self.logger.error(f"ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            expansion_result['processing_time'] = time.time() - start_time
            return expansion_result

    def _expand_with_synonyms(self, query: str) -> List[str]:
        """ë™ì˜ì–´ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥ (YAML ê¸°ë°˜, ìµœì í™”)"""
        expanded = []
        words = self.compiled_word_pattern.findall(query)

        # ë™ì˜ì–´ ì¸ë±ìŠ¤ í™œìš©
        for word in words:
            word_lower = word.lower()
            if word_lower in self.synonym_index:
                # í•´ë‹¹ ë‹¨ì–´ê°€ ì†í•œ ë™ì˜ì–´ ê·¸ë£¹ë“¤ì„ ì°¾ìŒ
                for synonym_key in self.synonym_index[word_lower]:
                    if synonym_key in self.synonyms:
                        for synonym in self.synonyms[synonym_key]:
                            if synonym.lower() != word_lower:  # ì›ë³¸ê³¼ ë‹¤ë¥¸ ê²½ìš°ë§Œ
                                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì¹˜í™˜
                                new_query = re.sub(
                                    re.escape(word),
                                    synonym,
                                    query,
                                    flags=re.IGNORECASE
                                )
                                if new_query != query and new_query not in expanded:
                                    expanded.append(new_query)

        max_expansions = self.performance_config.get('max_expansions', 10)
        return self._limit_expansions(expanded, min(self.MAX_SYNONYMS_EXPANSIONS, max_expansions))

    def _expand_abbreviations(self, query: str) -> List[str]:
        """ì•½ì–´ í™•ì¥ (í˜„ì¬ëŠ” ë¹„í™œì„±, YAML ì¶”ê°€ ì‹œ í™œì„±í™” ê°€ëŠ¥)"""
        expanded = []

        # abbreviationsê°€ ì„¤ì •ì— ìˆë‹¤ë©´ ì‚¬ìš©
        abbreviations = self.config.get('abbreviations', {})
        for abbr, full_form in abbreviations.items():
            if abbr in query:
                expanded_query = query.replace(abbr, full_form)
                expanded.append(expanded_query)
            elif full_form in query:
                expanded_query = query.replace(full_form, abbr)
                expanded.append(expanded_query)

        return expanded

    def _expand_with_patterns(self, query: str) -> List[str]:
        """íŒ¨í„´ ê¸°ë°˜ í™•ì¥ (YAML rules ê¸°ë°˜)"""
        expanded = []

        # YAML rules ì ìš©
        for rule in self.rules:
            match_keywords = rule.get('match', [])
            boosts = rule.get('boosts', {})

            # ë§¤ì¹˜ë˜ëŠ” í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            for keyword in match_keywords:
                if keyword in query:
                    # ë‚ ì§œ ê´€ë ¨ ê·œì¹™ ì²˜ë¦¬
                    if boosts.get('date_desc'):
                        # í˜„ì¬ ë…„ë„/ì‹ ê·œ í‚¤ì›Œë“œ ì¶”ê°€
                        current_year = time.strftime("%Y")
                        alternatives = ['ìµœì‹ ', 'ì‹ ê·œ', current_year]
                        for alt in alternatives:
                            if alt not in query:
                                new_query = f"{query} {alt}"
                                if new_query not in expanded:
                                    expanded.append(new_query)

                    # top_k override ì²˜ë¦¬
                    if 'top_k_override' in boosts:
                        # ë©”íƒ€ë°ì´í„°ì— ì €ì¥ (ì‹¤ì œ ê²€ìƒ‰ ì‹œ ì‚¬ìš©)
                        pass

                    break

        max_expansions = self.performance_config.get('max_expansions', 10)
        return self._limit_expansions(expanded, min(self.MAX_PATTERN_EXPANSIONS, max_expansions))

    def _expand_morphology(self, query: str) -> List[str]:
        """í˜•íƒœì†Œ ê¸°ë°˜ í™•ì¥ (í•œêµ­ì–´ íŠ¹í™”, ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)"""
        if not self.morpheme_enabled:
            return []

        expanded = []

        for pattern, replacement in self.compiled_morphology:
            new_query = pattern.sub(replacement, query)
            if new_query != query and new_query not in expanded:
                expanded.append(new_query)

        return self._limit_expansions(expanded, self.MAX_MORPHOLOGY_EXPANSIONS)

    def get_expansion_statistics(self, expansion_result: Dict[str, Any]) -> Dict[str, Any]:
        """í™•ì¥ í†µê³„ ì •ë³´"""
        stats = {
            'original_length': len(expansion_result['original_query']),
            'total_expansions': len(expansion_result['expanded_queries']),
            'methods_breakdown': {},
            'processing_time': expansion_result['processing_time'],
            'expansion_ratio': 0.0
        }

        # ë°©ë²•ë³„ í†µê³„
        if 'expansion_methods' in expansion_result:
            for method, expansions in expansion_result['expansion_methods'].items():
                stats['methods_breakdown'][method] = len(expansions)

        # í™•ì¥ ë¹„ìœ¨
        if expansion_result['original_query']:
            total_chars = sum(len(q) for q in expansion_result['expanded_queries'])
            stats['expansion_ratio'] = total_chars / len(expansion_result['original_query'])

        return stats

    def _limit_expansions(self, expansions: List[str], max_count: int) -> List[str]:
        """í™•ì¥ ê²°ê³¼ë¥¼ ìµœëŒ€ ê°œìˆ˜ë¡œ ì œí•œ"""
        return expansions[:max_count]

    def get_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = {
            'expansion_count': self.expansion_count,
            'total_expansion_time': self.total_expansion_time,
            'avg_expansion_time': self.total_expansion_time / self.expansion_count if self.expansion_count > 0 else 0.0,
            'method_usage': dict(self.method_usage),
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'cache_hit_rate': self.cache_hits / (self.cache_hits + self.cache_misses) * 100 if (self.cache_hits + self.cache_misses) > 0 else 0.0,
            'cache_info': self._expand_query_cached.cache_info() if hasattr(self._expand_query_cached, 'cache_info') else None,
            'synonym_index_size': len(self.synonym_index),
            'compiled_patterns': len(self.compiled_morphology),
            'config_loaded': len(self.synonyms) > 0,
            'config_path': str(self.config_path),
            'hot_reload_enabled': self.performance_config.get('hot_reload_interval', 0) > 0
        }
        return stats


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_query_expansion():
    """ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ (YAML ê¸°ë°˜)"""
    print("ğŸ” ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ (YAML ê¸°ë°˜)")

    try:
        # ì¿¼ë¦¬ í™•ì¥ê¸° ì´ˆê¸°í™”
        expander = QueryExpansion()

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "DVR êµ¬ë§¤ ìµœê·¼ ë¬¸ì„œ",
            "ë…¹í™”ê¸° ë°œì£¼ ë‚´ì—­",
            "ì¹´ë©”ë¼ ìˆ˜ë¦¬ ê±´",
            "LED ì¡°ëª… ìµœì‹ ",
            "êµ¬ë§¤í–ˆë˜ ì¥ë¹„"
        ]

        for query in test_queries:
            print(f"\nğŸ” ì›ë³¸ ì¿¼ë¦¬: '{query}'")

            # ì¿¼ë¦¬ í™•ì¥
            result = expander.expand_query(query)

            print(f"ğŸ“Š í™•ì¥ëœ ì¿¼ë¦¬ ìˆ˜: {len(result['expanded_queries'])}")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")

            # í™•ì¥ëœ ì¿¼ë¦¬ë“¤ ì¶œë ¥
            for i, expanded in enumerate(result['expanded_queries'][:5], 1):
                # ì–´ëŠ ë©”ì„œë“œì—ì„œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì°¾ê¸°
                method_name = 'unknown'
                if 'expansion_methods' in result:
                    for method, expansions in result['expansion_methods'].items():
                        if expanded in expansions:
                            method_name = method
                            break
                print(f"  {i}. [{method_name}] {expanded}")

            # í†µê³„ ì •ë³´
            stats = expander.get_expansion_statistics(result)
            print(f"ğŸ“ˆ ë°©ë²•ë³„ í™•ì¥ ìˆ˜: {stats['methods_breakdown']}")

        # ì „ì²´ í†µê³„
        print("\n" + "="*60)
        overall_stats = expander.get_stats()
        print(f"ğŸ“Š ì „ì²´ í†µê³„:")
        print(f"  - ì„¤ì • ë¡œë“œë¨: {overall_stats['config_loaded']}")
        print(f"  - ë™ì˜ì–´ ì¸ë±ìŠ¤ í¬ê¸°: {overall_stats['synonym_index_size']}")
        print(f"  - Hot reload í™œì„±: {overall_stats['hot_reload_enabled']}")

        print("\nâœ… ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True

    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    test_query_expansion()
