#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
========================
ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import psutil
import time
from datetime import datetime, timedelta
import json
from pathlib import Path
import threading
import queue
from typing import Dict, List, Any
import numpy as np

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI-CHAT ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.metrics_queue = queue.Queue()
        self.history = {
            'timestamps': [],
            'cpu': [],
            'memory': [],
            'disk': [],
            'network_in': [],
            'network_out': [],
            'queries_per_second': [],
            'cache_hits': [],
            'response_times': []
        }
        self.max_history = 100
        self.collecting = False
        self.thread = None

    def start_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        if not self.collecting:
            self.collecting = True
            self.thread = threading.Thread(target=self._collect_loop, daemon=True)
            self.thread.start()

    def stop_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€"""
        self.collecting = False
        if self.thread:
            self.thread.join(timeout=2)

    def _collect_loop(self):
        """ìˆ˜ì§‘ ë£¨í”„"""
        while self.collecting:
            metrics = self._get_current_metrics()
            self.metrics_queue.put(metrics)
            self._update_history(metrics)
            time.sleep(1)

    def _get_current_metrics(self) -> Dict:
        """í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        # CPU
        cpu_percent = psutil.cpu_percent(interval=0.1)
        cpu_cores = psutil.cpu_percent(percpu=True)

        # ë©”ëª¨ë¦¬
        memory = psutil.virtual_memory()
        swap = psutil.swap_memory()

        # ë””ìŠ¤í¬
        disk = psutil.disk_usage('/')
        disk_io = psutil.disk_io_counters()

        # ë„¤íŠ¸ì›Œí¬
        net_io = psutil.net_io_counters()

        # GPU (if available)
        try:
            import GPUtil
            gpus = GPUtil.getGPUs()
            gpu_data = {
                'gpu_load': gpus[0].load * 100 if gpus else 0,
                'gpu_memory': gpus[0].memoryUtil * 100 if gpus else 0,
                'gpu_temp': gpus[0].temperature if gpus else 0
            }
        except:
            gpu_data = {'gpu_load': 0, 'gpu_memory': 0, 'gpu_temp': 0}

        # í”„ë¡œì„¸ìŠ¤
        processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            if proc.info['memory_percent'] > 1:  # 1% ì´ìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©
                processes.append(proc.info)

        # ìºì‹œ ë° ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì‹œë®¬ë ˆì´ì…˜)
        cache_hits = np.random.randint(70, 95)
        qps = np.random.uniform(5, 20)
        response_time = np.random.uniform(0.1, 2.0)

        return {
            'timestamp': datetime.now().isoformat(),
            'cpu': {
                'percent': cpu_percent,
                'cores': cpu_cores,
                'count': psutil.cpu_count()
            },
            'memory': {
                'percent': memory.percent,
                'used_gb': memory.used / (1024**3),
                'total_gb': memory.total / (1024**3),
                'available_gb': memory.available / (1024**3),
                'swap_percent': swap.percent
            },
            'disk': {
                'percent': disk.percent,
                'used_gb': disk.used / (1024**3),
                'total_gb': disk.total / (1024**3),
                'read_mb': disk_io.read_bytes / (1024**2),
                'write_mb': disk_io.write_bytes / (1024**2)
            },
            'network': {
                'sent_mb': net_io.bytes_sent / (1024**2),
                'recv_mb': net_io.bytes_recv / (1024**2),
                'packets_sent': net_io.packets_sent,
                'packets_recv': net_io.packets_recv
            },
            'gpu': gpu_data,
            'processes': sorted(processes, key=lambda x: x['memory_percent'], reverse=True)[:5],
            'performance': {
                'cache_hit_rate': cache_hits,
                'queries_per_second': qps,
                'avg_response_time': response_time
            }
        }

    def _update_history(self, metrics: Dict):
        """íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""
        self.history['timestamps'].append(datetime.now())
        self.history['cpu'].append(metrics['cpu']['percent'])
        self.history['memory'].append(metrics['memory']['percent'])
        self.history['disk'].append(metrics['disk']['percent'])
        self.history['network_in'].append(metrics['network']['recv_mb'])
        self.history['network_out'].append(metrics['network']['sent_mb'])
        self.history['queries_per_second'].append(metrics['performance']['queries_per_second'])
        self.history['cache_hits'].append(metrics['performance']['cache_hit_rate'])
        self.history['response_times'].append(metrics['performance']['avg_response_time'])

        # í¬ê¸° ì œí•œ
        for key in self.history:
            if len(self.history[key]) > self.max_history:
                self.history[key].pop(0)

    def get_latest_metrics(self) -> Dict:
        """ìµœì‹  ë©”íŠ¸ë¦­ ë°˜í™˜"""
        try:
            return self.metrics_queue.get_nowait()
        except queue.Empty:
            return None


def create_gauge_chart(value: float, title: str, max_value: float = 100) -> go.Figure:
    """ê²Œì´ì§€ ì°¨íŠ¸ ìƒì„±"""
    if value < 50:
        color = "green"
    elif value < 80:
        color = "yellow"
    else:
        color = "red"

    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=value,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': title},
        delta={'reference': 50},
        gauge={
            'axis': {'range': [None, max_value]},
            'bar': {'color': color},
            'steps': [
                {'range': [0, 50], 'color': "lightgray"},
                {'range': [50, 80], 'color': "gray"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 90
            }
        }
    ))

    fig.update_layout(height=200, margin=dict(l=20, r=20, t=40, b=20))
    return fig


def create_time_series_chart(history: Dict, keys: List[str], title: str) -> go.Figure:
    """ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()

    for key in keys:
        if key in history and history[key]:
            fig.add_trace(go.Scatter(
                x=history['timestamps'],
                y=history[key],
                mode='lines',
                name=key.replace('_', ' ').title(),
                line=dict(width=2)
            ))

    fig.update_layout(
        title=title,
        xaxis_title="ì‹œê°„",
        yaxis_title="ê°’",
        hovermode='x unified',
        height=300,
        showlegend=True
    )

    return fig


def create_process_table(processes: List[Dict]) -> pd.DataFrame:
    """í”„ë¡œì„¸ìŠ¤ í…Œì´ë¸” ìƒì„±"""
    if not processes:
        return pd.DataFrame()

    df = pd.DataFrame(processes)
    df = df[['name', 'pid', 'cpu_percent', 'memory_percent']]
    df.columns = ['í”„ë¡œì„¸ìŠ¤', 'PID', 'CPU %', 'ë©”ëª¨ë¦¬ %']
    df['CPU %'] = df['CPU %'].round(1)
    df['ë©”ëª¨ë¦¬ %'] = df['ë©”ëª¨ë¦¬ %'].round(1)

    return df


def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""

    # í—¤ë”
    st.title("ğŸ¯ AI-CHAT ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")

    # ìƒíƒœ í‘œì‹œì¤„
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì‹œìŠ¤í…œ ìƒíƒœ", "âœ… ì •ìƒ", delta="ì•ˆì •ì ")
    with col2:
        st.metric("ê°€ë™ ì‹œê°„", "12ì‹œê°„ 34ë¶„", delta="+2ì‹œê°„")
    with col3:
        st.metric("í™œì„± ì„¸ì…˜", "3", delta="+1")
    with col4:
        st.metric("ì´ ì¿¼ë¦¬", "1,234", delta="+56")

    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    if 'collector' not in st.session_state:
        st.session_state.collector = MetricsCollector()
        st.session_state.collector.start_collection()

    collector = st.session_state.collector

    # ìë™ ìƒˆë¡œê³ ì¹¨
    placeholder = st.empty()

    with placeholder.container():
        # ìµœì‹  ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
        metrics = collector._get_current_metrics()

        if metrics:
            # íƒ­ ìƒì„±
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ“Š ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤",
                "âš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­",
                "ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„",
                "ğŸ” í”„ë¡œì„¸ìŠ¤ ìƒì„¸",
                "âš ï¸ ì•Œë¦¼ & ë¡œê·¸"
            ])

            with tab1:
                # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê²Œì´ì§€
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    fig_cpu = create_gauge_chart(
                        metrics['cpu']['percent'],
                        "CPU ì‚¬ìš©ë¥ "
                    )
                    st.plotly_chart(fig_cpu, use_container_width=True)

                with col2:
                    fig_memory = create_gauge_chart(
                        metrics['memory']['percent'],
                        "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ "
                    )
                    st.plotly_chart(fig_memory, use_container_width=True)

                with col3:
                    fig_disk = create_gauge_chart(
                        metrics['disk']['percent'],
                        "ë””ìŠ¤í¬ ì‚¬ìš©ë¥ "
                    )
                    st.plotly_chart(fig_disk, use_container_width=True)

                with col4:
                    fig_gpu = create_gauge_chart(
                        metrics['gpu']['gpu_load'],
                        "GPU ì‚¬ìš©ë¥ "
                    )
                    st.plotly_chart(fig_gpu, use_container_width=True)

                # ìƒì„¸ ì •ë³´
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ğŸ’» ì‹œìŠ¤í…œ ì •ë³´")
                    st.json({
                        "CPU ì½”ì–´": metrics['cpu']['count'],
                        "ì´ ë©”ëª¨ë¦¬": f"{metrics['memory']['total_gb']:.1f} GB",
                        "ì‚¬ìš© ë©”ëª¨ë¦¬": f"{metrics['memory']['used_gb']:.1f} GB",
                        "ë””ìŠ¤í¬ ì´ëŸ‰": f"{metrics['disk']['total_gb']:.1f} GB",
                        "ë””ìŠ¤í¬ ì‚¬ìš©": f"{metrics['disk']['used_gb']:.1f} GB"
                    })

                with col2:
                    st.subheader("ğŸŒ ë„¤íŠ¸ì›Œí¬")
                    st.json({
                        "ì†¡ì‹ ": f"{metrics['network']['sent_mb']:.1f} MB",
                        "ìˆ˜ì‹ ": f"{metrics['network']['recv_mb']:.1f} MB",
                        "ì†¡ì‹  íŒ¨í‚·": f"{metrics['network']['packets_sent']:,}",
                        "ìˆ˜ì‹  íŒ¨í‚·": f"{metrics['network']['packets_recv']:,}"
                    })

            with tab2:
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric(
                        "ìºì‹œ íˆíŠ¸ìœ¨",
                        f"{metrics['performance']['cache_hit_rate']}%",
                        delta="+5%"
                    )

                with col2:
                    st.metric(
                        "ì´ˆë‹¹ ì¿¼ë¦¬",
                        f"{metrics['performance']['queries_per_second']:.1f}",
                        delta="+2.3"
                    )

                with col3:
                    st.metric(
                        "í‰ê·  ì‘ë‹µì‹œê°„",
                        f"{metrics['performance']['avg_response_time']:.2f}ì´ˆ",
                        delta="-0.5ì´ˆ"
                    )

                # ì„±ëŠ¥ ì°¨íŠ¸
                st.subheader("ğŸ“Š ì„±ëŠ¥ íŠ¸ë Œë“œ")
                perf_fig = create_time_series_chart(
                    collector.history,
                    ['queries_per_second', 'cache_hits'],
                    "ì„±ëŠ¥ ë©”íŠ¸ë¦­"
                )
                st.plotly_chart(perf_fig, use_container_width=True)

            with tab3:
                # ì‹œê³„ì—´ ë¶„ì„
                st.subheader("ğŸ“ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íŠ¸ë Œë“œ")

                # CPU/ë©”ëª¨ë¦¬ ì°¨íŠ¸
                resource_fig = create_time_series_chart(
                    collector.history,
                    ['cpu', 'memory', 'disk'],
                    "ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  (%)"
                )
                st.plotly_chart(resource_fig, use_container_width=True)

                # ë„¤íŠ¸ì›Œí¬ ì°¨íŠ¸
                network_fig = create_time_series_chart(
                    collector.history,
                    ['network_in', 'network_out'],
                    "ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ (MB)"
                )
                st.plotly_chart(network_fig, use_container_width=True)

            with tab4:
                # í”„ë¡œì„¸ìŠ¤ ìƒì„¸
                st.subheader("ğŸ” ìƒìœ„ í”„ë¡œì„¸ìŠ¤")
                process_df = create_process_table(metrics['processes'])
                if not process_df.empty:
                    st.dataframe(
                        process_df,
                        use_container_width=True,
                        hide_index=True
                    )
                else:
                    st.info("í”„ë¡œì„¸ìŠ¤ ì •ë³´ ì—†ìŒ")

                # CPU ì½”ì–´ë³„ ì‚¬ìš©ë¥ 
                st.subheader("ğŸ–¥ï¸ CPU ì½”ì–´ë³„ ì‚¬ìš©ë¥ ")
                core_data = pd.DataFrame({
                    'Core': [f"Core {i}" for i in range(len(metrics['cpu']['cores']))],
                    'Usage': metrics['cpu']['cores']
                })
                fig_cores = px.bar(core_data, x='Core', y='Usage', title="CPU ì½”ì–´ ì‚¬ìš©ë¥ ")
                st.plotly_chart(fig_cores, use_container_width=True)

            with tab5:
                # ì•Œë¦¼ & ë¡œê·¸
                st.subheader("âš ï¸ ì‹œìŠ¤í…œ ì•Œë¦¼")

                # ì„ê³„ê°’ ì²´í¬
                alerts = []
                if metrics['cpu']['percent'] > 80:
                    alerts.append(("ğŸ”´ ë†’ì€ CPU ì‚¬ìš©ë¥ ", f"CPU: {metrics['cpu']['percent']:.1f}%"))
                if metrics['memory']['percent'] > 80:
                    alerts.append(("ğŸ”´ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"Memory: {metrics['memory']['percent']:.1f}%"))
                if metrics['disk']['percent'] > 90:
                    alerts.append(("ğŸ”´ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±", f"Disk: {metrics['disk']['percent']:.1f}%"))

                if alerts:
                    for alert_title, alert_msg in alerts:
                        st.error(f"{alert_title}: {alert_msg}")
                else:
                    st.success("âœ… ëª¨ë“  ì‹œìŠ¤í…œ ì •ìƒ")

                # ìµœê·¼ ë¡œê·¸
                st.subheader("ğŸ“ ìµœê·¼ ì‹œìŠ¤í…œ ë¡œê·¸")
                log_placeholder = st.empty()

                # ìƒ˜í”Œ ë¡œê·¸ (ì‹¤ì œë¡œëŠ” íŒŒì¼ì—ì„œ ì½ì–´ì˜´)
                sample_logs = [
                    f"{datetime.now():%H:%M:%S} [INFO] ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ì¤‘",
                    f"{datetime.now():%H:%M:%S} [INFO] ìºì‹œ íˆíŠ¸ìœ¨ 85%",
                    f"{datetime.now():%H:%M:%S} [INFO] ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬: 0.5ì´ˆ",
                ]

                log_text = "\n".join(sample_logs)
                log_placeholder.code(log_text, language="log")

    # ìë™ ìƒˆë¡œê³ ì¹¨ (1ì´ˆë§ˆë‹¤)
    time.sleep(1)
    st.rerun()


if __name__ == "__main__":
    main()