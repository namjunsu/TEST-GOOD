#!/usr/bin/env python3
"""
RAG íšŒê·€ ë²¤ì¹˜ë§ˆí¬

ê³¨ë“  ì…‹ ê¸°ë°˜ ì„±ëŠ¥ ì¸¡ì •:
- Hit@k (ì •í™•ë„)
- MRR (Mean Reciprocal Rank)
- P50/P95 Latency (ì„±ëŠ¥)
- ì‹¤íŒ¨ìœ¨

Usage:
    python scripts/bench_rag.py
    python scripts/bench_rag.py --golden-set data/golden_set.json
"""

import sys
import time
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))


@dataclass
class BenchResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼"""
    query: str
    expected_docs: List[str]
    retrieved_docs: List[str]
    hit: bool
    reciprocal_rank: float
    latency: float
    success: bool
    error: Optional[str] = None


@dataclass
class BenchSummary:
    """ë²¤ì¹˜ë§ˆí¬ ìš”ì•½"""
    total: int = 0
    hits: int = 0
    success: int = 0
    failures: int = 0
    latencies: List[float] = field(default_factory=list)
    reciprocal_ranks: List[float] = field(default_factory=list)

    def add_result(self, result: BenchResult):
        """ê²°ê³¼ ì¶”ê°€"""
        self.total += 1
        if result.success:
            self.success += 1
            if result.hit:
                self.hits += 1
            self.latencies.append(result.latency)
            self.reciprocal_ranks.append(result.reciprocal_rank)
        else:
            self.failures += 1

    def compute(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.latencies:
            return {
                "error": "No successful queries",
                "total": self.total,
                "failures": self.failures,
            }

        sorted_lat = sorted(self.latencies)
        n = len(sorted_lat)

        return {
            "total_queries": self.total,
            "successes": self.success,
            "failures": self.failures,
            "success_rate": self.success / self.total if self.total > 0 else 0,
            "hit_at_5": self.hits / self.success if self.success > 0 else 0,
            "mrr": sum(self.reciprocal_ranks) / len(self.reciprocal_ranks) if self.reciprocal_ranks else 0,
            "latency_p50": sorted_lat[int(n * 0.5)] if n > 0 else 0,
            "latency_p95": sorted_lat[int(n * 0.95)] if n > 0 else 0,
            "latency_mean": sum(sorted_lat) / n if n > 0 else 0,
        }


# ê³¨ë“  ì…‹ (ì˜ˆì‹œ - ì‹¤ì œë¡œëŠ” íŒŒì¼ì—ì„œ ë¡œë“œ)
DEFAULT_GOLDEN_SET = [
    {
        "query": "2024ë…„ ì˜ˆì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "expected_docs": ["budget_2024.pdf", "finance_report_2024.pdf"]
    },
    {
        "query": "ì‹ ê·œ ì±„ìš© ê³„íšì´ ìˆë‚˜ìš”?",
        "expected_docs": ["hr_plan_2024.pdf", "recruitment_2024.pdf"]
    },
    {
        "query": "ì˜¬í•´ ì£¼ìš” í”„ë¡œì íŠ¸ëŠ”?",
        "expected_docs": ["project_plan_2024.pdf", "annual_goals_2024.pdf"]
    },
    # ì‹¤ì œë¡œëŠ” 30~50ê°œ ì§ˆë¬¸
]


def load_golden_set(filepath: Optional[Path] = None) -> List[Dict[str, Any]]:
    """ê³¨ë“  ì…‹ ë¡œë“œ

    Args:
        filepath: ê³¨ë“  ì…‹ JSON íŒŒì¼ ê²½ë¡œ

    Returns:
        List of queries with expected docs
    """
    if filepath and filepath.exists():
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        print(f"âš ï¸  ê³¨ë“  ì…‹ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©: {len(DEFAULT_GOLDEN_SET)}ê°œ")
        return DEFAULT_GOLDEN_SET


def bench_query(pipeline, query: str, expected_docs: List[str], top_k: int = 5) -> BenchResult:
    """ë‹¨ì¼ ì§ˆì˜ ë²¤ì¹˜ë§ˆí¬

    Args:
        pipeline: RAG íŒŒì´í”„ë¼ì¸
        query: ì§ˆë¬¸
        expected_docs: ì˜ˆìƒ ë¬¸ì„œ ID ëª©ë¡
        top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜

    Returns:
        BenchResult
    """
    start = time.time()
    success = False
    error = None
    retrieved_docs = []
    hit = False
    reciprocal_rank = 0.0

    try:
        # RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        response = pipeline.answer(query, top_k=top_k)
        retrieved_docs = [ev.get("doc_id", "") for ev in response.evidence]
        success = True

        # Hit@k ê³„ì‚°
        expected_set = set(expected_docs)
        retrieved_set = set(retrieved_docs)
        hit = bool(expected_set & retrieved_set)

        # MRR ê³„ì‚° (ì²« ë²ˆì§¸ ì •ë‹µ ë¬¸ì„œì˜ ìˆœìœ„)
        for i, doc_id in enumerate(retrieved_docs, 1):
            if doc_id in expected_set:
                reciprocal_rank = 1.0 / i
                break

    except Exception as e:
        error = str(e)

    latency = time.time() - start

    return BenchResult(
        query=query,
        expected_docs=expected_docs,
        retrieved_docs=retrieved_docs,
        hit=hit,
        reciprocal_rank=reciprocal_rank,
        latency=latency,
        success=success,
        error=error,
    )


def run_benchmark(golden_set_path: Optional[Path] = None, top_k: int = 5) -> BenchSummary:
    """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

    Args:
        golden_set_path: ê³¨ë“  ì…‹ íŒŒì¼ ê²½ë¡œ
        top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜

    Returns:
        BenchSummary
    """
    print("=" * 60)
    print("  RAG íšŒê·€ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 60)
    print()

    # ê³¨ë“  ì…‹ ë¡œë“œ
    golden_set = load_golden_set(golden_set_path)
    print(f"ğŸ“Š ê³¨ë“  ì…‹: {len(golden_set)}ê°œ ì§ˆë¬¸")
    print()

    # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    print("ğŸ”§ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")

    try:
        # ìƒˆ êµ¬ì¡° (app/rag/pipeline.py)
        from app.rag.pipeline import RagPipeline
        from app.core.config import Config

        cfg = Config.get_instance()
        pipeline = RagPipeline(cfg)
        pipeline.warmup()
        print("âœ… app.rag.pipeline ë¡œë“œ ì™„ë£Œ")

    except ImportError:
        # ê¸°ì¡´ êµ¬ì¡° (hybrid_chat_rag_v2.py)
        try:
            from hybrid_chat_rag_v2 import UnifiedRAG as RagPipeline
            pipeline = RagPipeline()
            print("âœ… hybrid_chat_rag_v2 ë¡œë“œ ì™„ë£Œ (ë ˆê±°ì‹œ)")
        except ImportError:
            print("âŒ RAG íŒŒì´í”„ë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)

    print()

    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    summary = BenchSummary()

    for i, item in enumerate(golden_set, 1):
        query = item["query"]
        expected = item["expected_docs"]

        print(f"[{i}/{len(golden_set)}] {query[:50]}...")

        result = bench_query(pipeline, query, expected, top_k)
        summary.add_result(result)

        if result.success:
            status = "âœ… HIT" if result.hit else "âŒ MISS"
            print(f"  {status} | {result.latency:.2f}s | RR={result.reciprocal_rank:.3f}")
        else:
            print(f"  âŒ FAIL: {result.error}")

        print()

    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("  ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
    print("=" * 60)

    metrics = summary.compute()

    if "error" in metrics:
        print(f"âŒ {metrics['error']}")
        return summary

    print(f"ì´ ì§ˆë¬¸: {metrics['total_queries']}")
    print(f"ì„±ê³µ: {metrics['successes']} ({metrics['success_rate']:.1%})")
    print(f"ì‹¤íŒ¨: {metrics['failures']}")
    print()
    print(f"Hit@{top_k}: {metrics['hit_at_5']:.1%}")
    print(f"MRR: {metrics['mrr']:.3f}")
    print()
    print(f"Latency P50: {metrics['latency_p50']:.2f}s")
    print(f"Latency P95: {metrics['latency_p95']:.2f}s")
    print(f"Latency Mean: {metrics['latency_mean']:.2f}s")
    print("=" * 60)

    # ê²°ê³¼ ì €ì¥
    output_path = Path("var/log/bench_metrics.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_path}")

    return summary


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="RAG íšŒê·€ ë²¤ì¹˜ë§ˆí¬")
    parser.add_argument(
        "--golden-set",
        type=Path,
        help="ê³¨ë“  ì…‹ JSON íŒŒì¼ ê²½ë¡œ",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=5,
        help="ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸: 5)",
    )

    args = parser.parse_args()

    try:
        run_benchmark(args.golden_set, args.top_k)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ì ì¤‘ë‹¨")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
