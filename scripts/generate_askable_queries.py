#!/usr/bin/env python3
"""
DB ê¸°ë°˜ ì§ˆë¬¸ í”„ë¦¬ì…‹ ìë™ ìƒì„±ê¸°

í˜„ì¬ metadata.dbì— ì¡´ì¬í•˜ëŠ” ì‹¤ì œ ë¬¸ì„œë§Œì„ ê¸°ì¤€ìœ¼ë¡œ
ê²€ì¦ ê°€ëŠ¥í•œ ì§ˆë¬¸ í”„ë¦¬ì…‹ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

ì¶œë ¥:
- docs/ASKABLE_QUERIES.md
- reports/askable_queries_verified.csv
- ui/presets.json
"""

import sqlite3
import json
import os
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
from collections import defaultdict


class QueryGenerator:
    """ì‹¤ì œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±ê¸°"""

    def __init__(self, db_path: str = "metadata.db"):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
        self.cursor = self.conn.cursor()

        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        self.rag_min_score = float(os.getenv("RAG_MIN_SCORE", "0.35"))
        self.require_citations = os.getenv("REQUIRE_CITATIONS", "true").lower() == "true"

    def extract_equipment_keywords(self) -> Dict[str, int]:
        """ë¬¸ì„œì—ì„œ ì‹¤ì œ ì¥ë¹„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        self.cursor.execute("""
            SELECT keywords FROM documents
            WHERE keywords IS NOT NULL AND keywords != '[]'
        """)

        equipment = defaultdict(int)
        for row in self.cursor.fetchall():
            try:
                kw_list = json.loads(row['keywords'])
                for kw in kw_list:
                    # ì¥ë¹„ëª…ìœ¼ë¡œ ë³´ì´ëŠ” í‚¤ì›Œë“œë§Œ (í•œê¸€+ì˜ë¬¸ í˜¼í•©, ìµœì†Œ 2ì)
                    if len(kw) >= 2 and not kw.isdigit():
                        equipment[kw] += 1
            except:
                pass

        # ë¹ˆë„ìˆœ ì •ë ¬
        return dict(sorted(equipment.items(), key=lambda x: x[1], reverse=True))

    def get_document_summaries(self) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        self.cursor.execute("""
            SELECT
                filename,
                title,
                drafter,
                date,
                year,
                category,
                doctype,
                keywords,
                text_preview
            FROM documents
            WHERE filename IS NOT NULL
            ORDER BY date DESC
            LIMIT 100
        """)

        summaries = []
        for row in self.cursor.fetchall():
            doc = dict(row)
            # í‚¤ì›Œë“œ íŒŒì‹±
            try:
                doc['keywords'] = json.loads(doc['keywords'] or '[]')
            except:
                doc['keywords'] = []
            summaries.append(doc)

        return summaries

    def generate_query_templates(self, summaries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì‹¤ì œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ í…œí”Œë¦¿ ìƒì„±"""
        queries = []

        # 1. ì¼ë°˜ ëŒ€í™” (ë¬¸ì„œ ë¶ˆí•„ìš”)
        queries.extend([
            {
                "query": "ì•ˆë…•í•˜ì„¸ìš”",
                "category": "ì¼ë°˜ ëŒ€í™”",
                "expected_mode": "chat",
                "expected_citations": False,
                "difficulty": "easy"
            },
            {
                "query": "1 + 1ì€?",
                "category": "ì¼ë°˜ ëŒ€í™”",
                "expected_mode": "chat",
                "expected_citations": False,
                "difficulty": "easy"
            }
        ])

        # 2. ì‘ì„±ìë³„ ë¬¸ì„œ ê²€ìƒ‰ (ì‹¤ì œ ì‘ì„±ìë§Œ)
        drafters = {}
        for doc in summaries:
            if doc['drafter'] and doc['drafter'].strip():
                drafters[doc['drafter']] = drafters.get(doc['drafter'], 0) + 1

        top_drafters = sorted(drafters.items(), key=lambda x: x[1], reverse=True)[:3]
        for drafter, count in top_drafters:
            queries.append({
                "query": f"{drafter} ì‘ì„± ë¬¸ì„œ ìš”ì•½í•´ì¤˜",
                "category": "ì‘ì„±ì ê²€ìƒ‰",
                "expected_mode": "rag",
                "expected_citations": True,
                "difficulty": "medium",
                "metadata": {"drafter": drafter, "expected_count": count}
            })

        # 3. ì—°ë„ë³„ ë¬¸ì„œ ê²€ìƒ‰
        years = {}
        for doc in summaries:
            if doc['year']:
                years[doc['year']] = years.get(doc['year'], 0) + 1

        top_years = sorted(years.items(), key=lambda x: x[0], reverse=True)[:3]
        for year, count in top_years:
            queries.append({
                "query": f"{year}ë…„ ì‘ì„±ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸",
                "category": "ì—°ë„ë³„ ê²€ìƒ‰",
                "expected_mode": "rag",
                "expected_citations": True,
                "difficulty": "medium",
                "metadata": {"year": year, "expected_count": count}
            })

        # 4. íŠ¹ì • ë¬¸ì„œ ìš”ì•½ (íŒŒì¼ëª… ê¸°ë°˜)
        for doc in summaries[:10]:  # ìƒìœ„ 10ê°œ
            filename = doc['filename']
            # íŒŒì¼ëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            match = re.search(r'\d{4}-\d{2}-\d{2}_(.+)\.pdf', filename)
            if match:
                core_name = match.group(1).replace('_', ' ')
                queries.append({
                    "query": f"{core_name} ê´€ë ¨ ë¬¸ì„œ ìš”ì•½í•´ì¤˜",
                    "category": "ë¬¸ì„œ ìš”ì•½",
                    "expected_mode": "rag",
                    "expected_citations": True,
                    "difficulty": "medium",
                    "metadata": {"filename": filename}
                })

        # 5. ì¥ë¹„ë³„ ë¬¸ì„œ ê²€ìƒ‰ (ì‹¤ì œ í‚¤ì›Œë“œ ê¸°ë°˜)
        equipment_keywords = self.extract_equipment_keywords()
        top_equipment = list(equipment_keywords.items())[:10]

        for equipment, count in top_equipment:
            if count >= 3:  # ìµœì†Œ 3ê°œ ì´ìƒ ë¬¸ì„œì— ë“±ì¥
                queries.append({
                    "query": f"{equipment} ê´€ë ¨ êµ¬ë§¤/ìˆ˜ë¦¬ ë‚´ì—­ì€?",
                    "category": "ì¥ë¹„ ê²€ìƒ‰",
                    "expected_mode": "rag",
                    "expected_citations": True,
                    "difficulty": "hard",
                    "metadata": {"equipment": equipment, "expected_count": count}
                })

        # 6. ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
        categories = {}
        for doc in summaries:
            if doc['category'] and doc['category'].strip() and doc['category'] != ':':
                categories[doc['category']] = categories.get(doc['category'], 0) + 1

        for category, count in categories.items():
            if count >= 5:  # ìµœì†Œ 5ê°œ ì´ìƒ
                queries.append({
                    "query": f"{category} ì¹´í…Œê³ ë¦¬ ë¬¸ì„œ ìš”ì•½",
                    "category": "ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰",
                    "expected_mode": "rag",
                    "expected_citations": True,
                    "difficulty": "medium",
                    "metadata": {"category": category, "expected_count": count}
                })

        # 7. ë¬´ê·¼ê±° ì§ˆë¬¸ (DBì— ì—†ëŠ” ë‚´ìš©)
        queries.extend([
            {
                "query": "APEX ì¤‘ê³„ ë™ì‹œí†µì—­ ë¼ìš°íŒ… ì •í™•í•œ ì—°ê²° ë„ë©´?",
                "category": "ë¬´ê·¼ê±° ë°©ì§€",
                "expected_mode": "chat",
                "expected_citations": False,
                "difficulty": "hard"
            },
            {
                "query": "ì¡´ì¬í•˜ì§€_ì•ŠëŠ”_ì¥ë¹„_12345ì˜ êµ¬ë§¤ ì´ë ¥ì€?",
                "category": "ë¬´ê·¼ê±° ë°©ì§€",
                "expected_mode": "chat",
                "expected_citations": False,
                "difficulty": "hard"
            }
        ])

        return queries

    def export_markdown(self, queries: List[Dict[str, Any]], output_path: str):
        """Markdown í¬ë§· ì¶œë ¥"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# AI-CHAT ì§ˆë¬¸ ê°€ëŠ¥ ëª©ë¡ (Askable Queries)\n\n")
            f.write(f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**DB ê¸°ì¤€**: metadata.db (483ê°œ ë¬¸ì„œ)\n")
            f.write(f"**RAG_MIN_SCORE**: {self.rag_min_score}\n")
            f.write(f"**REQUIRE_CITATIONS**: {self.require_citations}\n\n")
            f.write("---\n\n")

            f.write("## ì‚¬ìš© ë°©ë²•\n\n")
            f.write("ì´ ë¬¸ì„œëŠ” í˜„ì¬ DBì— ì¡´ì¬í•˜ëŠ” ì‹¤ì œ ë¬¸ì„œë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±ëœ **ê²€ì¦ ê°€ëŠ¥í•œ ì§ˆë¬¸ ëª©ë¡**ì…ë‹ˆë‹¤.\n\n")
            f.write("- âœ… **RAG ëª¨ë“œ**: ë¬¸ì„œ ê²€ìƒ‰ + ì¶œì²˜ ì¸ìš© ì‘ë‹µ\n")
            f.write("- ğŸ’¬ **Chat ëª¨ë“œ**: ì¼ë°˜ ëŒ€í™” (ë¬¸ì„œ ë¶ˆí•„ìš”)\n\n")
            f.write("---\n\n")

            # ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í™”
            by_category = defaultdict(list)
            for q in queries:
                by_category[q['category']].append(q)

            for category, items in sorted(by_category.items()):
                f.write(f"## {category}\n\n")
                for i, q in enumerate(items, 1):
                    mode_icon = "âœ…" if q['expected_mode'] == "rag" else "ğŸ’¬"
                    f.write(f"### {mode_icon} {i}. {q['query']}\n\n")
                    f.write(f"- **ì˜ˆìƒ ëª¨ë“œ**: {q['expected_mode']}\n")
                    f.write(f"- **ì¶œì²˜ ì¸ìš©**: {'ì˜ˆ' if q['expected_citations'] else 'ì•„ë‹ˆì˜¤'}\n")
                    f.write(f"- **ë‚œì´ë„**: {q['difficulty']}\n")

                    if 'metadata' in q:
                        f.write(f"- **ë©”íƒ€ë°ì´í„°**: {json.dumps(q['metadata'], ensure_ascii=False)}\n")

                    f.write("\n")

        print(f"âœ… Markdown ì €ì¥: {output_path}")

    def export_csv(self, queries: List[Dict[str, Any]], output_path: str):
        """CSV í¬ë§· ì¶œë ¥"""
        import csv
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                "query",
                "category",
                "expected_mode",
                "expected_citations",
                "difficulty",
                "metadata"
            ])

            for q in queries:
                writer.writerow([
                    q['query'],
                    q['category'],
                    q['expected_mode'],
                    q['expected_citations'],
                    q['difficulty'],
                    json.dumps(q.get('metadata', {}), ensure_ascii=False)
                ])

        print(f"âœ… CSV ì €ì¥: {output_path}")

    def export_json(self, queries: List[Dict[str, Any]], output_path: str):
        """JSON í¬ë§· ì¶œë ¥ (UI í”„ë¦¬ì…‹ìš©)"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # UIìš©ìœ¼ë¡œ ê°„ì†Œí™”
        presets = {
            "version": "1.0",
            "generated_at": datetime.now().isoformat(),
            "total_queries": len(queries),
            "presets": []
        }

        for q in queries:
            preset = {
                "id": f"q_{len(presets['presets']) + 1}",
                "text": q['query'],
                "category": q['category'],
                "mode": q['expected_mode'],
                "difficulty": q['difficulty']
            }

            if 'metadata' in q:
                preset['metadata'] = q['metadata']

            presets['presets'].append(preset)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(presets, f, indent=2, ensure_ascii=False)

        print(f"âœ… JSON ì €ì¥: {output_path}")

    def close(self):
        """DB ì—°ê²° ì¢…ë£Œ"""
        self.conn.close()


def main():
    print("=" * 80)
    print("ğŸ¤– AI-CHAT ì§ˆë¬¸ í”„ë¦¬ì…‹ ìë™ ìƒì„±ê¸°")
    print("=" * 80)
    print()

    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = QueryGenerator()

    # ë¬¸ì„œ ìš”ì•½ ì¶”ì¶œ
    print("ğŸ“š ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    summaries = generator.get_document_summaries()
    print(f"   ì¶”ì¶œ ì™„ë£Œ: {len(summaries)}ê°œ ë¬¸ì„œ")

    # ì§ˆë¬¸ ìƒì„±
    print("\nğŸ” ì§ˆë¬¸ í”„ë¦¬ì…‹ ìƒì„± ì¤‘...")
    queries = generator.generate_query_templates(summaries)
    print(f"   ìƒì„± ì™„ë£Œ: {len(queries)}ê°œ ì§ˆë¬¸")

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    by_category = defaultdict(int)
    by_mode = defaultdict(int)
    for q in queries:
        by_category[q['category']] += 1
        by_mode[q['expected_mode']] += 1

    print("\nğŸ“Š ìƒì„± í†µê³„:")
    print(f"   ì¹´í…Œê³ ë¦¬ë³„:")
    for cat, cnt in sorted(by_category.items()):
        print(f"     - {cat}: {cnt}ê°œ")
    print(f"   ëª¨ë“œë³„:")
    for mode, cnt in sorted(by_mode.items()):
        print(f"     - {mode}: {cnt}ê°œ")

    # ì¶œë ¥
    print("\nğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...")
    generator.export_markdown(queries, "docs/ASKABLE_QUERIES.md")
    generator.export_csv(queries, "reports/askable_queries_verified.csv")
    generator.export_json(queries, "ui/presets.json")

    generator.close()

    print("\n" + "=" * 80)
    print("âœ… ì§ˆë¬¸ í”„ë¦¬ì…‹ ìƒì„± ì™„ë£Œ!")
    print("=" * 80)
    print()
    print("ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. ìƒì„±ëœ ì§ˆë¬¸ ê²€í† : docs/ASKABLE_QUERIES.md")
    print("  2. ê²€ì¦ ì‹¤í–‰: python scripts/scenario_validation.py")
    print("  3. UI í”„ë¦¬ì…‹ ì ìš©: ui/presets.json")


if __name__ == "__main__":
    main()
