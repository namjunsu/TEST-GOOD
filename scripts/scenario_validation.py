#!/usr/bin/env python3
"""
8ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ëŠ¥ ì ê²€ ìŠ¤í¬ë¦½íŠ¸

ìš´ì˜ ì¤€ë¹„ ì™„ë£Œ í™•ì¸ìš© - ì¼ë°˜ ëŒ€í™” vs ë¬¸ì„œê·¼ê±° RAG ìë™ ì „í™˜ í…ŒìŠ¤íŠ¸

ì‚¬ìš©ë²•:
    python test_8_scenarios.py

    ë˜ëŠ” íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ë§Œ:
    python test_8_scenarios.py --scenario 1
"""

import sys
import os
import time
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from app.rag.pipeline import RAGPipeline
from app.core.logging import get_logger

logger = get_logger(__name__)


class ScenarioTest:
    """ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ"""

    def __init__(self):
        self.pipeline = RAGPipeline()
        self.results = []

    def run_scenario(self,
                    scenario_num: int,
                    title: str,
                    query: str,
                    expected_mode: str,
                    expected_has_citations: bool) -> Dict[str, Any]:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰

        Args:
            scenario_num: ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸
            title: ì‹œë‚˜ë¦¬ì˜¤ ì œëª©
            query: í…ŒìŠ¤íŠ¸ ì§ˆì˜
            expected_mode: ì˜ˆìƒ ëª¨ë“œ (chat|rag)
            expected_has_citations: ì¶œì²˜ ì¸ìš© ì˜ˆìƒ ì—¬ë¶€

        Returns:
            ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("\n" + "=" * 80)
        print(f"ğŸ§ª ì‹œë‚˜ë¦¬ì˜¤ {scenario_num}: {title}")
        print("=" * 80)
        print(f"ì§ˆì˜: {query}")
        print("-" * 80)

        start_time = time.time()

        try:
            # RAG íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ
            response = self.pipeline.query(query)

            elapsed = time.time() - start_time

            # ê²°ê³¼ ë¶„ì„
            actual_mode = response.metrics.get('mode', 'unknown')
            has_citations = len(response.source_docs) > 0 or len(response.evidence_chunks) > 0
            top_score = response.metrics.get('top_score', 0.0)

            # ë‹µë³€ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 200ì)
            answer_preview = response.answer[:200] + "..." if len(response.answer) > 200 else response.answer

            print(f"\nğŸ“Š ê²°ê³¼:")
            print(f"  ëª¨ë“œ: {actual_mode}")
            print(f"  ìµœê³  ì ìˆ˜: {top_score:.3f}")
            print(f"  ì¶œì²˜ ê°œìˆ˜: {len(response.source_docs)}")
            print(f"  ì‘ë‹µ ì‹œê°„: {elapsed:.2f}ì´ˆ")
            print(f"\nğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°:")
            print(f"  {answer_preview}")

            if response.source_docs:
                print(f"\nğŸ“š ì¶œì²˜:")
                for i, doc in enumerate(response.source_docs[:3], 1):
                    print(f"  {i}. {doc}")

            # ê²€ì¦
            mode_match = actual_mode == expected_mode
            citation_match = has_citations == expected_has_citations

            status = "âœ… PASS" if (mode_match and citation_match) else "âŒ FAIL"

            if not mode_match:
                print(f"\nâš ï¸  ëª¨ë“œ ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_mode}, ì‹¤ì œ={actual_mode}")
            if not citation_match:
                print(f"\nâš ï¸  ì¶œì²˜ ì¸ìš© ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_has_citations}, ì‹¤ì œ={has_citations}")

            print(f"\n{status}")

            result = {
                'scenario': scenario_num,
                'title': title,
                'query': query,
                'status': 'PASS' if (mode_match and citation_match) else 'FAIL',
                'actual_mode': actual_mode,
                'expected_mode': expected_mode,
                'has_citations': has_citations,
                'expected_has_citations': expected_has_citations,
                'top_score': top_score,
                'latency': elapsed,
                'answer_length': len(response.answer)
            }

            self.results.append(result)
            return result

        except Exception as e:
            print(f"\nâŒ ERROR: {e}")
            import traceback
            traceback.print_exc()

            result = {
                'scenario': scenario_num,
                'title': title,
                'query': query,
                'status': 'ERROR',
                'error': str(e)
            }
            self.results.append(result)
            return result

    def print_summary(self):
        """ì „ì²´ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n\n" + "=" * 80)
        print("ğŸ“Š ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)

        passed = sum(1 for r in self.results if r['status'] == 'PASS')
        failed = sum(1 for r in self.results if r['status'] == 'FAIL')
        errors = sum(1 for r in self.results if r['status'] == 'ERROR')
        total = len(self.results)

        print(f"\nì´ {total}ê°œ ì‹œë‚˜ë¦¬ì˜¤:")
        print(f"  âœ… PASS: {passed}")
        print(f"  âŒ FAIL: {failed}")
        print(f"  ğŸ”¥ ERROR: {errors}")
        print(f"\nì„±ê³µë¥ : {passed/total*100:.1f}%")

        # ì‹¤íŒ¨í•œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„¸
        if failed > 0 or errors > 0:
            print("\nâŒ ì‹¤íŒ¨/ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤:")
            for r in self.results:
                if r['status'] != 'PASS':
                    print(f"  [{r['scenario']}] {r['title']}: {r['status']}")
                    if 'error' in r:
                        print(f"      Error: {r['error']}")

        # ë¡œê·¸ íŒŒì¼ ì €ì¥
        log_file = f"reports/scenario_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs("reports", exist_ok=True)

        import json
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'summary': {
                    'total': total,
                    'passed': passed,
                    'failed': failed,
                    'errors': errors
                },
                'results': self.results
            }, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼ ì €ì¥: {log_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("=" * 80)
    print("ğŸš€ AI-CHAT ìš´ì˜ ì¤€ë¹„ 8ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"MODE: {os.getenv('MODE', 'AUTO')}")
    print(f"RAG_MIN_SCORE: {os.getenv('RAG_MIN_SCORE', '0.35')}")
    print(f"ALLOW_UNGROUNDED_CHAT: {os.getenv('ALLOW_UNGROUNDED_CHAT', 'true')}")

    runner = ScenarioTest()

    # ========================================================================
    # ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
    # ========================================================================

    scenarios = [
        # 1. ì¼ë°˜ ëŒ€í™”: ë¬¸ì„œ ì¸ìš© ì—†ì´ ë‹µë³€
        {
            'num': 1,
            'title': 'ì¼ë°˜ ëŒ€í™” (ë¬¸ì„œ ì¸ìš© ì—†ìŒ)',
            'query': '1+1ì€?',
            'expected_mode': 'chat',
            'expected_has_citations': False
        },

        # 2. íšŒì‚¬ ë¬¸ì„œ ê²€ìƒ‰: ë¬¸ì„œ ì¸ìš© í¬í•¨
        {
            'num': 2,
            'title': 'íšŒì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ë¬¸ì„œ ì¸ìš© í¬í•¨)',
            'query': '2024-08-14 ê¸°ìˆ ê´€ë¦¬íŒ€ ë°©ì†¡ì‹œìŠ¤í…œ ì†Œëª¨í’ˆ êµ¬ë§¤ ê²€í† ì„œ ìš”ì•½í•´ì¤˜',
            'expected_mode': 'rag',
            'expected_has_citations': True
        },

        # 3. ì •ì±… ì§ˆì˜: ê´€ë ¨ ë¬¸ì„œ ì¸ìš©
        {
            'num': 3,
            'title': 'ì •ì±… ì§ˆì˜ (ê´€ë ¨ ë¬¸ì„œ ì¸ìš©)',
            'query': 'NVR ì €ì¥ìš©ëŸ‰ ì‚°ì • ê¸°ì¤€ê³¼ HDD êµì²´ ì£¼ê¸°ëŠ”?',
            'expected_mode': 'rag',
            'expected_has_citations': True
        },

        # 4. ì¸í”„ë¼ êµ¬ì„±: ë‹¤ì´ì–´ê·¸ë¨ ì„¹ì…˜ ì¸ìš©
        {
            'num': 4,
            'title': 'ì¸í”„ë¼ êµ¬ì„± (ë‹¤ì´ì–´ê·¸ë¨ ì„¹ì…˜ ì¸ìš©)',
            'query': 'Tri-Level Sync/Black Burst ì‹ í˜¸ ë¶„ë°° êµ¬ì„± ìš”ì•½',
            'expected_mode': 'rag',
            'expected_has_citations': True
        },

        # 5. ì‚¬ë¡€ ë¹„êµ: í•´ë‹¹ ë³´ê³ ì„œ ì¸ìš©
        {
            'num': 5,
            'title': 'ì‚¬ë¡€ ë¹„êµ (í•´ë‹¹ ë³´ê³ ì„œ ì¸ìš©)',
            'query': 'ë‰´ìŠ¤ ìŠ¤íŠœë””ì˜¤ ì§€ë¯¸ì§‘ Control Box ìˆ˜ë¦¬ ê±´ í•µì‹¬ ì›ì¸/ì¡°ì¹˜',
            'expected_mode': 'rag',
            'expected_has_citations': True
        },

        # 6. í•„í„° ê²€ìƒ‰: ë©”íƒ€í•„í„° ë™ì‘
        {
            'num': 6,
            'title': 'í•„í„° ê²€ìƒ‰ (ë©”íƒ€í•„í„° ë™ì‘)',
            'query': 'ê¸°ì•ˆì=ë‚¨ì¤€ìˆ˜, 2024ë…„ ë¬¸ì„œë§Œ ìš”ì•½ ë¦¬ìŠ¤íŠ¸',
            'expected_mode': 'rag',
            'expected_has_citations': True
        },

        # 7. ë¬´ê·¼ê±° ë°©ì§€: ê·¼ê±° ì—†ìœ¼ë©´ 'ê·¼ê±° ì—†ìŒ'
        {
            'num': 7,
            'title': 'ë¬´ê·¼ê±° ë°©ì§€ (ê·¼ê±° ì—†ìŒ ì²˜ë¦¬)',
            'query': 'APEX ì¤‘ê³„ ë™ì‹œí†µì—­ ë¼ìš°íŒ… ì •í™•í•œ ì—°ê²° ë„ë©´?',
            'expected_mode': 'chat',  # ê·¼ê±° ì—†ìœ¼ë©´ chat ëª¨ë“œë¡œ í´ë°±
            'expected_has_citations': False
        },

        # 8. ê¸´ ë¬¸ì„œ ìš”ì•½: TL;DR
        {
            'num': 8,
            'title': 'ê¸´ ë¬¸ì„œ ìš”ì•½ (TL;DR)',
            'query': 'ë°©ì†¡ì‹œìŠ¤í…œ ì†Œëª¨í’ˆ êµ¬ë§¤ ê²€í† ì„œ 3ë¬¸ì¥ TL;DR',
            'expected_mode': 'rag',
            'expected_has_citations': True
        }
    ]

    # íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ë§Œ ì‹¤í–‰í• ì§€ í™•ì¸
    if '--scenario' in sys.argv:
        idx = sys.argv.index('--scenario')
        if idx + 1 < len(sys.argv):
            scenario_num = int(sys.argv[idx + 1])
            scenarios = [s for s in scenarios if s['num'] == scenario_num]
            if not scenarios:
                print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ {scenario_num}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return 1

    # ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
    for scenario in scenarios:
        runner.run_scenario(
            scenario['num'],
            scenario['title'],
            scenario['query'],
            scenario['expected_mode'],
            scenario['expected_has_citations']
        )

        # ì‹œë‚˜ë¦¬ì˜¤ ê°„ ê°„ê²©
        if scenario != scenarios[-1]:
            time.sleep(1)

    # ê²°ê³¼ ìš”ì•½
    runner.print_summary()

    # ì¢…ë£Œ ì½”ë“œ ë°˜í™˜
    failed_count = sum(1 for r in runner.results if r['status'] != 'PASS')
    return 0 if failed_count == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
