#!/usr/bin/env python3
"""
metadata.db Cleaner - Stale ë ˆì½”ë“œ ì •ë¦¬ ìœ í‹¸ë¦¬í‹°
ë¬¼ë¦¬ì ìœ¼ë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import sqlite3
import os
from pathlib import Path
from typing import List, Tuple
from app.core.logging import get_logger

logger = get_logger(__name__)


def purge_missing_files_from_metadata(
    db_path: str = "metadata.db",
    dry_run: bool = False
) -> Tuple[int, List[str]]:
    """metadata.dbì—ì„œ ë¬¼ë¦¬ì ìœ¼ë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ë ˆì½”ë“œ ì‚­ì œ

    Args:
        db_path: metadata.db ê²½ë¡œ
        dry_run: Trueë©´ ì‹¤ì œë¡œ ì‚­ì œí•˜ì§€ ì•Šê³  ëŒ€ìƒë§Œ ì¶œë ¥

    Returns:
        (ì‚­ì œëœ ë ˆì½”ë“œ ìˆ˜, ì‚­ì œëœ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸)
    """
    if not os.path.exists(db_path):
        logger.error(f"DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_path}")
        return 0, []

    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
        cursor.execute("""
            SELECT id, filename, path
            FROM documents
            WHERE LOWER(filename) LIKE '%.pdf' OR LOWER(filename) LIKE '%.txt'
        """)

        all_docs = cursor.fetchall()
        stale_ids = []
        stale_filenames = []

        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        for row in all_docs:
            doc_id = row['id']
            filename = row['filename']
            path = row['path']

            # ê²½ë¡œ í™•ì¸ (path í•„ë“œê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ docs/ + filename)
            if path:
                file_path = Path(path)
            else:
                file_path = Path('docs') / filename

            # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ stale ëª©ë¡ì— ì¶”ê°€
            if not file_path.exists():
                stale_ids.append(doc_id)
                stale_filenames.append(filename)

        # ê²°ê³¼ ë¡œê¹…
        logger.info(f"ì „ì²´ ë¬¸ì„œ: {len(all_docs)}ê°œ")
        logger.info(f"Stale ë ˆì½”ë“œ: {len(stale_ids)}ê°œ")

        if dry_run:
            logger.info("DRY RUN ëª¨ë“œ - ì‚­ì œí•˜ì§€ ì•ŠìŒ")
            for filename in stale_filenames[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
                logger.info(f"  - {filename}")
            if len(stale_filenames) > 10:
                logger.info(f"  ... ì™¸ {len(stale_filenames) - 10}ê°œ")
        else:
            # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
            if stale_ids:
                # documents í…Œì´ë¸”ì—ì„œ ì‚­ì œ (íŠ¸ë¦¬ê±°ë¡œ documents_ftsë„ ìë™ ì‚­ì œë¨)
                placeholders = ','.join(['?'] * len(stale_ids))
                cursor.execute(f"""
                    DELETE FROM documents
                    WHERE id IN ({placeholders})
                """, stale_ids)

                conn.commit()
                logger.info(f"âœ… {len(stale_ids)}ê°œ stale ë ˆì½”ë“œ ì‚­ì œ ì™„ë£Œ")

                # ì‚­ì œëœ íŒŒì¼ëª… ë¡œê¹… (ì²˜ìŒ 10ê°œë§Œ)
                for filename in stale_filenames[:10]:
                    logger.info(f"  - {filename}")
                if len(stale_filenames) > 10:
                    logger.info(f"  ... ì™¸ {len(stale_filenames) - 10}ê°œ")

        conn.close()
        return len(stale_ids), stale_filenames

    except Exception as e:
        logger.error(f"metadata.db ì •ë¦¬ ì‹¤íŒ¨: {e}")
        return 0, []


def verify_sync(metadata_db: str = "metadata.db", index_db: str = "everything_index.db") -> dict:
    """ë‘ DB ê°„ì˜ ë™ê¸°í™” ìƒíƒœ í™•ì¸

    Args:
        metadata_db: metadata.db ê²½ë¡œ
        index_db: everything_index.db ê²½ë¡œ

    Returns:
        ë™ê¸°í™” ìƒíƒœ ë”•ì…”ë„ˆë¦¬
    """
    result = {
        'metadata_count': 0,
        'index_count': 0,
        'diff': 0,
        'missing_in_index': [],
        'stale_in_index': [],
        'synced': False
    }

    try:
        # metadata.db ì¹´ìš´íŠ¸
        metadata_conn = sqlite3.connect(metadata_db)
        metadata_conn.row_factory = sqlite3.Row
        cursor = metadata_conn.execute("""
            SELECT COUNT(DISTINCT filename) as count
            FROM documents
            WHERE LOWER(filename) LIKE '%.pdf' OR LOWER(filename) LIKE '%.txt'
        """)
        result['metadata_count'] = cursor.fetchone()['count']

        # ëª¨ë“  íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
        cursor = metadata_conn.execute("""
            SELECT DISTINCT filename
            FROM documents
            WHERE LOWER(filename) LIKE '%.pdf' OR LOWER(filename) LIKE '%.txt'
        """)
        metadata_files = {row['filename'] for row in cursor.fetchall()}
        metadata_conn.close()

        # everything_index.db ì¹´ìš´íŠ¸
        if os.path.exists(index_db):
            index_conn = sqlite3.connect(index_db)
            index_conn.row_factory = sqlite3.Row
            cursor = index_conn.execute("""
                SELECT COUNT(DISTINCT filename) as count
                FROM files
            """)
            result['index_count'] = cursor.fetchone()['count']

            # ëª¨ë“  íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
            cursor = index_conn.execute("""
                SELECT DISTINCT filename
                FROM files
            """)
            index_files = {row['filename'] for row in cursor.fetchall()}
            index_conn.close()

            # ì°¨ì´ ê³„ì‚°
            result['missing_in_index'] = list(metadata_files - index_files)
            result['stale_in_index'] = list(index_files - metadata_files)

        result['diff'] = result['metadata_count'] - result['index_count']
        result['synced'] = (result['diff'] == 0 and
                           len(result['missing_in_index']) == 0 and
                           len(result['stale_in_index']) == 0)

        return result

    except Exception as e:
        logger.error(f"ë™ê¸°í™” í™•ì¸ ì‹¤íŒ¨: {e}")
        return result


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="metadata.db Cleaner")
    parser.add_argument('--dry-run', action='store_true', help='ì‚­ì œí•˜ì§€ ì•Šê³  ëŒ€ìƒë§Œ ì¶œë ¥')
    parser.add_argument('--verify', action='store_true', help='ë™ê¸°í™” ìƒíƒœë§Œ í™•ì¸')
    parser.add_argument('--db', default='metadata.db', help='DB ê²½ë¡œ')

    args = parser.parse_args()

    if args.verify:
        print("ğŸ” ë™ê¸°í™” ìƒíƒœ í™•ì¸ ì¤‘...")
        result = verify_sync(args.db)
        print(f"\nğŸ“Š ë™ê¸°í™” ìƒíƒœ:")
        print(f"  - metadata.db: {result['metadata_count']}ê°œ")
        print(f"  - everything_index.db: {result['index_count']}ê°œ")
        print(f"  - ì°¨ì´: {result['diff']}ê°œ")
        print(f"  - ë™ê¸°í™” ìƒíƒœ: {'âœ… ì •ìƒ' if result['synced'] else 'âš ï¸ ë¶ˆì¼ì¹˜'}")

        if result['missing_in_index']:
            print(f"\nâš ï¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ë§Œ ì¡´ì¬ (ì¸ë±ìŠ¤ì— ì—†ìŒ): {len(result['missing_in_index'])}ê°œ")
            for filename in result['missing_in_index'][:5]:
                print(f"  - {filename}")

        if result['stale_in_index']:
            print(f"\nâš ï¸ ì¸ë±ìŠ¤ì—ë§Œ ì¡´ì¬ (ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì—†ìŒ): {len(result['stale_in_index'])}ê°œ")
            for filename in result['stale_in_index'][:5]:
                print(f"  - {filename}")
    else:
        print(f"ğŸ§¹ metadata.db ì •ë¦¬ ì‹œì‘... (DRY_RUN={args.dry_run})")
        count, filenames = purge_missing_files_from_metadata(args.db, args.dry_run)

        if args.dry_run:
            print(f"\nğŸ“‹ ì‚­ì œ ëŒ€ìƒ: {count}ê°œ (ì‹¤ì œë¡œ ì‚­ì œí•˜ì§€ ì•ŠìŒ)")
            print("ì‹¤ì œë¡œ ì‚­ì œí•˜ë ¤ë©´ --dry-run ì˜µì…˜ ì—†ì´ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            print(f"\nâœ… ì •ë¦¬ ì™„ë£Œ: {count}ê°œ stale ë ˆì½”ë“œ ì‚­ì œ")
