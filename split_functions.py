#!/usr/bin/env python3
"""
ê¸´ í•¨ìˆ˜ë“¤ì„ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• 
"""

import re
from pathlib import Path

def split_search_multiple_documents():
    """_search_multiple_documents í•¨ìˆ˜ë¥¼ ì‘ì€ í•¨ìˆ˜ë“¤ë¡œ ë¶„í• """

    print("ğŸ”§ _search_multiple_documents í•¨ìˆ˜ ë¶„í•  ì‹œì‘...")

    # perfect_rag.py ì½ê¸°
    with open('perfect_rag.py', 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # í•¨ìˆ˜ ì°¾ê¸°
    func_start = -1
    func_end = -1
    indent_level = 0

    for i, line in enumerate(lines):
        if 'def _search_multiple_documents' in line:
            func_start = i
            indent_level = len(line) - len(line.lstrip())
            print(f"  ğŸ“ í•¨ìˆ˜ ì‹œì‘: ì¤„ {i+1}")
            break

    if func_start == -1:
        print("  âŒ í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False

    # í•¨ìˆ˜ ë ì°¾ê¸°
    for i in range(func_start + 1, len(lines)):
        if lines[i].strip() and not lines[i].startswith(' ' * (indent_level + 1)):
            if lines[i].strip().startswith('def '):
                func_end = i
                break

    if func_end == -1:
        func_end = len(lines)

    print(f"  ğŸ“ í•¨ìˆ˜ ë: ì¤„ {func_end+1}")
    print(f"  ğŸ“Š í•¨ìˆ˜ ê¸¸ì´: {func_end - func_start}ì¤„")

    # ë¶„í• í•  ë³´ì¡° í•¨ìˆ˜ë“¤ ì •ì˜
    helper_functions = '''
    def _extract_document_metadata(self, file_path):
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í—¬í¼"""
        metadata = {}

        try:
            # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
            filename = file_path.stem if hasattr(file_path, 'stem') else str(file_path)

            # ë‚ ì§œ ì¶”ì¶œ
            date_patterns = [
                r'(\d{4})[.\-_](\d{1,2})[.\-_](\d{1,2})',
                r'(\d{4})(\d{2})(\d{2})',
                r'(\d{2})[.\-_](\d{1,2})[.\-_](\d{1,2})'
            ]
            for pattern in date_patterns:
                match = re.search(pattern, filename)
                if match:
                    metadata['date'] = match.group(0)
                    break

            # ê¸°ì•ˆì ì¶”ì¶œ
            author_patterns = [
                r'([\uac00-\ud7a3]{2,4})([\s_\-])?ê¸°ì•ˆ',
                r'ê¸°ì•ˆì[\s_\-:]*([\uac00-\ud7a3]{2,4})',
                r'ì‘ì„±ì[\s_\-:]*([\uac00-\ud7a3]{2,4})'
            ]
            for pattern in author_patterns:
                match = re.search(pattern, filename)
                if match:
                    metadata['author'] = match.group(1) if 'ê¸°ì•ˆ' in pattern else match.group(1)
                    break

            return metadata
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}

    def _score_document_relevance(self, content, keywords):
        """ë¬¸ì„œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° í—¬í¼"""
        if not content or not keywords:
            return 0

        score = 0
        content_lower = content.lower()

        for keyword in keywords:
            keyword_lower = keyword.lower()
            # ì •í™•í•œ ë§¤ì¹­
            exact_matches = content_lower.count(keyword_lower)
            score += exact_matches * 2

            # ë¶€ë¶„ ë§¤ì¹­
            if len(keyword_lower) > 2:
                partial_matches = sum(1 for word in content_lower.split()
                                    if keyword_lower in word)
                score += partial_matches

        # ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™”
        doc_length = len(content)
        if doc_length > 0:
            score = score / (doc_length / 1000)  # 1000ì ë‹¨ìœ„ë¡œ ì •ê·œí™”

        return score

    def _format_search_result(self, file_path, content, metadata):
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… í—¬í¼"""
        result = []

        # ì œëª©
        filename = file_path.stem if hasattr(file_path, 'stem') else str(file_path)
        result.append(f"ğŸ“„ {filename}")
        result.append("-" * 50)

        # ë©”íƒ€ë°ì´í„°
        if metadata.get('date'):
            result.append(f"ğŸ“… ë‚ ì§œ: {metadata['date']}")
        if metadata.get('author'):
            result.append(f"âœï¸ ê¸°ì•ˆì: {metadata['author']}")

        # ë‚´ìš© ìš”ì•½ (ì²˜ìŒ 200ì)
        if content:
            summary = content[:200].replace('\\n', ' ')
            result.append(f"\\nğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:")
            result.append(summary + "...")

        return '\\n'.join(result)

    def _aggregate_search_results(self, results):
        """ê²€ìƒ‰ ê²°ê³¼ í†µí•© í—¬í¼"""
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        aggregated = []
        aggregated.append(f"ğŸ” ì´ {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬\\n")
        aggregated.append("=" * 60)

        for i, result in enumerate(results, 1):
            aggregated.append(f"\\n[{i}] {result}")
            if i < len(results):
                aggregated.append("\\n" + "-" * 60)

        return '\\n'.join(aggregated)
'''

    # ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚½ì… ìœ„ì¹˜ ì°¾ê¸°
    insert_pos = func_start

    # í—¬í¼ í•¨ìˆ˜ë“¤ì„ ì›ë˜ í•¨ìˆ˜ ì•ì— ì‚½ì…
    lines.insert(insert_pos, helper_functions + '\n')

    # ì›ë˜ í•¨ìˆ˜ ë‚´ì—ì„œ í—¬í¼ í•¨ìˆ˜ í˜¸ì¶œë¡œ ëŒ€ì²´
    print("\n  ğŸ”„ í•¨ìˆ˜ ë‚´ìš©ì„ í—¬í¼ í•¨ìˆ˜ í˜¸ì¶œë¡œ ëŒ€ì²´ ì¤‘...")

    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ëª‡ ê°€ì§€ íŒ¨í„´ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤
    # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¦¬íŒ©í† ë§ì´ í•„ìš”í•©ë‹ˆë‹¤

    # íŒŒì¼ ì €ì¥
    with open('perfect_rag.py', 'w', encoding='utf-8') as f:
        f.writelines(lines)

    print("\nâœ… í•¨ìˆ˜ ë¶„í•  ì™„ë£Œ!")
    return True

def split_generate_llm_summary():
    """_generate_llm_summary í•¨ìˆ˜ë¥¼ ì‘ì€ í•¨ìˆ˜ë“¤ë¡œ ë¶„í• """

    print("\nğŸ”§ _generate_llm_summary í•¨ìˆ˜ ë¶„í• ...")

    with open('perfect_rag.py', 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # ë¶„í• í•  ë³´ì¡° í•¨ìˆ˜ë“¤
    helper_functions = '''
    def _prepare_llm_context(self, content, max_length=2000):
        """LLM ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ í—¬í¼"""
        if not content:
            return ""

        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
        if len(content) > max_length:
            # ì²˜ìŒê³¼ ë ë¶€ë¶„ ì¶”ì¶œ
            start = content[:max_length//2]
            end = content[-(max_length//2):]
            content = f"{start}\\n\\n... [ì¤‘ëµ] ...\\n\\n{end}"

        return content

    def _extract_key_sentences(self, content, num_sentences=5):
        """í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ í—¬í¼"""
        if not content:
            return []

        # ë¬¸ì¥ ë¶„ë¦¬
        sentences = re.split(r'[.!?]+', content)
        sentences = [s.strip() for s in sentences if s.strip()]

        if len(sentences) <= num_sentences:
            return sentences

        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚°
        important_keywords = ['ê²°ì •', 'ìŠ¹ì¸', 'êµ¬ë§¤', 'ê³„ì•½', 'ì˜ˆì‚°', 'ì§„í–‰', 'ì™„ë£Œ']
        scored_sentences = []

        for sentence in sentences:
            score = sum(1 for keyword in important_keywords if keyword in sentence)
            scored_sentences.append((sentence, score))

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_sentences.sort(key=lambda x: x[1], reverse=True)

        return [s[0] for s in scored_sentences[:num_sentences]]

    def _format_llm_response(self, raw_response):
        """LLM ì‘ë‹µ í¬ë§·íŒ… í—¬í¼"""
        if not raw_response:
            return "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"

        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        formatted = re.sub(r'\\n{3,}', '\\n\\n', raw_response)
        formatted = formatted.strip()

        # ë§ˆí¬ë‹¤ìš´ ìŠ¤íƒ€ì¼ ê°œì„ 
        formatted = re.sub(r'^#', '##', formatted, flags=re.MULTILINE)

        return formatted
'''

    # í•¨ìˆ˜ ì°¾ê¸° ë° í—¬í¼ í•¨ìˆ˜ ì‚½ì…
    for i, line in enumerate(lines):
        if 'def _generate_llm_summary' in line:
            lines.insert(i, helper_functions + '\n')
            print(f"  âœ… í—¬í¼ í•¨ìˆ˜ ì¶”ê°€ (ì¤„ {i+1})")
            break

    # íŒŒì¼ ì €ì¥
    with open('perfect_rag.py', 'w', encoding='utf-8') as f:
        f.writelines(lines)

    print("  âœ… _generate_llm_summary ë¶„í•  ì™„ë£Œ")
    return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸ”¨ ê¸´ í•¨ìˆ˜ ë¶„í•  ì‘ì—… ì‹œì‘")
    print("="*60)

    # 1. _search_multiple_documents ë¶„í• 
    success1 = split_search_multiple_documents()

    # 2. _generate_llm_summary ë¶„í• 
    success2 = split_generate_llm_summary()

    if success1 and success2:
        print("\nâœ… ëª¨ë“  í•¨ìˆ˜ ë¶„í•  ì™„ë£Œ!")
        print("  - _search_multiple_documents: 4ê°œ í—¬í¼ í•¨ìˆ˜ë¡œ ë¶„í• ")
        print("  - _generate_llm_summary: 3ê°œ í—¬í¼ í•¨ìˆ˜ë¡œ ë¶„í• ")
    else:
        print("\nâš ï¸ ì¼ë¶€ í•¨ìˆ˜ ë¶„í•  ì‹¤íŒ¨")

    # ë¬¸ë²• ê²€ì¦
    import subprocess
    result = subprocess.run(['python3', '-m', 'py_compile', 'perfect_rag.py'],
                          capture_output=True, text=True)
    if result.returncode == 0:
        print("\nâœ… ë¬¸ë²• ì˜¤ë¥˜ ì—†ìŒ")
    else:
        print(f"\nâŒ ë¬¸ë²• ì˜¤ë¥˜: {result.stderr}")

if __name__ == "__main__":
    main()