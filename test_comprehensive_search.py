#!/usr/bin/env python3
"""
í¬ê´„ì  ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ - ë‹¤ì–‘í•œ ì¥ë¹„ ë° í™•ì¥ì„± ê²€ì¦
"""

import sys
from pathlib import Path
import time
import re

sys.path.append(str(Path(__file__).parent))

from perfect_rag import PerfectRAG

def test_comprehensive_search():
    """ë‹¤ì–‘í•œ ì¥ë¹„ ë¬¸ì„œ ê²€ìƒ‰ ë° í™•ì¥ì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ“Š í¬ê´„ì  ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (889ê°œ ë¬¸ì„œ ëŒ€ìƒ)")
    print("="*60 + "\n")

    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    start = time.time()
    rag = PerfectRAG(preload_llm=False)
    init_time = time.time() - start

    print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {init_time:.2f}ì´ˆ")
    print(f"ğŸ“ ì´ {len(rag.pdf_files)}ê°œ PDF ë¬¸ì„œ ë¡œë“œ")
    print(f"ğŸ“ ë©”íƒ€ë°ì´í„° ìºì‹œ: {len(rag.metadata_cache)}ê°œ í•­ëª©\n")

    # ë‹¤ì–‘í•œ ì¥ë¹„ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        ("DVRê´€ë ¨ ë¬¸ì„œ", "DVR"),
        ("ì¹´ë©”ë¼ ê´€ë ¨ ë¬¸ì„œ", "ì¹´ë©”ë¼"),
        ("ë Œì¦ˆ ê´€ë ¨ ë¬¸ì„œ", "ë Œì¦ˆ"),
        ("ëª¨ë‹ˆí„° ê´€ë ¨ ë¬¸ì„œ", "ëª¨ë‹ˆí„°"),
        ("ì‚¼ê°ëŒ€ êµ¬ë§¤ ë¬¸ì„œ", "ì‚¼ê°ëŒ€"),
        ("ì¤‘ê³„ì°¨ ê´€ë ¨ ë¬¸ì„œ", "ì¤‘ê³„ì°¨"),
        ("2020ë…„ êµ¬ë§¤ ë¬¸ì„œ", "2020.*êµ¬ë§¤"),
        ("2019ë…„ ìˆ˜ë¦¬ ë¬¸ì„œ", "2019.*ìˆ˜ë¦¬"),
        ("ìµœìƒˆë¦„ ê¸°ì•ˆì ë¬¸ì„œ", "ìµœìƒˆë¦„"),
        ("ê¹€ë¯¼ìˆ˜ ê¸°ì•ˆì ë¬¸ì„œ", "ê¹€ë¯¼ìˆ˜")
    ]

    results_summary = []

    print("ğŸ” ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    print("-" * 60)

    for query, keyword in test_queries:
        print(f"\nğŸ“Œ í…ŒìŠ¤íŠ¸: '{query}'")
        start = time.time()

        try:
            # ë¬¸ì„œ ê²€ìƒ‰ ì‹¤í–‰
            result = rag._search_multiple_documents(query)
            search_time = time.time() - start

            # ê²°ê³¼ ë¶„ì„
            doc_count = 0
            found_files = []

            if 'ê²€ìƒ‰ ê²°ê³¼' in result and 'ê°œ ë¬¸ì„œ ë°œê²¬' in result:
                count_match = re.search(r'ì´ (\d+)ê°œ ë¬¸ì„œ ë°œê²¬', result)
                if count_match:
                    doc_count = int(count_match.group(1))

                # íŒŒì¼ëª… ì¶”ì¶œ
                lines = result.split('\n')
                for line in lines:
                    if '.pdf' in line:
                        file_match = re.search(r'([^\/\[\]]+\.pdf)', line)
                        if file_match:
                            filename = file_match.group(1).strip()
                            if filename not in found_files:
                                found_files.append(filename)

            # ì§ì ‘ ìºì‹œì—ì„œ ê²€ì¦
            cache_count = 0
            for cache_key, metadata in rag.metadata_cache.items():
                if metadata.get('is_pdf'):
                    filename = metadata.get('filename', '')
                    text = metadata.get('text', '')[:1000]  # ì²« 1000ì

                    # í‚¤ì›Œë“œ ê²€ìƒ‰
                    if keyword.lower() in filename.lower() or keyword.lower() in text.lower():
                        cache_count += 1

            # ê²°ê³¼ ì €ì¥
            results_summary.append({
                'query': query,
                'found': doc_count,
                'cache_verified': cache_count,
                'time': search_time,
                'sample_files': found_files[:3]
            })

            # ê²°ê³¼ ì¶œë ¥
            if doc_count > 0:
                print(f"  âœ… {doc_count}ê°œ ë¬¸ì„œ ë°œê²¬ (ìºì‹œ ê²€ì¦: {cache_count}ê°œ)")
                if found_files:
                    print(f"  ğŸ“„ ìƒ˜í”Œ: {found_files[0][:50]}...")
            else:
                print(f"  âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ìºì‹œì—ëŠ” {cache_count}ê°œ ì¡´ì¬)")

            print(f"  â±ï¸ ê²€ìƒ‰ ì‹œê°„: {search_time:.3f}ì´ˆ")

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            results_summary.append({
                'query': query,
                'found': 0,
                'cache_verified': 0,
                'time': 0,
                'error': str(e)
            })

    # ì¢…í•© ë¶„ì„
    print("\n" + "="*60)
    print("ğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ ì¢…í•© ë¶„ì„")
    print("="*60 + "\n")

    total_found = sum(r['found'] for r in results_summary)
    total_time = sum(r['time'] for r in results_summary)
    successful_searches = [r for r in results_summary if r['found'] > 0]

    print(f"ğŸ“ˆ ì „ì²´ í†µê³„:")
    print(f"  - ì´ ê²€ìƒ‰ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
    print(f"  - ì„±ê³µí•œ ê²€ìƒ‰: {len(successful_searches)}ê°œ")
    print(f"  - ë°œê²¬ëœ ë¬¸ì„œ ì´í•©: {total_found}ê°œ")
    print(f"  - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {total_time/len(test_queries):.3f}ì´ˆ")
    print(f"  - ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")

    print(f"\nğŸ” ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê²€ì¦:")
    for r in results_summary:
        if r['found'] != r['cache_verified']:
            status = "âš ï¸ ë¶ˆì¼ì¹˜"
        elif r['found'] > 0:
            status = "âœ… ì •í™•"
        else:
            status = "ğŸ” ì¶”ê°€ í™•ì¸ í•„ìš”"

        print(f"  {r['query']:20s} : ê²€ìƒ‰ {r['found']:3d}ê°œ, ìºì‹œ {r['cache_verified']:3d}ê°œ - {status}")

    # í™•ì¥ì„± í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“¦ í™•ì¥ì„± ê²€ì¦:")
    print(f"  - ì „ì²´ ë¬¸ì„œ ìˆ˜: {len(rag.pdf_files)}ê°œ")
    print(f"  - ë©”íƒ€ë°ì´í„° ìºì‹œ í¬ê¸°: {len(rag.metadata_cache)}ê°œ")
    print(f"  - ì´ˆê¸°í™” ì‹œê°„: {init_time:.2f}ì´ˆ")
    print(f"  - ë¬¸ì„œë‹¹ í‰ê·  ì´ˆê¸°í™”: {init_time/len(rag.pdf_files)*1000:.1f}ms")

    # auto_indexer ì—°ë™ í™•ì¸
    auto_indexer_path = Path(__file__).parent / 'auto_indexer.py'
    if auto_indexer_path.exists():
        print(f"\nğŸ”„ ìë™ ì¸ë±ì‹± ì‹œìŠ¤í…œ: âœ… ì‚¬ìš© ê°€ëŠ¥")
        print(f"  - ìƒˆ ë¬¸ì„œ ìë™ ê°ì§€ ë° ì¸ë±ì‹± ì§€ì›")
        print(f"  - 60ì´ˆë§ˆë‹¤ docs í´ë” ëª¨ë‹ˆí„°ë§")
    else:
        print(f"\nğŸ”„ ìë™ ì¸ë±ì‹± ì‹œìŠ¤í…œ: âŒ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*60)

if __name__ == "__main__":
    test_comprehensive_search()